[{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"generic","dir":"Articles","previous_headings":"","what":"Generic","title":"Practical Power Analysis in R","text":"generic functions compute return statistical power option generate Type Type II error plots test statistics degrees freedom available. Users can input test statistics manually, valuable custom designs outside {pwrss} package’s scope, extract statistical software output. flexibility proves particularly advantageous since test statistics degrees freedom typically accessible programs like jamovi, JASP, SAS, SPSS, Stata. Power calculations can performed entering test statistic ncp mean arguments. Post-hoc power estimates derived way provide sensitivity analysis, revealing evidential strength study’s sample size relative observed effect size. approach offers valuable insights large samples, effect estimates demonstrate greater stability. However, small samples, effect size estimates exhibit higher variability, post-hoc power requires cautious interpretation.","code":""},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"post-hoc","dir":"Articles","previous_headings":"Generic > T-Test","what":"Post-Hoc","title":"Practical Power Analysis in R","text":"Example: mtcars dataset R contains information 32 car models 1974 issue Motor Trend magazine includes various performance design attributes vehicle. variables interest: mpg : Miles per gallon hp : Gross horsepower wt : Weight car (1000 lbs unit) aim estimate extent one-unit increase gross horsepower associated miles per gallon, controlling vehicle weight. post-hoc power given observed test statistic?  Report: post-hoc power analysis showed sample 32 cars 0.925 chance detecting observed relationship horsepower miles per gallon, relationship exists. analysis conducted using α\\alpha level 0.05.","code":"data(mtcars)  model <- lm(mpg ~ hp + wt, data = mtcars) summary(model) #>  #> Call: #> lm(formula = mpg ~ hp + wt, data = mtcars) #>  #> Residuals: #>    Min     1Q Median     3Q    Max  #> -3.941 -1.600 -0.182  1.050  5.854  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 37.22727    1.59879  23.285  < 2e-16 *** #> hp          -0.03177    0.00903  -3.519  0.00145 **  #> wt          -3.87783    0.63273  -6.129 1.12e-06 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 2.593 on 29 degrees of freedom #> Multiple R-squared:  0.8268, Adjusted R-squared:  0.8148  #> F-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12  power.t.test(ncp = -3.519, # t-value for hp variable              df = 29, # residual degrees of freedom              alpha = 0.05, # type 1 error rate              alternative = \"two.sided\",              plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp = null.ncp  #>   H1 (Alt. Claim) : ncp != null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.075 #>   Statistical Power      = 0.925  <<"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"user-defined-design","dir":"Articles","previous_headings":"Generic > T-Test","what":"User-Defined Design","title":"Practical Power Analysis in R","text":"Power calculation readily available non-equivalent pre-test vs. post-test control-group-designs formula already known. approximate standard error SE=1−R2p(1−p)n(1−RTX2)SE = \\sqrt{\\frac{1 - R^2}{p(1 - p)n(1 - R^2_{TX})}} df=n−g−2df = n - g - 2 R2R^2 : Explanatory power covariates RTX2R^2_{TX} : Squared point-biserial correlation treatment indicator pre-test pp : Group allocation rate nn : Total sample size gg : Number covariates details please see (Bulus, 2021, p. 52; Oakes Feldman, 2001, p. 15). Example: team educational psychologists implements mindfulness-based stress-reduction program 6th-grade classrooms one middle school, 6th-grade classrooms another school continue usual homeroom activities (conventional approach). want determine whether new program yields greater improvements emotional regulation comparing students intervention school control school. students complete standardized emotional-regulation inventory start end semester. superiority test conducted assess whether improvements intervention school exceed control school meaningful margin. researcher considers medium effect relevant sufficient support potential scale-(d = 0.50) defines superiority margin 0.10 - , mindfulness program considered superior conventional program d - null.d least 0.10. Assume two classrooms school, classroom 30 students, pre-test accounts 50% variance post-test scores, squared point-biserial correlation group membership emotional regulation scores 0.10. power detect superiority criteria? Report: power analysis conducted assess whether sample 120 students sufficient detect effect mindfulness intervention emotional regulation. analysis targeted moderate effect size (d = 0.50) superiority margin 0.10, using one-tailed test α\\alpha = 0.05. design yielded estimated power 0.90, indicating adequate sensitivity detect intervention effect.","code":"# define parameters d <- 0.50 # effect size under alternative null.d <- 0 # effect size under null margin <- 0.10 # smallest meaningful diff between d and null.d  p <- 0.50 # proportion of subjects in the intervention school n <- 120 # total sample size g <- 1 # number of covariates r.squared <- 0.50 # explanatory power of covariates rtx.squared <- 0.10 # squared point-biserial cor between trt dummy and outcome  # calculate the standard error std.error <- sqrt((1 - r.squared) / (p * (1 - p) * n * (1 - rtx.squared)))  # calculate non-centrality parameters ncp <- (d - null.d) / std.error null.ncp <- margin / std.error  # calculate power power.t.test(ncp = ncp,              null.ncp = null.ncp,              df = n - g - 2,              alpha = 0.05,              alternative = \"one.sided\",              plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp <= null.ncp  #>   H1 (Alt. Claim) : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.104 #>   Statistical Power      = 0.896  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"post-hoc-1","dir":"Articles","previous_headings":"Generic > Z-Test","what":"Post-Hoc","title":"Practical Power Analysis in R","text":"Example: warpbreaks dataset R contains data experiment number warp breaks per loom fixed length yarn. includes information type wool tension level used weaving. dataset often used illustrate count data modeling. variables interest: breaks: Number warp breaks wool: Type wool (factor levels B) tension: Tension applied yarn (factor levels Low, Medium, High) aim estimate extent type wool level tension associated number warp breaks using Poisson regression model. post-hoc power given observed test statistic Wool B?  Report: post-hoc power analysis showed sample 54 trials 0.979 chance detecting observed relationship Wool B number warp breaks, relationship exists. analysis conducted using α\\alpha level 0.05.","code":"data(warpbreaks)  model <- glm(breaks ~ wool + tension, data = warpbreaks,              family = poisson(link = \"log\")) summary(model) #>  #> Call: #> glm(formula = breaks ~ wool + tension, family = poisson(link = \"log\"),  #>     data = warpbreaks) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  3.69196    0.04541  81.302  < 2e-16 *** #> woolB       -0.20599    0.05157  -3.994 6.49e-05 *** #> tensionM    -0.32132    0.06027  -5.332 9.73e-08 *** #> tensionH    -0.51849    0.06396  -8.107 5.21e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for poisson family taken to be 1) #>  #>     Null deviance: 297.37  on 53  degrees of freedom #> Residual deviance: 210.39  on 50  degrees of freedom #> AIC: 493.06 #>  #> Number of Fisher Scoring iterations: 4  power.z.test(mean = -3.994, # z-value for wool B              alpha = 0.05, # type 1 error rate              alternative = \"two.sided\",              plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean = null.mean  #>   H1 (Alt. Claim) : mean != null.mean  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.021 #>   Statistical Power    = 0.979  <<"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"user-defined-design-1","dir":"Articles","previous_headings":"Generic > Z-Test","what":"User Defined Design","title":"Practical Power Analysis in R","text":"Power calculation readily available Spearman’s ρ\\rho rank correlation formula already known. approximate standard error Fisher’s Z-transformed correlation coefficient SE=1.06n−3SE = \\sqrt{\\frac{1.06}{n - 3}} nn sample size. details please see (Fieller, Hartley, Pearson, 1957, p. 472). Example: team school counselors want examine whether relationship students’ class rank (1st, 2nd, 3rd, etc.) self-reported academic stress levels, measured 10-point scale (1 = stress, 10 = extreme stress). Since class rank ordinal variable (lower ranks mean higher academic standing) stress scale subjective potentially interval-scaled, counselor uses Spearman’s rank-order correlation (Spearman’s ρ\\rho) assess whether higher-ranking students tend report lower higher levels stress. Researchers hypothesize students higher class ranks (.e., lower rank numbers) report lower stress levels. plan recruit 100 students, interested detecting Spearman’s ρ\\rho small 0.30, use two-tailed test α\\alpha level 0.05. power criteria?  Report: power analysis conducted assess whether 100 students sufficient detect association students’ class rank self-reported academic stress levels. analysis targeted moderate Spearman’s ρ\\rho 0.30, two-tailed test α\\alpha = 0.05. configuration yielded estimated power 0.84, indicating sufficient sensitivity detect hypothesized association.","code":"# define parameters rs <- 0.30 # spearman rho rank cor under alternative null.rs <- 0 # spearman rho rank cor under null n <- 100 # sample size  # apply Fisher's Z transformation z.rs <- cor.to.z(rs)$z #>         z       rho  #> 0.3095196 0.3000000 z.null.rs <- cor.to.z(null.rs)$z #>   z rho  #>   0   0  # calculate the standard error z.std.error <- sqrt(1.06 / (n - 3))  # calculate the non-centrality parameter ncp <- (z.rs - z.null.rs) / z.std.error  # calculate power power.z.test(ncp = ncp,              alpha = 0.05,              alternative = \"two.sided\",              plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean = null.mean  #>   H1 (Alt. Claim) : mean != null.mean  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.158 #>   Statistical Power    = 0.842  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"post-hoc-2","dir":"Articles","previous_headings":"Generic > F-Test","what":"Post-Hoc","title":"Practical Power Analysis in R","text":"Example: trees dataset R contains measurements volume, height, girth (diameter) 31 black cherry trees. variables interest: Girth: Diameter tree (inches) Height: Height tree (feet) aim estimate extent tree height associated tree girth. post-hoc power given observed test statistic? Report: post-hoc power analysis showed sample 31 trees 0.885 chance detecting observed relationship tree height girth, relationship exists population. analysis conducted using α\\alpha level 0.05.","code":"data(trees)  # model <- aov(Girth ~ Height, data = trees) model <- lm(Girth ~ Height, data = trees) summary(model) #>  #> Call: #> lm(formula = Girth ~ Height, data = trees) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -4.2386 -1.9205 -0.0714  2.7450  4.5384  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)    #> (Intercept) -6.18839    5.96020  -1.038  0.30772    #> Height       0.25575    0.07816   3.272  0.00276 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 2.728 on 29 degrees of freedom #> Multiple R-squared:  0.2697, Adjusted R-squared:  0.2445  #> F-statistic: 10.71 on 1 and 29 DF,  p-value: 0.002758  power.f.test(ncp = 10.71, # non-centrality under alternative              df1 = 1, # numerator degrees of freedom              df2 = 29, # denominator degrees of freedom              alpha = 0.05, # type 1 error rate              plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic F-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp = null.ncp  #>   H1 (Alt. Claim) : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.115 #>   Statistical Power      = 0.885  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"post-hoc-1-1","dir":"Articles","previous_headings":"Generic > Chi-square Test","what":"Post-Hoc 1","title":"Practical Power Analysis in R","text":"Example: HairEyeColor dataset R contains data survey 592 students, recording joint distribution hair color, eye color, gender. stored three-dimensional contingency table, counts representing number individuals category. variables interest: Hair: Hair color (e.g., Black, Brown, Blond, Red) Eye: Eye color (e.g., Brown, Blue, Hazel, Green) aim examine association hair color eye color. post-hoc power given observed test statistic chi-squared test independence? Report: post-hoc power analysis showed sample 592 individuals 1.00 chance detecting observed relationship hair eye color, relationship exists population. analysis conducted using α\\alpha level 0.05.","code":"data(HairEyeColor)  table <- margin.table(HairEyeColor, c(1, 2)) print(table) #>        Eye #> Hair    Brown Blue Hazel Green #>   Black    68   20    15     5 #>   Brown   119   84    54    29 #>   Red      26   17    14    14 #>   Blond     7   94    10    16  chisq.test(table) #>  #>  Pearson's Chi-squared test #>  #> data:  table #> X-squared = 138.29, df = 9, p-value < 2.2e-16  power.chisq.test(ncp = 138.29, # X-squared                  df = 9, # degrees of freedom                  alpha = 0.05, # type 1 error rate                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Chi-square Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : ncp = null.ncp  #>   H1 (Alt. Claim)   : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.000 #>   Statistical Power      = 1  <<"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"post-hoc-2-1","dir":"Articles","previous_headings":"Generic > Chi-square Test","what":"Post-Hoc 2","title":"Practical Power Analysis in R","text":"Example: infert dataset R contains data study infertility women, examining relationship reproductive history infertility status. includes demographic clinical information 248 women. variables interest: case: Infertility status (1 = infertile, 0 = fertile) age: Age woman years parity: Number prior full-term pregnancies induced: Number induced abortions spontaneous: Number spontaneous abortions aim evaluate whether number induced abortions contributes prediction infertility status, beyond effects age, parity, spontaneous abortions, using logistic regression framework. post-hoc power given observed deviance difference full reduced models?  Report: post-hoc power analysis indicated sample 248 women provided 0.99 probability detecting unique contribution number induced abortions infertility status, controlling variables, assuming relationship exists population. analysis conducted using α\\alpha level 0.05.","code":"data(infert)  fit.reduced <- glm(case ~ age + parity + spontaneous,                    data = infert,                    family = binomial)  fit.full <- glm(case ~ age + parity + spontaneous + induced,                 data = infert,                 family = binomial)  anova(fit.reduced, fit.full) #> Analysis of Deviance Table #>  #> Model 1: case ~ age + parity + spontaneous #> Model 2: case ~ age + parity + spontaneous + induced #>   Resid. Df Resid. Dev Df Deviance  Pr(>Chi)     #> 1       244     279.41                           #> 2       243     260.94  1   18.463 1.732e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  power.chisq.test(ncp = 18.463,                  df = 1,                  alpha = 0.05,                  plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Chi-square Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : ncp = null.ncp  #>   H1 (Alt. Claim)   : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.010 #>   Statistical Power      = 0.99  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"post-hoc-3","dir":"Articles","previous_headings":"Generic > Binomial Test","what":"Post-Hoc","title":"Practical Power Analysis in R","text":"Example: faithful dataset contains 272 observations eruptions Old Faithful geyser Yellowstone National Park. includes: eruptions: Eruption duration (minutes) waiting: Time eruptions (minutes) aim test whether eruptions lasting 3 minutes occur half time. post-hoc power given observed proportion sample size?  Report: post-hoc power analysis indicated sample 272 eruptions provided 0.999 probability detecting whether eruptions lasting 3 minutes occur 50% time, exists underlying eruption pattern. analysis based one-sided test procedure α\\alpha = 0.05.","code":"data(faithful)  long <- faithful$eruptions > 3 n.success <- sum(long) n.total <- nrow(faithful)  binom.test(n.success, n.total, p = 0.50) #>  #>  Exact binomial test #>  #> data:  n.success and n.total #> number of successes = 175, number of trials = 272, p-value = 2.609e-06 #> alternative hypothesis: true probability of success is not equal to 0.5 #> 95 percent confidence interval: #>  0.5832982 0.7003038 #> sample estimates: #> probability of success  #>              0.6433824  power.binom.test(size = n.total, # number of eruptions                  prob = n.success / n.total, # prob. of occurrence under alt.                  null.prob = 0.50, # prob. of occurrence under null                  alpha = 0.05,                  alternative = \"one.sided\",                  plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= null.prob  #>   H1 (Alt. Claim) : prob > null.prob  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.039 #>   Type 2 Error (beta)    = 0.001 #>   Statistical Power      = 0.999  <<"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"user-defined-designs","dir":"Articles","previous_headings":"Generic > Binomial Test","what":"User-Defined Designs","title":"Practical Power Analysis in R","text":"Example 1: Find number coin toss test whether coin fair. Report 1: Power analysis indicated least 85,632 coin tosses required determine whether coin fair. analysis assumes fair coin 0.50 probability landing heads, equivalence margins set 0.495 0.505, using two one-sided test procedure α\\alpha = 0.05. Example 2: Find optimal number replications Monte Carlo simulation. reliably detect type 1 error rate 0.05: reliably detect power rate 0.80: Report 2: Power analysis indicated least 16,424 replications required estimate Type 1 error rate α\\alpha = 0.05. analysis used two one-sided test procedure equivalence margins set 0.045 0.055. contrast, least 55,011 replications needed estimate statistical power 0.80, assuming equivalence margins 0.795 0.805, also using two one-sided test procedure α\\alpha = 0.05.","code":"# find the approximate solution power.z.oneprop(prob = 0.50, # prob. of head under alt.                 null.prob = c(0.495, 0.505), # equivalence margins                 power = 0.80,                 alpha = 0.05, # type 1 error rate                 alternative = \"two.one.sided\",                 verbose = FALSE)$n #> [1] 85639  # iterate to find the exact solution power.binom.test(size = 85632, # number of tosses needed                  prob = 0.50, # prob. of head under alt.                  null.prob = c(0.495, 0.505), # equivalence margins                  alpha = 0.05, # type 1 error rate                  alternative = \"two.one.sided\",                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= min(null.prob) or  #>                     prob >= max(null.prob)  #>   H1 (Alt. Claim) : prob > min(null.prob) and  #>                     prob < max(null.prob)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  << # find the approximate solution power.z.oneprop(prob = 0.05, # prob. of head under alt.                 null.prob = c(0.045, 0.055), # equivalence margins                 power = 0.80,                 alpha = 0.05, # type 1 error rate                 alternative = \"two.one.sided\", verbose = FALSE)$n #> [1] 16272  # iterate to find the exact solution power.binom.test(size = 16424, # number of replications needed                  prob = 0.05, # prob. of falsely rejecting null                  null.prob = c(0.045, 0.055), # equivalence margins                  alpha = 0.05,                  alternative = \"two.one.sided\",                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= min(null.prob) or  #>                     prob >= max(null.prob)  #>   H1 (Alt. Claim) : prob > min(null.prob) and  #>                     prob < max(null.prob)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.049 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802  << # find the approximate solution power.z.oneprop(prob = 0.80, # prob. of correctly rejecting null                 null.prob = c(0.795, 0.805), # equivalence margins                 power = 0.80,                 alpha = 0.05, # type 1 error rate                 alternative = \"two.one.sided\", verbose = FALSE)$n #> [1] 54809  # iterate to find the exact solution power.binom.test(size = 55011, # number of replications needed                  prob = 0.80, # prob. of correctly rejecting null                  null.prob = c(0.795, 0.805), # equivalence margins                  alpha = 0.05,                  alternative = \"two.one.sided\",                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= min(null.prob) or  #>                     prob >= max(null.prob)  #>   H1 (Alt. Claim) : prob > min(null.prob) and  #>                     prob < max(null.prob)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  <<"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"error-plots","dir":"Articles","previous_headings":"Generic","what":"Error Plots","title":"Practical Power Analysis in R","text":"plot() function (S3 method) wrapper around generic functions . creates visual representation null alternative distributions, shaded areas indicating Type 1 error (false positive) Type 2 error (false negative) regions. Assign results pwrss function R object pass plot() function.  NOTE: earlier versions {pwrss} package, plot() function generated multiple panel plots ANCOVA designs mediation models. feature longer supported, updated functions now return one effect time.","code":"power.t.student(d = 0.20, power = 0.80) |>   plot()"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"independent-samples-t-test","dir":"Articles","previous_headings":"Means (T-Test)","what":"Independent Samples T-Test","title":"Practical Power Analysis in R","text":"independent samples t-test used compare mean outcomes two groups statistically independent - meaning outcome value individual one group related outcome value individual group. groups may represent treatment control conditions, gender groups (e.g., females males), pre-existing experimentally assigned categories.","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"parametric","dir":"Articles","previous_headings":"Means (T-Test) > Independent Samples T-Test","what":"Parametric","title":"Practical Power Analysis in R","text":"Example: Suppose aim evaluate extent psychological intervention reduces post-earthquake psychosomatic symptoms. consider standardized mean difference small Cohen’s d = -0.20 treatment control groups meaningful relevant. minimum required sample size per group, accounting 0.05 dropout rate treatment group? Report: conducted power analysis determine required sample size comparing treatment control groups psychosomatic symptoms. analysis assumed small effect size (Cohen’s d = 0.20), 0.80 statistical power, 0.05 significance level (one-tailed). Results indicated 310 participants per group needed (620 total). account anticipated 0.05 attrition treatment group, additional 17 participants required, bringing total sample size 637.","code":"power.t.student(d = -0.20,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d >= 0  #>   H1 (Alt. Claim) : d - null.d < 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 310 and 310  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # account for attrition inflate.sample(n = 310, rate = 0) # control #> 310 inflate.sample(n = 310, rate = 0.05) # treatment #> 327"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"robust-parametric","dir":"Articles","previous_headings":"Means (T-Test) > Independent Samples T-Test","what":"Robust Parametric","title":"Practical Power Analysis in R","text":"Unlike experimental designs, group variances population proportions may differ pre-existing groups (e.g. male female teachers). Assume smallest effect size interest Cohen’s d = 0.20. expected variance ratio (female male) 1.5, prevalence ratio (female male) population 2. minimum required sample size per group conditions? Report: conducted power analysis determine required sample size comparing females males. analysis assumed small effect (Cohen’s d = 0.20), 0.80 power, 0.05 significance level (two-tailed). analysis additionally incorporated realistic population characteristics: unequal variances (variance ratio = 1.5, females relative males) unequal group prevalence (2:1 female--male ratio). Results indicated 517 females 259 males required (776 total).","code":"power.t.welch(d = 0.20,               power = 0.80,               n.ratio = 2,               var.ratio = 1.5,               alpha = 0.05,               alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 517 and 259  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"non-parametric","dir":"Articles","previous_headings":"Means (T-Test) > Independent Samples T-Test","what":"Non-Parametric","title":"Practical Power Analysis in R","text":"outcome variable may treated continuous, follow normal distribution - example, Likert-type scales 5 7 categories, ranked data, bounded ordinal measures. Assume smallest effect size interest treatment control groups Cohen’s d = 0.20. minimum required sample size per group, accounting 0.05 dropout rate treatment group? Report: conducted power analysis determine required sample size comparing treatment control groups Likert-type outcome measure, assuming observed categories reflect underlying continuous latent construct follows normal distribution. analysis assumed small effect size (Cohen’s d = 0.20), 0.80 statistical power, 0.05 significance level (two-tailed). Results indicated 412 participants per group needed (824 total). account anticipated 0.05 attrition treatment group, additional 22 participants required, bringing total sample size 846.","code":"power.np.wilcoxon(d = 0.20,                   power = 0.80,                   n.ratio = 1,                   alpha = 0.05,                   alternative = \"two.sided\",                   design = \"independent\",                   distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 412 and 412  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  inflate.sample(n = 412, rate = 0.05) # treatment #> 434"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"non-inferiority","dir":"Articles","previous_headings":"Means (T-Test) > Independent Samples T-Test","what":"Non-Inferiority","title":"Practical Power Analysis in R","text":"non-inferiority trial, may evaluate effectiveness new program, drug, product, tests whether mean outcome treatment group unacceptably worse conventional-treatment placebo group, based pre-specified non-inferiority margin. instance, d - null.d difference small margin = -0.05 may still support conclusion non-inferiority. minimum required sample size detect effect size d = 0.20 criterion? higher values outcome better margin usually takes NEGATIVE values; whereas lower values outcome better margin usually takes POSITIVE values.  Report: conducted power analysis determine required sample size non-inferiority trial comparing treatment placebo groups. analysis assumed small treatment effect (d = 0.20), non-inferiority margin d = -0.05, 0.80 power, 0.05 significance level using one-tailed test appropriate non-inferiority designs. Results indicated 199 participants per group (398 total) needed demonstrate treatment meaningfully inferior placebo. Accounting anticipated 0.05 attrition rate, recruit additional 21 participants, yielding target sample size 419 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = -0.05,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 199 and 199  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # consider 0.05 attrition rate inflate.sample(n = 398, rate = 0.05) #> 419  # robust parametric power.t.welch(d = 0.20,               margin = -0.05,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 238 and 119  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = -0.05,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208 and 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"superiority","dir":"Articles","previous_headings":"Means (T-Test) > Independent Samples T-Test","what":"Superiority","title":"Practical Power Analysis in R","text":"superiority trial evaluates whether new program, drug, product leads meaningfully better mean outcome treatment group compared conventional treatment placebo group, based pre-specified superiority margin. example, d - null.d difference small margin = 0.05 may considered sufficient claim superiority. minimum required sample size detect effect size d = 0.20 criterion?  Report: conducted power analysis determine required sample size superiority trial comparing treatment placebo groups. analysis assumed small treatment effect (d = 0.20), superiority margin d = 0.05, 0.80 power, 0.05 significance level using one-tailed test appropriate superiority designs. Results indicated 552 participants per group (1104 total) needed demonstrate treatment meaningfully superior placebo. Accounting anticipated 0.05 attrition rate groups, recruit additional 59 participants, yielding target sample size 1163 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = 0.05,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 552 and 552  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # consider 0.05 attrition rate inflate.sample(n = 1104, rate = 0.05) #> 1163  # robust parametric power.t.welch(d = 0.20,               margin = 0.05,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 662 and 331  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = 0.05,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 578 and 578  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"equivalence","dir":"Articles","previous_headings":"Means (T-Test) > Independent Samples T-Test","what":"Equivalence","title":"Practical Power Analysis in R","text":"equivalence trial evaluates whether new program, drug, product performs similarly conventional treatment placebo, within pre-specified equivalence margin. example, difference d - null.d falling within range margin = c(-0.10, 0.10) may considered sufficient claim equivalence. minimum required sample size detect effect size d = 0.20 criterion? Report: conducted power analysis determine required sample size equivalence trial comparing new treatment conventional one. analysis assumed difference (d = 0), equivalence margin ranging d = -0.10 d = 0.10, 0.80 power, 0.05 significance level using two one-sided test appropriate equivalence designs. Results indicated 1714 participants per group (3428 total) needed demonstrate new treatment similar conventional one. Accounting anticipated 0.05 attrition rate groups, recruit additional 181 participants, yielding target sample size 3609 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0,                 margin = c(-0.10, 0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1714 and 1714  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 3428, rate = 0.05) #> 3609  # robust parametric power.t.welch(d = 0,               margin = c(-0.10, 0.10),               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 2056 and 1028  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # non-parametric power.np.wilcoxon(d = 0,                   margin = c(-0.10, 0.10),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1795 and 1795  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"minimum-effect","dir":"Articles","previous_headings":"Means (T-Test) > Independent Samples T-Test","what":"Minimum Effect","title":"Practical Power Analysis in R","text":"Minimum effect testing useful goal assess whether new program, drug, product performs meaningfully better worse conventional treatment-beyond pre-defined threshold practical significance (equivalence margins). instance, difference d - null.d falling outside range margin = c(-0.05, 0.05) may sufficient conclude intervention either inferior superior, exceeding bounds minimal practical importance. minimum required sample size detect effect size Cohen’s d = 0.20 criterion? Report: conducted power analysis determine required sample size minimum effect testing comparing new treatment conventional one. analysis assumed modest difference (d = 0.20), equivalence margin ranging d = -0.05 d = 0.05, 0.80 power, 0.05 significance level using two one-sided test appropriate minimum effect testing. Results indicated 700 participants per group (1400 total) needed reliably detect whether new treatment differs conventional treatment minimally important difference. Accounting anticipated 0.05 attrition rate groups, recruit additional 74 participants, yielding target sample size 1474 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = c(-0.05, 0.05),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 700 and 700  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 1400, rate = 0.05) #> 1474  # robust parametric power.t.welch(d = 0.20,               margin = c(-0.05, 0.05),               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 841 and 421  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = c(-0.05, 0.05),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 733 and 733  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"paired-samples-t-test","dir":"Articles","previous_headings":"Means (T-Test)","what":"Paired Samples T-Test","title":"Practical Power Analysis in R","text":"paired samples t-test used compare mean outcomes two related matched groups, observation one group paired corresponding observation . test appropriate outcome values independent, measurements taken individuals two time points (e.g., pre-test post-test), individuals matched based characteristics (e.g., siblings, matched pairs experimental designs).","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"paired-t-parametric","dir":"Articles","previous_headings":"Means (T-Test) > Paired Samples T-Test","what":"Parametric","title":"Practical Power Analysis in R","text":"Example: mental health clinic transitions -person online-group therapy sessions due logistical constraints. evaluate whether new format supports core therapeutic outcome - emotional regulation - researchers plan recruit new group clients participating online therapy compare outcomes historical sample clients previously completed program person. Participants matched based baseline symptom severity, age, gender, diagnosis. primary outcome emotional regulation, assessed end program using Difficulties Emotion Regulation Scale (DERS). two-sided test conducted determine whether emotional regulation improves deteriorates online format comparison -person format. Researchers aim detect small effect (d = 0.20), using two-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criterion? Report: conducted power analysis determine required sample size comparing emotional regulation scores online versus -person therapy sessions. analysis assumed modest difference groups (d = 0.20), 0.80 power, 0.05 significance level using two-sided test. Results indicated 199 participants need matched reliably determine whether online therapy better worse -person therapy. Accounting anticipated 0.05 attrition online group, additional 11 participants need matched, yielding target sample size 210 participants.","code":"power.t.student(d = 0.20,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 199  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802  # consider an attrition rate of 0.05 inflate.sample(n = 199, rate = 0.05) #> 210"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"non-parametric-1","dir":"Articles","previous_headings":"Means (T-Test) > Paired Samples T-Test","what":"Non-parametric","title":"Practical Power Analysis in R","text":"Example: Consider earlier example, now focus different outcome: session satisfaction ratings, measured 5-point scale (1 = , 5 = Extremely). Researchers aim determine whether satisfaction ratings differ online -person formats. test , plan use Wilcoxon signed-rank test paired data, targeting small effect size (d = 0.20) two-sided significance level α\\alpha = 0.05. minimum required sample size conditions? Report: conducted power analysis determine required sample size comparing session satisfaction ratings online versus -person therapy sessions using Wilcoxon signed-rank test. analysis assumed modest difference groups (d = 0.20), 0.80 power, 0.05 significance level using two-sided test, normal distribution. Results indicated 208 participants need matched reliably determine whether online therapy better worse -person therapy terms session satisfaction ratings. Accounting anticipated 0.05 attrition online group, additional 11 participants need matched, yielding target sample size 219 participants.","code":"power.np.wilcoxon(d = 0.20,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.sided\",                   design = \"paired\",                   distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # consider an attrition rate of 0.05 inflate.sample(n = 208, rate = 0.05) #> 219"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"non-inferiority-1","dir":"Articles","previous_headings":"Means (T-Test) > Paired Samples T-Test","what":"Non-inferiority","title":"Practical Power Analysis in R","text":"Consider earlier example, now focus different outcome: perceived group cohesion. evaluate whether new format preserves perceived group cohesion, researchers plan conduct non-inferiority test assess whether perceived group cohesion ratings online group meaningfully worse matched -person group. researcher expects change (d = 0). d - null.d difference can small margin = -0.10 online format still considered non-inferior. minimum required sample size criterion?  Report: conducted power analysis determine required sample size non-inferiority test comparing perceived group cohesion ratings online versus -person therapy sessions. analysis assumed true difference groups (d = 0), non-inferiority margin -0.10, 0.80 power, 0.05 significance level using one-sided test appropriate non-inferiority designs. Results indicated 619 participants need matched reliably determine whether online therapy meaningfully worse -person therapy pre-specified margin. Accounting anticipated 0.05 attrition online group, additional 33 participants required, yielding target sample size 652 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0,                 margin = -0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 619  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 619, rate = 0.05) #> 652  # non-parametric power.np.wilcoxon(d = 0,                   margin = -0.10,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 648  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"superiority-1","dir":"Articles","previous_headings":"Means (T-Test) > Paired Samples T-Test","what":"Superiority","title":"Practical Power Analysis in R","text":"Consider earlier example, now focus different outcome: psychological safety. maintaining core therapeutic outcomes important, online format may offer additional advantages. One outcome psychological safety, defined comfort expressing thoughts, emotions, personal experiences group sessions without fear judgment rejection. evaluate whether online format enhances dimension, researchers plan recruit new group clients beginning online therapy match historical sample previous clients completed program person. Matching done based baseline symptom severity, age, gender, diagnosis. superiority test conducted assess whether psychological safety ratings meaningfully higher online group compared matched -person group. researcher interested modest change (d = 0.20), d - null.d difference can small margin = 0.10 online format still considered superior. minimum required sample size criterion?  Report: conducted power analysis determine required sample size superiority test comparing psychological safety ratings online versus -person therapy sessions. analysis assumed modest difference groups (d = 0.20), superiority margin 0.10, 0.80 power, 0.05 significance level using one-sided test appropriate superiority designs. Results indicated 627 participants need matched reliably determine whether online therapy meaningfully better -person therapy pre-specified margin. Accounting anticipated 0.05 attrition online group, additional 33 participants required, yielding target sample size 660 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = 0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 627  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 627, rate = 0.05) #> 660  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = 0.10,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 657  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"equivalence-1","dir":"Articles","previous_headings":"Means (T-Test) > Paired Samples T-Test","what":"Equivalence","title":"Practical Power Analysis in R","text":"Example: Consider earlier example, now focus different outcome: emotional intensity. new format expected retain key therapeutic benefits, certain outcomes must remain stable intervention considered acceptable. One outcome emotional intensity sessions, defined typical depth strength emotions experienced expressed participants group discussions. little emotional intensity may signal disengagement superficial participation, much may overwhelm participants disrupt group cohesion. Therefore, maintaining similar level emotional intensity online format essential. evaluate , researchers plan recruit new group clients beginning online therapy match historical sample previous clients completed program person. Matching done based baseline symptom severity, age, gender, diagnosis. equivalence test conducted assess whether emotional intensity scores online group meaningfully similar matched -person group. researcher interested detecting difference (d = 0). d - null.d difference within range margin = c(-0.10, 0.10) considered sufficient claim equivalence. minimum required sample size criterion? Report: conducted power analysis determine required sample size equivalence test comparing emotional intensity online versus -person group therapy sessions. analysis assumed difference groups (d = 0), equivalence margin -0.10 0.10, 0.80 power, 0.05 significance level using two one-sided test appropriate equivalence designs. Results indicated 858 participants need matched reliably determine whether emotional intensity online therapy meaningfully similar -person therapy within pre-specified equivalence margin. Accounting anticipated 0.05 attrition online group, additional 46 participants required, yielding target sample size 904 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0,                 margin = c(-0.10, 0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 858  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 858, rate = 0.05) #> 904  # non-parametric power.np.wilcoxon(d = 0,                   margin = c(-0.10, 0.10),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 898  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"minimum-effect-1","dir":"Articles","previous_headings":"Means (T-Test) > Paired Samples T-Test","what":"Minimum Effect","title":"Practical Power Analysis in R","text":"Consider earlier example, outcome: emotional regulation. Different earlier example, null hypothesis longer point zero stated terms equivalence interval. minimal effect test conducted assess whether emotional regulation scores online group meaningfully different matched -person group. researcher interested detecting modest difference (d = 0.20). d - null.d difference outside range margin = c(-0.10, 0.10) considered sufficient claim difference. minimum required sample size criterion? Report: conducted power analysis determine required sample size minimal effect test comparing emotional regulation online versus -person group therapy sessions. analysis assumed modest difference groups (d = 0.20), equivalence margin -0.10 0.10, 0.80 power, 0.05 significance level using two one-sided test appropriate minimal effect testing. Results indicated 797 participants need matched reliably determine whether emotional regulation online therapy meaningfully different -person therapy. Accounting anticipated 0.05 attrition online group, additional 42 participants required, yielding target sample size 839 participants.","code":"# parametric (an example report is provided below) power.t.student(d = -0.20,                 margin = c(-0.10, 0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 797  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 797, rate = 0.05) #> 839  # non-parametric power.np.wilcoxon(d = -0.20,                   margin = c(-0.05, 0.05),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 370  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-sample-t-test","dir":"Articles","previous_headings":"Means (T-Test)","what":"One-Sample T-Test","title":"Practical Power Analysis in R","text":"one-sample t-test used determine whether mean single group differs significantly known hypothesized population value. test appropriate comparing observed sample mean fixed reference point-national average, theoretical benchmark, target score.","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-sample-t-parametric","dir":"Articles","previous_headings":"Means (T-Test) > One-Sample T-Test","what":"Parametric","title":"Practical Power Analysis in R","text":"Example: school district interested determining teacher stress levels introducing new program involves extensive teaching activities evaluation students. research division plan administer Perceived Stress Scale (PSS) teachers, produces total scores ranging 0 40. primary goal determine whether average stress level among teachers meaningfully elevated. mean score 22 higher - two points commonly used clinical threshold 20 - considered indicative elevated stress warrants attention. estimated standard deviation 5, two-point difference corresponds medium effect size (Cohen’s d = 0.40). Assume one-tailed test significance level α\\alpha = 0.05 target power 0.80. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether teachers exhibit elevated stress levels due workload. Assuming two-point difference clinical threshold (Cohen’s d = 0.40), one-sided test 0.80 power, 0.05 significance level, analysis indicated minimum 52 teachers surveyed reliably detect elevated stress.","code":"power.t.student(d = 0.40,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 52  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.192 #>   Statistical Power      = 0.808"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"non-parametric-2","dir":"Articles","previous_headings":"Means (T-Test) > One-Sample T-Test","what":"Non-Parametric","title":"Practical Power Analysis in R","text":"Example: Consider earlier example, now focus different outcome measured using single Likert-type item: job satisfaction. Job satisfaction measured using “Overall, satisfied job.” responses range 1 (strongly disagree) 5 (strongly agree). mean score neutral point 3 indicates dissatisfaction. schools district considers modest difference average neutral point (Cohen’s d = -0.20). Assume one-tailed test significance level α\\alpha = 0.05 target power 0.80. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether teachers satisfied job. Assuming modest difference neutral point (Cohen’s d = -0.20), one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 208 teachers surveyed.","code":"power.np.wilcoxon(d = -0.20,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.sided\",                   design = \"one.sample\",                   distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"practically-greater","dir":"Articles","previous_headings":"Means (T-Test) > One-Sample T-Test","what":"Practically Greater","title":"Practical Power Analysis in R","text":"Example: Consider earlier example focuses stress primary outcome. Now assume researchers testing whether observed difference (d - null.d) exceeds minimum meaningful effect specifying margin = 0.10 - correspond half-point increase average stress level. Differences smaller margin considered practically significant cause concern. Researchers plan use one-sided test significance level α\\alpha = 0.05 desired power 0.80. minimum required sample size configuration? Report: conducted power analysis determine required sample size assessing whether stress level teachers clinical threshold. Assuming medium difference clinical threshold (Cohen’s d = 0.40), one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 72 teachers surveyed.","code":"# parametric power.t.student(d = 0.40,                 margin = 0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 72  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # non-parametric power.np.wilcoxon(d = 0.40,                   margin = 0.10,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 76  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"equivalence-2","dir":"Articles","previous_headings":"Means (T-Test) > One-Sample T-Test","what":"Equivalence","title":"Practical Power Analysis in R","text":"Example: sleep research team evaluating safety new melatonin-based supplement designed support better sleep adults without causing excessive drowsiness oversleeping. ensure supplement disrupt healthy sleep patterns, plan assess whether average nightly sleep duration among users falls within clinically acceptable range 6.5 8.5 hours, considered optimal adults. Using one-sample equivalence t-test equivalence bounds set ±\\pm 1 hour around target value 7.5 hours, researchers aim demonstrate supplement lead - oversleeping. two one-sided tests procedure conducted significance level α\\alpha = 0.05 0.80 power. Assume standard deviation 1.2 hours expected mean 7.5 hours. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether sleep duration falls within predefined acceptable range. Assuming difference (d = 0) equivalence margin d = ±\\pm 0.83, two one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 14 participants needed.","code":"d <- (7.5 - 7.5) / 1.2 margin <- c((6.5 - 7.5) / 1.2, (8.5 - 7.5) / 1.2)  # parametric power.t.student(d = d,                 margin = margin,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 14  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.174 #>   Statistical Power      = 0.826  # non-parametric power.np.wilcoxon(d = d,                   margin = margin,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 14  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"minimal-effect","dir":"Articles","previous_headings":"Means (T-Test) > One-Sample T-Test","what":"Minimal Effect","title":"Practical Power Analysis in R","text":"Example: research team testing new medication developed treat generalized anxiety disorder monitoring whether disrupts normal sleep patterns. drug designed reduce anxiety, concern may cause excessive drowsiness oversleeping. clinically acceptable sleep range healthy adults defined 6.5 8.5 hours per night, 7.5 hours midpoint. goal determine whether mean sleep duration deviates significantly 7.5 hours. sleep duration equal greater 9 hours considered problematic. one-sample t-test used test whether average sleep duration differs range normative values. two one-sided test significance level 0.05 0.80 power, assuming standard deviation 1.2 hours. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether sleep duration falls outside predefined acceptable range. Assuming large difference (d = 1.25) equivalence margin d = ±\\pm 0.83, two one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 74 participants needed.","code":"d <- (9 - 7.5) / 1.2 margin <- c((6.5 - 7.5) / 1.2, (8.5 - 7.5) / 1.2)  # parametric power.t.student(d = d,                 margin = margin,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 74  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802  # non-parametric power.np.wilcoxon(d = d,                   margin = margin,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 78  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-sample","dir":"Articles","previous_headings":"Proportions (Z-Test)","what":"One-Sample","title":"Practical Power Analysis in R","text":"one-sample proportion test compares proportion successes sample known population proportion hypothesized value. “Success” defined based outcome interest can represent various binary events: patient recovery, disease presence, survival, website click-, customer retention, exam passage, program completion, yes / outcome relevant research question.","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"approximate","dir":"Articles","previous_headings":"Proportions (Z-Test) > One-Sample","what":"Approximate","title":"Practical Power Analysis in R","text":"approach assumes test statistics follow standard normal distribution. Example: regional traffic safety agency plans conduct observational study estimate seat belt use among daytime drivers. state law mandates seat belt use, agency adopts 90% compliance rate public safety benchmark, consistent national targets promoted National Highway Traffic Safety Administration (NHTSA). usage rate 80% lower raise concern potentially trigger enforcement campaigns. Assuming one-sided test α=0.05\\alpha = 0.05 0.80 power, many vehicles observed? Report: conducted power analysis determine required sample size assessing whether rate seat belt use falls predetermined compliance benchmark. true usage rate 80% lower considered cause concern relative 90% target. Assuming one-sided test significance level 0.05 0.80 power, analysis indicated minimum 69 vehicles observed. Arcsine transformation: arcsine transformation stabilizes variance proportion differences. can useful proportions towards extreme. Continuity correction: Continuity correction improves normal approximation small samples accounting discrete nature outcome, resulting accurate test statistics. Calculate standard error using probability success alternative hypothesis: default procedure calculates standard error using probability success null hypothesis (PASS). approach adjusts null distribution standard deviation obtain precise critical values. can changed via std.error argument. null values close zero one, appropriate use exact test.","code":"power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 69  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.200 #>   Statistical Power     = 0.8 power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 arcsine = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : TRUE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 54  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.197 #>   Statistical Power     = 0.803 power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 correct = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : TRUE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 79  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.198 #>   Statistical Power     = 0.802 power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 std.error = \"alternative\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Alternative #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 99  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.200 #>   Statistical Power     = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-prop-exact","dir":"Articles","previous_headings":"Proportions (Z-Test) > One-Sample","what":"Exact (Binomial)","title":"Practical Power Analysis in R","text":"Example: pharmaceutical company evaluating safety profile new medication developed generalized anxiety disorder monitoring occurrence skin rash. company finds minimum rate 2 1000 problematic. research division plan one-sided test significance level 0.05 0.80 power. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing rash prevalence. Assuming rate 2 1000, one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 804 participants needed.","code":"power.exact.oneprop(prob = 0.002, # probability of success under alternative                     null.prob = 0, # probability of success under null                     power = 0.80,                     alpha = 0.05,                     alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob <= 0 #>   H1 (Alt. Claim)        : prob - null.prob > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 804  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.200 #>   Statistical Power     = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"independent-samples","dir":"Articles","previous_headings":"Proportions (Z-Test)","what":"Independent Samples","title":"Practical Power Analysis in R","text":"independent samples proportion test compares proportion “successes” two distinct groups (groups related, paired, matched) determine whether statistically significant difference exists. Group may exist naturally (females - males, urban - rural, etc.) formed researcher (new - standard drug, intervention - control, etc.).  example compares two approaches:","code":"# z-test approach power.z.twoprops(prob1 = 0.60, prob2 = 0.50,                  power = 0.80, arcsine = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 = 0  #>   H1 (Alt. Claim) : prob1 - prob2 != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 388 and 388  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801  # find Cohen's h probs.to.h(prob1 = 0.60, prob2 = 0.50) #>         h     prob1     prob2  #> 0.2013579 0.6000000 0.5000000  # t-test approach power.t.student(d = 0.2013579, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 389 and 389  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"approximate-1","dir":"Articles","previous_headings":"Proportions (Z-Test) > Independent Samples","what":"Approximate","title":"Practical Power Analysis in R","text":"Example: pharmaceutical company investigating new medication intended treat generalized anxiety disorder. anti-anxiety efficacy evaluated elsewhere, early case reports suggest daytime sleepiness - recorded binary outcome (present vs. absent) - may occur frequently women men. verify potential gender-specific side effect, researchers enroll equal numbers male female patients, administer drug four weeks, document whether participant experiences clinically significant daytime sleepiness. five percent difference considered clinically meaningful warrants attention. research division plan one-sided test significance level 0.05 0.80 power. minimum required sample size criterion?  Report: conducted power analysis determine required sample size assessing whether gender differences exist daytime sleepiness. analysis assume rate 15% females 10% males, one-sided test 0.05 significance level 0.80 power. Results indicated minimum 540 participants needed per group (1080 total). Arcsine transformation: Continuity correction: Calculate standard error using unpooled standard deviations:","code":"power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 540 and 540  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\",                  arcsine = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 536 and 536  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\",                  correct = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 580 and 580  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\",                  std.error = \"unpooled\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 538 and 538  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"exact-fisher","dir":"Articles","previous_headings":"Proportions (Z-Test) > Independent Samples","what":"Exact (Fisher)","title":"Practical Power Analysis in R","text":"Example: metropolitan library system piloting two new reminder strategies boost timely return overdue books - naturally binary outcome, patron either brings item back within amnesty window (yes) (). Borrowers approaching due date randomly assigned one two groups. Group receives interactive WhatsApp chatbot walks renewal return options, whereas Group B receives gamified -app badge awards points prompt returns. reminder system judged worthwhile return rate either group exceeds least 10 percentage points. decision help reminder system invest considering cost. prior data exist, planners adopt “worst-case scenario” approach maximizes required sample size: rise 50% 60%. Using one-sided test α\\alpha = 0.05 0.80 power, minimum number patrons needed group? Report: conducted power analysis estimate required sample size evaluating relative effectiveness two reminder systems. Assuming 10% difference (50% 60%), one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 321 patrons needed group (642 total).","code":"power.exact.twoprops(prob1 = 0.60,                      prob2 = 0.50,                      power = 0.80,                      alpha = 0.05,                      alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Fisher's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 278 and 278  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.000 #>   Statistical Power    = 1"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"twoprops-non-inferiority","dir":"Articles","previous_headings":"Proportions (Z-Test) > Independent Samples","what":"Non-inferiority","title":"Practical Power Analysis in R","text":"Example: pharmaceutical company conducting non-inferiority trial evaluate safety profile new medication developed generalized anxiety disorder, focusing specifically occurrence skin rash side effect. current standard treatment skin rash rate approximately 2 per 1,000 patients (0.2%). company wants ensure new medication lead clinically unacceptable increase side effect. expect new drug skin rash rate approximately 1 per 1,000 patients (0.1%) define non-inferiority margin 1 per 1,000 (0.1%), meaning new drug’s skin rash rate exceed 0.3% considered non-inferior. Assuming one-sided test 0.05 significance level, 0.80 power, 0.05 attrition rate groups, minimum required sample size evaluate non-inferiority criterion? Report: conducted power analysis estimate minimum required sample size evaluate non-inferiority new drug treating generalized anxiety disorder compared standard treatment. analysis focused skin rash adverse event, assumed prevalence rate 1 1,000 (0.1%) new drug 2 1,000 (0.2%) standard treatment. Using non-inferiority margin 1 1,000 (0.1%) increase, one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 457 participants needed group (914 total). Considering 5% attrition rate total 963 participants needed.","code":"power.z.twoprops(prob1 = 0.01,                  prob2 = 0.02,                  margin = 0.01,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 >= margin  #>   H1 (Alt. Claim) : prob1 - prob2 < margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 457 and 457  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # consider 5% attrition rate inflate.sample(n = 914, rate = 0.05) #> 963"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"superiority-test","dir":"Articles","previous_headings":"Proportions (Z-Test) > Independent Samples","what":"Superiority Test","title":"Practical Power Analysis in R","text":"Example: Consider earlier example focuses non-inferiority new drug treating generalized anxiety disorder compared standard treatment. Now assume researchers aim evaluate whether new drug superior standard treatment reducing proportion patients resort rescue medication. 5% absolute reduction rescue medication use expected new drug group. Since prior estimates available, assume worst-case scenario 50% usage rate standard treatment group. Using 1% superiority margin, one-sided test 0.05 significance level, 0.80 power, 5% attrition rate groups, minimum required sample size test superiority conditions? Report: conducted power analysis estimate minimum required sample size evaluate superiority new drug treating generalized anxiety disorder compared standard treatment. analysis focused proportion patients requiring rescue medication, assuming prevalence rate 50% standard treatment group 45% new drug group. Using least 1% decrease superiority margin, one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 1,926 participants per group (3,852 total) required. Accounting 5% attrition rate, total sample size increases 4,055 participants.","code":"power.z.twoprops(prob1 = 0.45,                  prob2 = 0.50,                  margin = -0.01,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 >= margin  #>   H1 (Alt. Claim) : prob1 - prob2 < margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1926 and 1926  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # consider 5% attrition rate inflate.sample(n = 3852, rate = 0.05) #> 4055"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"twoprops-equivalence","dir":"Articles","previous_headings":"Proportions (Z-Test) > Independent Samples","what":"Equivalence","title":"Practical Power Analysis in R","text":"Example: national education ministry implements new automated scoring system evaluate high school students merit-based university scholarship program. algorithm incorporates multiple factors including GPA, standardized test scores, extracurricular activities, socio-economic indicators using complex weighting system. Despite using seemingly objective inputs, concerns algorithm’s weighting interaction effects might inadvertently favor one gender another - example, system overweights certain activities traditionally dominated one gender, interaction effects variables create unexpected biases. concerns algorithmic bias composite scoring methodology, ministry wants eligibility rates (eligible vs. eligible) scholarship must remain equivalent across male female students. disparity greater ±\\pm 1% eligibility rates flagged potential violation gender equity policy. equivalence trial conducted determine whether new automated scoring system produces statistically equivalent scholarship eligibility rates male female students. standard, human-rated system yields eligibility rates approximately 10% groups. evaluate equivalence, analysis uses two one-sided test 0.05 significance level 0.80 power. minimum required number applications process per group test equivalence conditions? Report: conducted power analysis estimate minimum required sample size evaluate whether new automated scoring system yields scholarship eligibility rates statistically equivalent male female students. analysis assumed baseline eligibility rate 10% groups standard rater-based system. Using equivalence margin ±\\pm 5%, two one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 3,854 applications processed per group (7,708 total).","code":"power.z.twoprops(prob1 = 0.10,                  prob2 = 0.10,                  margin = c(-0.02, 0.02),                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= min(margin) or  #>                     prob1 - prob2 >= max(margin)  #>   H1 (Alt. Claim) : prob1 - prob2 > min(margin) and  #>                     prob1 - prob2 < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 3854 and 3854  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"minimum-effect-2","dir":"Articles","previous_headings":"Proportions (Z-Test) > Independent Samples","what":"Minimum Effect","title":"Practical Power Analysis in R","text":"Example: Consider earlier example evaluates whether new automated scoring system yields scholarship eligibility rates statistically equivalent male female students. research team establishes gender difference eligibility rates greater ±\\pm 3% constitute meaningful disparity requiring algorithmic adjustment. establish equivalence bounds ±\\pm 1% eligibility rates - threshold considered smallest practically important effect warrants monitoring potential intervention. minimal effect test conducted check whether system produces gender difference least 1% either direction. Using two one-sided test 0.05 significance level, 0.80 power, minimum required number complete applications process? Report: conducted power analysis estimate minimum required number complete scholarship applications evaluate whether new automated scoring system results gender difference 3% eligibility rates (13% females 10% males). Using equivalence bounds ±\\pm 1%, two one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 3,992 applications processed per group (7,984 total).","code":"power.z.twoprops(prob1 = 0.13,                  prob2 = 0.10,                  margin = c(-0.01, 0.01),                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 >= min(margin) and  #>                     prob1 - prob2 <= max(margin)  #>   H1 (Alt. Claim) : prob1 - prob2 < min(margin) or  #>                     prob1 - prob2 > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 3992 and 3992  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"twoprops-paired-approx","dir":"Articles","previous_headings":"Proportions (Z-Test) > Paired Samples","what":"Approximate","title":"Practical Power Analysis in R","text":"Example: Colorectal cancer screening recommended adults aged 50-74 part routine preventive care. Traditionally, eligible individuals invited primary care clinics complete fecal immuno-chemical test (FIT), non-invasive screening tool early detection colorectal cancer. However, historical administrative records show 40% invited individuals complete test -clinic invitation model. improve public health outcomes, regional health authority piloting new outreach program FIT kits mailed directly individuals’ homes, removing need schedule attend clinic visit. Researchers recruit new sample 50- 74-year-olds receive -home kits compare screening completion rate 40% baseline rate administrative data. new group (receiving mailed FIT kits) matched historical administrative cohort (invited -clinic screening) based key demographic clinical characteristics available health records, binary outcome screening completion (yes / ). aim evaluate whether -home kit significantly improves uptake, expected 10% increase (40% 50%). two-sided test, α\\alpha = 0.05, 0.80 power planned estimate minimum required sample size newly recruited group. Report: conducted power analysis estimate minimum required sample size evaluate whether new -home screening strategy improves colorectal cancer screening completion among adults aged 50-74, compared historical -clinic invitation data. Administrative records show approximately 40% eligible individuals completed screening standard model. intervention aims improve rate least 10 percentage points, reaching 50% completion. Using two-sided test 0.05 significance level, 0.80 power, analysis indicates minimum 200 participants need matched.","code":"power.z.twoprops(prob1 = 0.50,                  prob2 = 0.40,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  paired = TRUE,                  rho.paired = 0.50) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Paired Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob10 - prob01 = 0 #>   H1 (Alt. Claim) : prob10 - prob01 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Paired Sample Size   = 200  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.196 #>   Statistical Power    = 0.804"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"exact-mcnemar","dir":"Articles","previous_headings":"Proportions (Z-Test) > Paired Samples","what":"Exact (McNemar)","title":"Practical Power Analysis in R","text":"Consider earlier example evaluates new outreach program increase colorectal cancer screening rates via mailing FIT kits directly individuals’ homes instead inviting clinic. Instead relying normal approximation hypothesis testing, researchers use exact McNemar’s test. parameters remain unchanged; however, additional 13 subjects need matched maintain desired power.","code":"power.exact.twoprops(prob1 = 0.50,                      prob2 = 0.40,                      power = 0.80,                      alpha = 0.05,                      alternative = \"two.sided\",                      paired = TRUE,                      rho.paired = 0.50) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Paired Proportions #>  #>   Method          : McNemar's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob10 - prob01 = 0 #>   H1 (Alt. Claim) : prob10 - prob01 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Paired Sample Size   = 213  << #>   Type 1 Error (alpha) = 0.030 #>   Type 2 Error (beta)  = 0.195 #>   Statistical Power    = 0.805"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-sample-1","dir":"Articles","previous_headings":"Correlations (Z-Test)","what":"One-Sample","title":"Practical Power Analysis in R","text":"Example: university counseling center interested understanding relationship students’ self-reported sleep quality levels academic stress. Prior research suggests weak associations, center believes relationship may stronger population due increased course loads reduced access support services. plan test whether Pearson correlation sleep quality scores academic stress scores significantly greater 0.10, define minimum meaningful effect size. Researchers define difference expected correlation (0.20) benchmark value (0.10) minimum meaningful effect size warrants attention. plan one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis estimate minimum required sample size evaluating whether correlation academic stress sleep disturbance among university students meaningfully greater benchmark value. Researchers identified correlation 0.20 theoretically relevant set minimum meaningful difference 0.10, using 0.10 benchmark. one-sided test significance level 0.05 0.80 power planned. analysis indicated minimum 593 students sufficient.","code":"power.z.onecor(rho = 0.20,                null.rho = 0.10,                power = 0.80,                alpha = 0.05,                alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-Sample Correlation  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho -  null.rho <= 0 #>   H1 (Alt. Claim) : rho -  null.rho > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 593  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"independent-samples-1","dir":"Articles","previous_headings":"Correlations (Z-Test)","what":"Independent Samples","title":"Practical Power Analysis in R","text":"example compares two approaches:  Example: research team examining whether association parental support academic achievement stronger low socio-economic status (SES) schools compared high-SES schools. confirmed, intend recommend targeted interventions enhance parental involvement specifically low-SES settings. determine required sample size, researchers anticipate small meaningful difference two correlations. consider minimum meaningful difference 0.10 - representing difference correlation 0 0.10 worst-case scenario - corresponds small effect size (Cohen’s q = 0.10). Researchers plan use one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis estimate minimum required sample size evaluating whether correlation parental support academic achievement meaningfully stronger low socio-economic status (SES) schools compared high-SES schools. reflect conservative scenario, considered minimum meaningful increase correlation 0 0.10, representing small effect size (Cohen’s q = 0.10). analysis assumed one-sided test significance level 0.05 statistical power 0.80. Results indicated data collected least 1,232 students (parents) SES group, totaling 2,464 participants.","code":"# z-test approach power.z.twocors(rho1 = 0.20, rho2 = 0.10, power = .80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Correlations  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho1 - rho2 = 0 #>   H1 (Alt. Claim) : rho1 - rho2 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1501 and 1501  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # find Cohen's q cors.to.q(rho1 = 0.20, rho2 = 0.10) #>         q     delta      rho1      rho2  #> 0.1023972 0.1000000 0.2000000 0.1000000  # t-test approach power.t.student(d = 0.1023972, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1499 and 1499  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 power.z.twocors(rho1 = 0.10,                 rho2 = 0,                 power = .80,                 alpha = 0.05,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Correlations  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho1 - rho2 <= 0 #>   H1 (Alt. Claim) : rho1 - rho2 > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1232 and 1232  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # calculate Cohen's h cors.to.q(rho1 = 0.10, rho2 = 0) #>         q     delta      rho1      rho2  #> 0.1003353 0.1000000 0.1000000 0.0000000  # t-test approximation power.t.student(d = 0.1003353,                 power = .80,                 alpha = 0.05,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= 0  #>   H1 (Alt. Claim) : d - null.d > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1229 and 1229  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-common-index","dir":"Articles","previous_headings":"Correlations (Z-Test) > Paired Samples","what":"One Common Index","title":"Practical Power Analysis in R","text":"Example: research team investigates whether school-based parental engagement program can reduce impact socio-economic status (SES) academic achievement. Using pre-test post-test scores, compare correlation SES achievement intervention. power analysis conducted detect small meaningful change (Cohen’s q = 0.10) strength correlations. post-intervention correlation weaker, suggests program effectively mitigates SES-related disparities. Several meta-analyses found moderate positive correlation SES academic achievement (rho12 = 0.30). reduction 0.30 0.20 meaningful warrants attention (rho13 = 0.30). Also based prior meta-analytic findings, common observe correlation 0.70 pre-test post-test achievement scores (rho23 = 0.30). Researchers plan use one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis determine minimum sample size required detect meaningful reduction correlation SES academic achievement following parental engagement intervention. Based prior meta-analyses, correlation SES academic achievement assumed ρ12\\rho_{12} = 0.30 pre-test, post-test correlation ρ13\\rho_{13} = 0.20 representing meaningful reduction (Cohen’s q = 0.126). correlation pre-test post-test scores assumed ρ23\\rho_{23} = -0.70. analysis uses one-sided Steiger’s Z test compare dependent correlations, significance level 0.05 statistical power 0.80. assumptions, minimum required sample size 286 students. account anticipated 5% attrition rate, additional 16 students included, bringing total target sample size 302 students.","code":"# example data for one common index # compare cor(V1, V2) to cor(V1, V3)  # subject    V1       V2      V3 # <int>    <dbl>    <dbl>    <dbl> #   1       1.2      2.3      0.8 #   2      -0.0      1.1      0.7 #   3       1.9     -0.4     -2.3 #   4       0.7      1.3      0.4 #   5       2.1     -0.1      0.8 #   ...     ...      ...      ... #   1000   -0.5      2.7     -1.7  # V1: socio-economic status (common) # V2: pre-test # V3: post-test  power.z.twocors.steiger(rho12 = 0.50,                         rho13 = 0.40,                         rho23 = 0.70,                         power = 0.80,                         alpha = 0.05,                         alternative = \"one.sided\",                         common.index = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Dependent Correlations #>  #>   Common Index    : TRUE #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho12 - rho13 <= 0 #>   H1 (Alt. Claim) : rho12 - rho13 > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 286  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # calculate the effect size cors.to.q(rho1 = 0.40, rho2 = 0.50) #>          q      delta       rho1       rho2  #> -0.1256572 -0.1000000  0.4000000  0.5000000  # adjust the sample for 5% attrition rate inflate.sample(n = 286, rate = 0.05) #> 302"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"no-common-index","dir":"Articles","previous_headings":"Correlations (Z-Test) > Paired Samples","what":"No Common Index","title":"Practical Power Analysis in R","text":"Example: research team investigates whether teaching students meta-cognitive strategies reading transferable math domain. expect increase correlation reading math scores pre-test post-test following intervention involving activities related meta-cognition. Based meta-analytic findings, typical correlation reading math around 0.50. team considers increase rho12 = 0.50 rho34 = 0.60 meaningful relevant, corresponding Cohen’s q = 0.144. increase average reading math scores, along stronger post-test correlation reading math, suggest meta-cognitive strategies targeted reading transferable math domain. Researchers also assume correlation pre-test post-test reading rho13 = 0.70, correlation pre-test post-test math rho24 = 0.70, correlation pre-test reading post-test math rho14 = 0.40, correlation pre-test math post-test reading rho23 = 0.40. Researchers plan use one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis determine minimum sample size required detect meaningful increase correlation reading math performance following intervention involving meta-cognitive strategy instruction reading. Based prior meta-analyses, correlation reading math scores assumed ρ12=0.50\\rho_{12} = 0.50 pre-test, post-test correlation ρ34=0.60\\rho_{34} = 0.60 representing meaningful increase (Cohen’s q=0.144q = 0.144). analysis also incorporates following assumed correlations: ρ13=0.70\\rho_{13} = 0.70 (pre-test reading - post-test reading), ρ24=0.70\\rho_{24} = 0.70 (pre-test math - post-test math), ρ14=0.40\\rho_{14} = 0.40 (pre-test reading - post-test math), ρ23=0.40\\rho_{23} = 0.40 (pre-test math - post-test reading). analysis uses one-sided Steiger’s Z test compare dependent correlations, significance level 0.05 statistical power 0.80. assumptions, minimum required sample size 317 students. account anticipated 5% attrition rate, additional 17 students included, bringing total target sample size 334 students.","code":"# example data for no common index # compare cor(V1, V2) to cor(V3, V4)  # subject    V1       V2       V3       V4 # <int>    <dbl>    <dbl>    <dbl>    <dbl> #   1       1.2      2.3      0.8      1.2 #   2      -0.0      1.1      0.7      0.9 #   3       1.9     -0.4     -2.3     -0.1 #   4       0.7      1.3      0.4     -0.3 #   5       2.1     -0.1      0.8      2.7 #   ...     ...      ...      ...      ... #   1000   -0.5      2.7     -1.7      0.8  # V1: pre-test reading # V2: pre-test math # V3: post-test reading # V4: post-test math  power.z.twocors.steiger(rho12 = 0.50, # cor(V1, V2)                         rho13 = 0.70,                         rho23 = 0.40,                         rho14 = 0.40,                         rho24 = 0.70,                         rho34 = 0.60, # cor(V3, V4)                         power = 0.80,                         alpha = 0.05,                         alternative = \"one.sided\",                         common.index = FALSE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Dependent Correlations #>  #>   Common Index    : FALSE #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho12 - rho34 >= 0 #>   H1 (Alt. Claim) : rho12 - rho34 < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 317  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # calculate the effect size cors.to.q(rho1 = 0.60, rho2 = 0.50) #>        q    delta     rho1     rho2  #> 0.143841 0.100000 0.600000 0.500000  # adjust the sample for 5% attrition rate inflate.sample(n = 317, rate = 0.05) #> 334"},{"path":[]},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"reg-f-test","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Omnibus F-Test","what":"R2>0R^2 > 0","title":"Practical Power Analysis in R","text":"omnibus F-test multiple linear regression used evaluate whether model whole explains statistically significant portion variance outcome variable. null hypothesis states regression coefficients (except intercept) equal zero means none predictors contributes meaningfully explaining outcome variable (R2R^2 equal zero). Alternative hypothesis states least regression coefficients (except intercept) different zero (R2R^2 greater zero). Example: Assume want predict continuous variable YY using X1X_{1}, X2X_{2}, X2X_{2} variables (can combination binary continuous). Y=β0+β1X1+β2X2+β3X3+r,r∼N(0,σ2)Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + r, \\quad r \\sim N(0, \\sigma ^ 2) interested minimum R2R^2 = 0.10. minimum required sample size? Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY three predictors (X1X_{1}, X2X_{2}, X3X_{3}). interested effect small R2=0.10R^2 = 0.10 using omnibus F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. assumptions, minimum required sample size 103 participants.","code":"power.f.regression(r.squared = 0.10,                    k.total = 3, # number of total predictors                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : R-squared = 0  #>   H1 (Alt. Claim) : R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 103  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.196 #>   Statistical Power    = 0.804"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"r2-margin","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Omnibus F-Test","what":"R2R^2 > Margin","title":"Practical Power Analysis in R","text":"Example: Consider earlier example. Now, instead testing zero null hypothesis (.e., R2R^2 = 0), aim set practical null hypothesis R2R^2 0.05 (margin = 0.05), representing largest effect size considered practically null. minimum required sample size conditions? Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY three predictors (X1X_{1}, X2X_{2}, X3X_{3}). interested effect small R2R^2 = 0.10 using omnibus F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. R2R^2 < 0.05 considered negligible practical significance. assumptions, minimum required sample size 612 participants.","code":"power.f.regression(r.squared = 0.10,                    margin = 0.05,                    k.total = 3,                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= R-squared <= margin  #>   H1 (Alt. Claim) : R-squared > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 612  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"reg-f-test-rsq-change","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Omnibus F-Test","what":"ΔR2\\Delta R^2 > 0","title":"Practical Power Analysis in R","text":"Example: Assume want test incremental contribution two additional predictors (X4X_{4} X5X_{5}) existing regression model. , testing whether adding two predictors (k.tested = 2) results significant increase explained variance. full model includes five predictors total (k.total = 5). interested detecting meaningful increase explained variance ΔR2=0.10\\Delta R^2 = 0.10. minimum required sample size criteria? Y=β0+β1X1+β2X2+β3X3+β4X4+β5X5+r,r∼N(0,σ2) Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + \\beta_{4}X_{4} + \\beta_{5}X_{5} + r, \\quad r \\sim N(0, \\sigma ^ 2) Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY five predictors (X1X_{1} X5X_{5}). primary interest testing incremental contribution two predictors (X4X_{4} X5X_{5}), beyond initial model includes X1X_{1}, X2X_{2}, X3X_{3}. Specifically, aim detect increase explained variance ΔR2=0.10\\Delta R^2 = 0.10 using F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. total number predictors final model five (k.total = 5), number predictors tested two (k.tested = 2). assumptions, minimum required sample size 90 participants.","code":"power.f.regression(r.squared.change = 0.10,                    k.total = 5, # number of total predictors                    k.tested = 2, # number of tested predictors                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Hierarchical Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Change in R-squared = 0  #>   H1 (Alt. Claim) : Change in R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 90  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"delta-r2-margin","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Omnibus F-Test","what":"ΔR2\\Delta R^2 > Margin","title":"Practical Power Analysis in R","text":"Example: Consider earlier example. Now, instead testing zero null hypothesis (.e., ΔR2\\Delta R^2 = 0), aim set practical null hypothesis ΔR2\\Delta R^2 0.05 (margin = 0.05), representing largest effect size considered practically null. minimum required sample size conditions? Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY five predictors (X1X_{1} X5X_{5}). specific interest lies testing incremental contribution two predictors (X4X_{4} X5X_{5}) beyond initial model containing three predictors (X1X_{1}, X2X_{2}, X3X_{3}). interested detecting increase explained variance ΔR2=0.10\\Delta R^2 = 0.10 using F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. ΔR2\\Delta R^2 less 0.05 considered negligible practical significance. assumptions, minimum required sample size 606 participants.","code":"power.f.regression(r.squared.change = 0.10,                    margin = 0.05,                    k.total = 5, # number of total predictors                    k.tested = 2, # number of tested predictors                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Hierarchical Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= Change in R-squared <= margin  #>   H1 (Alt. Claim) : Change in R-squared > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 606  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"standardized-input","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Single Coefficient (T-Test)","what":"Standardized Input","title":"Practical Power Analysis in R","text":"earlier example, assume want predict continuous variable YY using continuous predictor X1X_{1} control X2X_{2}, X2X_{2} variables (can combination binary continuous). mainly interested effect X1X_{1} expect standardized regression coefficient β1=0.20\\beta_{1} = 0.20. Y=β0+β1X1+β2X2+β3X3+r,r∼N(0,σ2) Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + r, \\quad r \\sim N(0, \\sigma ^ 2) , expecting three variables explain 30% variance outcome (R2=0.30R^2 = 0.30). minimum required sample size? sufficient provide standardized regression coefficient beta sd.predictor = 1 sd.outcome = 1 default.","code":"power.t.regression(beta = 0.20,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 140  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.198 #>   Statistical Power      = 0.802"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"unstandardized-input","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Single Coefficient (T-Test)","what":"Unstandardized Input","title":"Practical Power Analysis in R","text":"unstandardized coefficients specify sd.outcome sd.predictor. Assume expecting unstandardized regression coefficient beta = 0.60, standard deviation sd.outcome = 12 outcome standard deviation sd.predictor = 4 main predictor. minimum required sample size? main predictor binary (e.g. treatment / control), standardized regression coefficient Cohen’s d. Standard deviation main predictor p(1−p)\\sqrt{p(1-p)} p proportion sample one groups. Assume half sample first group p=0.50p = 0.50. minimum required sample size? sufficient provide Cohen’s d beta (standardized difference two groups) specify sd.predictor = sqrt(p * (1 - p)) p proportion subjects one groups.","code":"power.t.regression(beta = 0.60,                    sd.outcome = 12,                    sd.predictor = 4,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 140  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.198 #>   Statistical Power      = 0.802 p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 552  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"non-inferiority-2","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Single Coefficient (T-Test)","what":"Non-inferiority","title":"Practical Power Analysis in R","text":"intervention expected non-inferior earlier interventions. Assume effect earlier intervention beta = 0.10. beta - null.beta expected positive least -0.05 (margin = -0.05). minimum required sample size?","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    null.beta = 0.10,                    margin = -0.05,                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= margin  #>   H1 (Alt. Claim) : beta - null.beta >  margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 770  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"superiority-2","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Single Coefficient (T-Test)","what":"Superiority","title":"Practical Power Analysis in R","text":"intervention expected superior earlier interventions. Assume effect earlier intervention beta = 0.10. beta - null.beta expected positive least 0.05 (margin = 0.05). minimum required sample size?","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    null.beta = 0.10,                    margin = 0.05,                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= margin  #>   H1 (Alt. Claim) : beta - null.beta >  margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 6934  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"equivalence-3","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Single Coefficient (T-Test)","what":"Equivalence","title":"Practical Power Analysis in R","text":"intervention expected equivalent earlier interventions. Assume effect earlier intervention beta = 0.20. beta - null.beta expected within -0.05 0.05 (margin = c(-0.05, 0.05)). minimum required sample size?","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    null.beta = 0.20,                    margin = c(-0.05, 0.05),                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= min(margin) or  #>                     beta - null.beta >= max(margin)  #>   H1 (Alt. Claim) : beta - null.beta > min(margin) and  #>                     beta - null.beta < max(margin) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 9593  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"minimum-effect-3","dir":"Articles","previous_headings":"Regression: Linear (F- and T-Test) > Single Coefficient (T-Test)","what":"Minimum Effect","title":"Practical Power Analysis in R","text":"intervention effect expected different smallest value matters policy practice. beta - null.beta expected less -0.05 greater 0.05 (margin = c(-0.05, 0.05)). minimum required sample size?","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    margin = c(-0.05, 0.05),                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta >= min(margin) and  #>                     beta - null.beta <= max(margin)  #>   H1 (Alt. Claim) : beta - null.beta < min(margin) or  #>                     beta - null.beta > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 981  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"regression-logistic-walds-z-test","dir":"Articles","previous_headings":"","what":"Regression: Logistic (Wald’s Z-Test)","title":"Practical Power Analysis in R","text":"logistic regression binary outcome variable (0 / 1: failure / success, dead / alive, absent / present) modeled predicting probability group 1 (P1P_1) via logit transformation (natural logarithm odds). base probability P0P_0 overall probability group 1 without influence predictors model (null). alternative hypothesis, probability group 1 (P1P_1) deviate P0P_0 depending value predictor; whereas null P0P_0. model one main predictor (X1X_1) two covariates (X2X_2 X3X_3) can constructed ln(P11−P1)=β0+β1X1+β2X2+β3X3ln(\\frac{P_1}{1 - P_1}) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} β0=ln(P01−P0)\\beta_0 = ln(\\frac{P_0}{1 - P_0})β1=ln(P11−P1/P01−P0)\\beta_1 = ln(\\frac{P_1}{1 - P_1} / \\frac{P_0}{1 - P_0}) Odds ratio defined =exp(β1)=P11−P1/P01−P0OR = exp(\\beta_1) = \\frac{P_1}{1 - P_1} / \\frac{P_0}{1 - P_0} Example: Assume squared multiple correlation 0.20 X1X_1 covariates (r2..x = 0.20 code). can found form adjusted R-square via regressing X1X_1 X2X_2 X3X_3. Higher values require larger sample sizes. default 0 (zero). base probability P0=0.15P_0 = 0.15. rate predictor X1=0X_1 = 0 β1=0\\beta_1 = 0. Increasing X1X_1 0 1 reduces probability group 1 0.15 0.10 (P1=0.10P_1 = 0.10). minimum required sample size? three types specification statistical power sample size calculations; () probability specification, (ii) odds ratio specification, (iii) regression coefficient specification (standard software output).","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"probability-specification","dir":"Articles","previous_headings":"Regression: Logistic (Wald’s Z-Test)","what":"Probability Specification","title":"Practical Power Analysis in R","text":"","code":"power.z.logistic(prob = 0.10,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 365  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"odds-ratio-specification","dir":"Articles","previous_headings":"Regression: Logistic (Wald’s Z-Test)","what":"Odds Ratio Specification","title":"Practical Power Analysis in R","text":"=P11−P1/P01−P0=0.101−0.10/0.151−0.15=0.6296OR = \\frac{P_1}{1 - P1} / \\frac{P_0}{1 - P_0} = \\frac{0.10}{1 - 0.10} / \\frac{0.15}{1 - 0.15} = 0.6296","code":"power.z.logistic(odds.ratio = 0.6296,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 365  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"regression-coefficient","dir":"Articles","previous_headings":"Regression: Logistic (Wald’s Z-Test)","what":"Regression Coefficient","title":"Practical Power Analysis in R","text":"β1=ln(P11−P1/P01−P0)=ln(0.6296)=−0.4626\\beta_1 = ln(\\frac{P_1}{1 - P1} / \\frac{P_0}{1 - P_0}) = ln(0.6296) = -0.4626","code":"power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 365  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"change-distribution","dir":"Articles","previous_headings":"Regression: Logistic (Wald’s Z-Test)","what":"Change Distribution","title":"Practical Power Analysis in R","text":"Change distribution parameters predictor X: mean standard deviation normally distributed main predictor 0 1 default. can modified. following example mean 20 standard deviation 8. Change distribution family predictor X: distribution types supported function. example, main predictor can binary (e.g. treatment / control groups). Often half sample assigned treatment group half control (prob = 0.50 default). Change treatment group allocation rate binary predictor X (prob = 0.40): per-subject cost treatment group sometimes substantially higher per-subject cost control group. times, difficult recruit subjects treatment whereas plenty subjects considered control group (e.g. long wait-list). cases leeway pick unbalanced sample (much unbalanced). Assume treatment group allocation rate 40%. minimum required sample size?","code":"distribution <- list(dist = \"normal\", mean = 20, sd = 8)  power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 591  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"bernoulli\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1723  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 distribution <- list(dist = \"bernoulli\", prob = 0.40)  power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1826  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"regression-poisson-walds-z-test","dir":"Articles","previous_headings":"","what":"Regression: Poisson (Wald’s Z-Test)","title":"Practical Power Analysis in R","text":"Poisson regression count outcome variable (e.g. number hospital / store / website visits, number absence / dead / purchase day / week / month) modeled predicting incidence rate (λ\\lambda) via logarithmic transformation (natural logarithm rates). model one main predictor (X1X_1) two covariates (X2X_2 X3X_3) can constructed ln(λ)=β0+β1X1+β2X2+β3X3 ln(\\lambda) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} exp(β0)exp(\\beta_0) base incidence rate. β1=ln(λ(X1=1)λ(X1=0))\\beta_1 = ln(\\frac{\\lambda(X_1=1)}{\\lambda(X_1=0)}) Incidence rate ratio defined exp(β1)=λ(X1=1)λ(X1=0)exp(\\beta_1) = \\frac{\\lambda(X_1=1)}{\\lambda(X_1=0)} Assume expected base incidence rate 1.65: exp(0.50)=1.65exp(0.50) = 1.65. Increasing X1X_1 0 1 reduces mean incidence rate 1.65 0.905: exp(−0.10)=0.905exp(-0.10) = 0.905. minimum required sample size? two types specification; () rate ratio specification (exponentiated regression coefficient), (ii) raw regression coefficient specification (standard software output).","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"regression-coefficient-1","dir":"Articles","previous_headings":"Regression: Poisson (Wald’s Z-Test)","what":"Regression Coefficient","title":"Practical Power Analysis in R","text":"","code":"power.z.poisson(beta0 = 0.50,                 beta1 = -0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 474  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"rate-ratio-specification","dir":"Articles","previous_headings":"Regression: Poisson (Wald’s Z-Test)","what":"Rate Ratio Specification","title":"Practical Power Analysis in R","text":"","code":"power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 474  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"change-distribution-1","dir":"Articles","previous_headings":"Regression: Poisson (Wald’s Z-Test)","what":"Change Distribution","title":"Practical Power Analysis in R","text":"Change distribution’s parameters predictor X: function accommodates types distribution. example, main predictor can binary (e.g. treatment / control groups). Change treatment group allocation rate binary predictor X (prob = 0.40):","code":"distribution <- list(dist = \"normal\", mean = 20, sd = 8)  power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 40  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = \"bernoulli\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2003  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 distribution <- list(dist = \"bernoulli\", prob = 0.40)  power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2095  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"regression-mediation-z-test","dir":"Articles","previous_headings":"","what":"Regression: Mediation (Z-Test)","title":"Practical Power Analysis in R","text":"simple mediation model can constructed figure. Regression models take form M=β0M+βaX+eY=β0Y+βbM+βcpX+ϵ \\begin{eqnarray} M & = & \\beta_{0M} + \\beta_{} X + e \\\\ Y & = & \\beta_{0Y} + \\beta_{b} M + \\beta_{cp} X + \\epsilon \\end{eqnarray} Y outcome, M mediator, X main predictor. indirect effect product βa\\beta_a βb\\beta_b path coefficients. βcp\\beta_{cp} path coefficient direct effect. Path coefficients can standardized unstandardized. presumed standardized default main predictor, mediator, outcome standard deviations sd.predictor = 1, sd.mediator = 1, sd.outcome = 1 function. Standard deviations specified unstandardized path coefficients (can find values descriptive tables reports / publications).","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"continuous-predictor","dir":"Articles","previous_headings":"Regression: Mediation (Z-Test)","what":"Continuous Predictor","title":"Practical Power Analysis in R","text":"software applications presume covariates mediator outcome models (RM2=0R^2_M = 0 RM2=0R^2_M = 0). Even covariates, X explain variance M (RM2>0R^2_M > 0) M & X explains variance Y (RY2>0R^2_Y > 0). almost never R-squared value 0 (zero). explained variance basic mediation model (base R-squared values) can non-trivial taken account function default. Thus, results may seem different software outputs. match results software packages, explicitly specify parameters 0 (zero) (r.squared.mediator = 0 r.squared.outcome = 0). warnings indicating function expects R-squared values greater base R-squared value. Note case beta.cp argument ignored.","code":"# mediation model with base R-squared values power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 244  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801 # base R-squared values are 0 (zero) # do not specify 'cp' power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   r.squared.mediator = 0,                   r.squared.outcome = 0,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 252  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"binary-predictor","dir":"Articles","previous_headings":"Regression: Mediation (Z-Test)","what":"Binary Predictor","title":"Practical Power Analysis in R","text":"case main predictor binary can useful practice. researcher might interested whether treatment influence outcome mediators.","code":"p <- 0.50 # proportion of subjects in one of the groups sd.predictor <- sqrt(p * (1 - p))  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 615  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"joint-and-monte-carlo","dir":"Articles","previous_headings":"Regression: Mediation (Z-Test)","what":"Joint and Monte Carlo","title":"Practical Power Analysis in R","text":"Joint Monte Carlo tests available power requested.","code":"# binary X p <- 0.50 # proportion of subjects in one of the groups sd.predictor <- sqrt(p * (1 - p))  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   n = 300,                   alpha = 0.05,                   method = \"joint\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Joint #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 300 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.416 #>   Statistical Power    = 0.584  <<  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   n = 300,                   alpha = 0.05,                   method = \"monte.carlo\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Monte Carlo #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 300 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.415 #>   Statistical Power    = 0.585  <<"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"covariate-adjustment","dir":"Articles","previous_headings":"Regression: Mediation (Z-Test)","what":"Covariate Adjustment","title":"Practical Power Analysis in R","text":"Covariates can added mediator model, outcome model, . Explanatory power covariates (R-squared values) mediator outcome models can specified via r.squared.mediator r.squared.outcome arguments. experimental design subjects randomly assigned treatment control groups. allocation usually takes place rate 50% (probability 0.50) meaning half sample assigned treatment half control. Thus, mediator model less likely confounder. common add covariates outcome model .","code":"# continuous X power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   r.squared.mediator = 0.50,                   r.squared.outcome = 0.50,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 189  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801 # binary X p <- 0.50 # proportion of subjects in one of the groups sd.predictor <- sqrt(p * (1 - p))  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   r.squared.outcome = 0.50,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 559  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"anova-f-test","dir":"Articles","previous_headings":"","what":"ANOVA (F-Test)","title":"Practical Power Analysis in R","text":"one-way ANOVA, researcher might interested comparing means several groups (levels factor) respect continuous variable. one-way ANCOVA, may want adjust means covariates. Furthermore, may want inspect interaction two three factors (two-way three-way ANOVA), adjust interaction covariates (two-way three-way ANCOVA). following examples illustrate determine minimum required sample size designs.","code":""},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-way","dir":"Articles","previous_headings":"ANOVA (F-Test) > Effect Size as Input","what":"One-way","title":"Practical Power Analysis in R","text":"researcher expecting difference Cohen’s d = 0.50 treatment control groups (two levels) translating η2=0.059\\eta^2 = 0.059 (eta.squared = 0.059). Means adjusted covariates. minimum required sample size?","code":"power.f.ancova(eta.squared = 0.059,                factor.levels = 2,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"two-way","dir":"Articles","previous_headings":"ANOVA (F-Test) > Effect Size as Input","what":"Two-way","title":"Practical Power Analysis in R","text":"researcher expecting partial η2=0.03\\eta^2 = 0.03 (eta.squared = 0.03) interaction treatment / control (Factor : two levels) gender (Factor B: two levels). Thus, factor.levels = c(2,2). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.03,                factor.levels = c(2, 2),                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 256  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"three-way","dir":"Articles","previous_headings":"ANOVA (F-Test) > Effect Size as Input","what":"Three-way","title":"Practical Power Analysis in R","text":"researcher expecting partial η2=0.02\\eta^2 = 0.02 (eta.squared = 0.02) interaction treatment / control (Factor : two levels), gender (Factor B: two levels), socio-economic status (Factor C: three levels). Thus, factor.levels = c(2, 2, 3). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.02,                factor.levels = c(2, 2, 3),                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Three-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 480  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"practical-effects","dir":"Articles","previous_headings":"ANOVA (F-Test) > Effect Size as Input","what":"Practical Effects","title":"Practical Power Analysis in R","text":"smallest effect size interest policy practice may differ zero. example, want test whether η2=0.02\\eta^2 = 0.02 meaningfully different null value ηNull2=0.01\\eta^2_{\\text{Null}} = 0.01, can specify null.eta.squared = 0.01.","code":"power.f.ancova(eta.squared = 0.02,                null.eta.squared = 0.01,                factor.levels = c(2, 2, 3),                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Three-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= eta.squared <= null.eta.squared  #>   H1 (Alt. Claim) : eta.squared > null.eta.squared #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 3516  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"means-and-sds-as-input","dir":"Articles","previous_headings":"ANOVA (F-Test)","what":"Means and SDs as Input","title":"Practical Power Analysis in R","text":"researcher expecting difference Cohen’s d = 0.50 treatment control groups (two levels) translating η2=0.059\\eta^2 = 0.059, earlier example. Means standard deviations adjusted covariates. minimum required sample size? NOTE: Keppel procedure allows one-way ANOVA.","code":"power.f.ancova.keppel(mu.vector = c(0.50, 0), # vector of means                       sd.vector = c(1, 1), # vector of standard deviations                       p.vector = c(0.50, 0.50), # sample allocation rates                       power = 0.80,                       alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"anova-mixed-effects-f-test","dir":"Articles","previous_headings":"","what":"ANOVA: Mixed-Effects (F-Test)","title":"Practical Power Analysis in R","text":"group () effect: researcher might interested comparing means several groups (levels factor) respect outcome variable (continuous) controlling effect time. time effect can thought improvement / grow / loss / deterioration outcome variable happens naturally due unknown causes. time (within) effect: researcher might interested comparing means several time points respect outcome variable controlling group effect. words, change across time points due group membership due improvement / grow / loss / deterioration outcome variable happens naturally due unknown causes. group x time interaction: researcher might suspect means across groups means across time points independent . amount improvement / grow / loss / deterioration outcome variable depends group membership.","code":""},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"group-effect-between","dir":"Articles","previous_headings":"ANOVA: Mixed-Effects (F-Test)","what":"Group Effect (Between)","title":"Practical Power Analysis in R","text":"Example 1: post-test design treatment control groups. researcher expecting difference Cohen’s d = 0.50 post-test score treatment control groups, translating η2=0.059\\eta^2 = 0.059. test administered single time point; thus, number repeated measures 1. minimum required sample size?","code":"power.f.mixed.anova(eta.squared = 0.059,                     factor.levels = c(2, 1), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"time-effect-within","dir":"Articles","previous_headings":"ANOVA: Mixed-Effects (F-Test)","what":"Time Effect (Within)","title":"Practical Power Analysis in R","text":"Example 2: Pre-test vs. post-test design treatment group . researcher expecting difference Cohen’s d = 0.30 post-test pre-test scores, translating η2=0.022\\eta^2 = 0.022. test administered treatment; thus, number repeated measures 2. treatment group control group. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size?","code":"power.f.mixed.anova(eta.squared = 0.022,                     factor.levels = c(1, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"within\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Repeated Measures Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 90  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"group-x-time-interaction","dir":"Articles","previous_headings":"ANOVA: Mixed-Effects (F-Test)","what":"Group x Time Interaction","title":"Practical Power Analysis in R","text":"Example 3: Pre-test vs.post-test control-group design. researcher expecting difference Cohen’s d = 0.40 post-test scores treatment control groups controlling pre-test, translating partial η2=0.038\\eta^2 = 0.038. test administered treatment; thus, number repeated measures 2. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size? researcher expecting difference Cohen’s d = 0.30 post-test pre-test scores controlling group membership, translating partial η2=0.022\\eta^2 = 0.022. treatment control groups. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size? rationale inspecting interaction benefit treatment may depend pre-test score (e.g. higher scores pre-test improve deteriorate ). researcher expecting interaction effect partial η2=0.01\\eta^2 = 0.01. test administered treatment; thus, number repeated measures 2. treatment control groups. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size?","code":"power.f.mixed.anova(eta.squared = 0.038,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 152  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803 power.f.mixed.anova(eta.squared = 0.022,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"within\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 90  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 power.f.mixed.anova(eta.squared = 0.01,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"interaction\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 198  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"adjusted-eta-squared","dir":"Articles","previous_headings":"ANOVA: Mixed-Effects (F-Test)","what":"Adjusted Eta-squared","title":"Practical Power Analysis in R","text":"possible η2\\eta^2 already adjusted within-subject correlation. case instead using unadjusted η2=0.038\\eta^2 = 0.038 use adjusted η2=0.05\\eta^2 = 0.05 specify rho.within = NA.","code":"power.f.mixed.anova(eta.squared = 0.05,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = NA,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 152  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"practical-effects-1","dir":"Articles","previous_headings":"ANOVA: Mixed-Effects (F-Test)","what":"Practical Effects","title":"Practical Power Analysis in R","text":"smallest effect size interest policy practice may differ zero. example, want test whether η2=0.05\\eta^2 = 0.05 meaningfully different null value ηNull2=0.01\\eta^2_{\\text{Null}} = 0.01, can specify null.eta.squared = 0.01.","code":"power.f.mixed.anova(eta.squared = 0.05,                     null.eta.squared = 0.01,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = NA,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= eta.squared <= null.eta.squared  #>   H1 (Alt. Claim) : eta.squared > null.eta.squared #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 380  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":[]},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-way-1","dir":"Articles","previous_headings":"ANCOVA (F-Test) > Effect Size as Input","what":"One-way","title":"Practical Power Analysis in R","text":"researcher expecting adjusted difference Cohen’s d = 0.45 treatment control groups (factor.levels = 2) controlling pre-test (k.covariates = 1) translating partial η2=0.048\\eta^2 = 0.048. minimum required sample size?","code":"power.f.ancova(eta.squared = 0.048,                factor.levels = 2,                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 158  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"two-way-1","dir":"Articles","previous_headings":"ANCOVA (F-Test)","what":"Two-way","title":"Practical Power Analysis in R","text":"researcher expecting partial η2=0.02\\eta^2 = 0.02 interaction treatment / control (Factor ) gender (Factor B) adjusted pre-test (k.covariates = 1). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.02,                factor.levels = c(2, 2),                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 388  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"three-way-1","dir":"Articles","previous_headings":"ANCOVA (F-Test)","what":"Three-way","title":"Practical Power Analysis in R","text":"researcher expecting partial η2=0.01\\eta^2 = 0.01 interaction treatment / control (Factor ), gender (Factor B), socio-economic status (Factor C: three levels) adjusted pre-test (k.covariates = 1). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.01,                factor.levels = c(2, 2, 3),                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Three-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 960  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"practical-effects-2","dir":"Articles","previous_headings":"ANCOVA (F-Test)","what":"Practical Effects","title":"Practical Power Analysis in R","text":"smallest effect size interest policy practice may differ zero. example, want test whether η2=0.048\\eta^2 = 0.048 meaningfully different null value ηNull2=0.01\\eta^2_{\\text{Null}} = 0.01, can specify null.eta.squared = 0.01.","code":"power.f.ancova(eta.squared = 0.048,                null.eta.squared = 0.01,                factor.levels = 2,                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= eta.squared <= null.eta.squared  #>   H1 (Alt. Claim) : eta.squared > null.eta.squared #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 410  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"keppel-procedure","dir":"Articles","previous_headings":"","what":"Keppel Procedure","title":"Practical Power Analysis in R","text":"researcher expecting adjusted difference Cohen’s d = 0.318 treatment control groups controlling pre-test (k.covariates = 1) explanatory power covariates (r.squared = 0.50). translates partial η2=0.048\\eta^2 = 0.048. minimum required sample size? NOTE: Keppel procedure allows one-way ANOVA.","code":"power.f.ancova.keppel(mu.vector = c(0.318, 0), # vector of adjusted means                       sd.vector = c(1, 1), # vector of unadjusted standard deviations                       p.vector = c(0.50, 0.50), # sample allocation rates                       r.squared = 0.50,                       k.covariates = 1,                       power = 0.80,                       alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 158  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"one-way-2","dir":"Articles","previous_headings":"Shieh Procedure","what":"One-way","title":"Practical Power Analysis in R","text":"researcher expecting adjusted difference Cohen’s d = 0.318 treatment control groups controlling pre-test (k.covariates = 1) explanatory power covariates (r.squared = 0.50). translates partial η2=0.048\\eta^2 = 0.048. minimum required sample size?","code":"power.f.ancova.shieh(mu.vector = c(0.318, 0), # vector of adjusted means                       sd.vector = c(1, 1), # vector of unadjusted standard deviations                       p.vector = c(0.50, 0.50), # sample allocation rates                       r.squared = 0.50,                       k.covariates = 1,                       power = 0.80,                       alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 160  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.195 #>   Statistical Power      = 0.805"},{"path":"https://metinbulus.github.io/pwrss/articles/examples.html","id":"two-way-2","dir":"Articles","previous_headings":"Shieh Procedure","what":"Two-way","title":"Practical Power Analysis in R","text":"Assume cell means interaction treatment / control (Factor ) gender (Factor B) adjusted pre-test (k.covariates = 1) explanatory power covariate (r.squared = 0.50) 0.30, 0.09, 0.05, 0.245, corresponding cells A1:B1, A1:B2, A2:B1, A2:B2, respectively, unit standard deviation . translates partial η2=0.02\\eta^2 = 0.02. minimum required sample size?","code":"power.f.ancova.shieh(mu.vector = c(0.30, 0.09, 0.05, 0.245), # vector of adjusted means                      sd.vector = c(1, 1, 1, 1), # vector of unadjusted standard deviations                      p.vector = c(0.25, 0.25, 0.25, 0.25), # sample allocation rates                      factor.levels = c(2, 2),                      r.squared = 0.50,                      k.covariates = 1,                      power = 0.80,                      alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 388  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802"},{"path":"https://metinbulus.github.io/pwrss/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Metin Bulus. Author, maintainer. Sebastian Jentschke. Contributor.","code":""},{"path":"https://metinbulus.github.io/pwrss/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bulus, M., & Jentschke, S. (2025). pwrss:  Statistical Power Sample Size Calculation Tools. R package version 1.0.0. https://doi.org/10.32614/CRAN.package.pwrss","code":"@Manual{,   title = {{pwrss}: Statistical Power and Sample Size Calculation Tools},   author = {Metin Bulus and Sebastian Jentschke},   note = {R package version 1.0.0},   year = {2025},   url = {https://doi.org/10.32614/CRAN.package.pwrss}, }"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"pwrss-","dir":"","previous_headings":"","what":"Statistical Power and Sample Size Calculation Tools","title":"Statistical Power and Sample Size Calculation Tools","text":"original tutorial published CRAN can accessed : https://cran.rstudio.com/web/packages/pwrss/vignettes/examples.html  Install load pwrss R package: find package related material useful please cite : Bulus, M., & Jentschke, S. (2025). pwrss: Statistical Power Sample Size Calculation Tools. R package version 1.0.0. https://doi.org/10.32614/CRAN.package.pwrss Acknowledgments open-source project benefited users taken time report typos identify bugs. like acknowledge helped improve accuracy quality project reporting issues. missed anyone provided similar feedback, please let know. Error reports (alphabetic order):  Adrian Olszewski (bug report); Catherine (Kate) Crespi (bug report); dpnichols811 (GitHub profile) (bug report); Fred Oswald (typo report); Jarrod Hadfield (bug report); Leszek Gawarecki (typo report); Roland Thijs (typo report) Please send bug reports, feedback, questions bulusmetin [] gmail.com","code":"install.packages(\"pwrss\") library(pwrss)"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"generic","dir":"","previous_headings":"","what":"Generic","title":"Statistical Power and Sample Size Calculation Tools","text":"generic functions compute return statistical power option generate Type Type II error plots test statistics degrees freedom available. Users can input test statistics manually, valuable custom designs outside {pwrss} package’s scope, extract statistical software output. flexibility proves particularly advantageous since test statistics degrees freedom typically accessible programs like jamovi, JASP, SAS, SPSS, Stata. Power calculations can performed entering test statistic ncp mean arguments. Post-hoc power estimates derived way provide sensitivity analysis, revealing evidential strength study’s sample size relative observed effect size. approach offers valuable insights large samples, effect estimates demonstrate greater stability. However, small samples, effect size estimates exhibit higher variability, post-hoc power requires cautious interpretation.","code":""},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"post-hoc","dir":"","previous_headings":"T-Test","what":"Post-Hoc","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: mtcars dataset R contains information 32 car models 1974 issue Motor Trend magazine includes various performance design attributes vehicle. variables interest: mpg : Miles per gallon hp : Gross horsepower wt : Weight car (1000 lbs unit) aim estimate extent one-unit increase gross horsepower associated miles per gallon, controlling vehicle weight. post-hoc power given observed test statistic?  Report: post-hoc power analysis showed sample 32 cars 0.925 chance detecting observed relationship horsepower miles per gallon, relationship exists. analysis conducted using α\\alpha level 0.05.","code":"data(mtcars)  model <- lm(mpg ~ hp + wt, data = mtcars) summary(model) #>  #> Call: #> lm(formula = mpg ~ hp + wt, data = mtcars) #>  #> Residuals: #>    Min     1Q Median     3Q    Max  #> -3.941 -1.600 -0.182  1.050  5.854  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 37.22727    1.59879  23.285  < 2e-16 *** #> hp          -0.03177    0.00903  -3.519  0.00145 **  #> wt          -3.87783    0.63273  -6.129 1.12e-06 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 2.593 on 29 degrees of freedom #> Multiple R-squared:  0.8268, Adjusted R-squared:  0.8148  #> F-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12  power.t.test(ncp = -3.519, # t-value for hp variable              df = 29, # residual degrees of freedom              alpha = 0.05, # type 1 error rate              alternative = \"two.sided\",              plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp = null.ncp  #>   H1 (Alt. Claim) : ncp != null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.075 #>   Statistical Power      = 0.925  <<"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"user-defined-design","dir":"","previous_headings":"T-Test","what":"User-Defined Design","title":"Statistical Power and Sample Size Calculation Tools","text":"Power calculation readily available non-equivalent pre-test vs. post-test control-group-designs formula already known. approximate standard error SE=1−R2p(1−p)n(1−RTX2)SE = \\sqrt{\\frac{1 - R^2}{p(1 - p)n(1 - R^2_{TX})}} df=n−g−2df = n - g - 2 R2R^2 : Explanatory power covariates RTX2R^2_{TX} : Squared point-biserial correlation treatment indicator pre-test pp : Group allocation rate nn : Total sample size gg : Number covariates details please see (Bulus, 2021, p. 52; Oakes Feldman, 2001, p. 15). Example: team educational psychologists implements mindfulness-based stress-reduction program 6th-grade classrooms one middle school, 6th-grade classrooms another school continue usual homeroom activities (conventional approach). want determine whether new program yields greater improvements emotional regulation comparing students intervention school control school. students complete standardized emotional-regulation inventory start end semester. superiority test conducted assess whether improvements intervention school exceed control school meaningful margin. researcher considers medium effect relevant sufficient support potential scale-(d = 0.50) defines superiority margin 0.10 - , mindfulness program considered superior conventional program d - null.d least 0.10. Assume two classrooms school, classroom 30 students, pre-test accounts 50% variance post-test scores, squared point-biserial correlation group membership emotional regulation scores 0.10. power detect superiority criteria? Report: power analysis conducted assess whether sample 120 students sufficient detect effect mindfulness intervention emotional regulation. analysis targeted moderate effect size (d = 0.50) superiority margin 0.10, using one-tailed test α\\alpha = 0.05. design yielded estimated power 0.90, indicating adequate sensitivity detect intervention effect.","code":"# define parameters d <- 0.50 # effect size under alternative null.d <- 0 # effect size under null margin <- 0.10 # smallest meaningful diff between d and null.d  p <- 0.50 # proportion of subjects in the intervention school n <- 120 # total sample size g <- 1 # number of covariates r.squared <- 0.50 # explanatory power of covariates rtx.squared <- 0.10 # squared point-biserial cor between trt dummy and outcome  # calculate the standard error std.error <- sqrt((1 - r.squared) / (p * (1 - p) * n * (1 - rtx.squared)))  # calculate non-centrality parameters ncp <- (d - null.d) / std.error null.ncp <- margin / std.error  # calculate power power.t.test(ncp = ncp,              null.ncp = null.ncp,              df = n - g - 2,              alpha = 0.05,              alternative = \"one.sided\",              plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp <= null.ncp  #>   H1 (Alt. Claim) : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.104 #>   Statistical Power      = 0.896  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"post-hoc-1","dir":"","previous_headings":"Z-Test","what":"Post-Hoc","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: warpbreaks dataset R contains data experiment number warp breaks per loom fixed length yarn. includes information type wool tension level used weaving. dataset often used illustrate count data modeling. variables interest: breaks: Number warp breaks wool: Type wool (factor levels B) tension: Tension applied yarn (factor levels Low, Medium, High) aim estimate extent type wool level tension associated number warp breaks using Poisson regression model. post-hoc power given observed test statistic Wool B?  Report: post-hoc power analysis showed sample 54 trials 0.979 chance detecting observed relationship Wool B number warp breaks, relationship exists. analysis conducted using α\\alpha level 0.05.","code":"data(warpbreaks)  model <- glm(breaks ~ wool + tension, data = warpbreaks,              family = poisson(link = \"log\")) summary(model) #>  #> Call: #> glm(formula = breaks ~ wool + tension, family = poisson(link = \"log\"),  #>     data = warpbreaks) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  3.69196    0.04541  81.302  < 2e-16 *** #> woolB       -0.20599    0.05157  -3.994 6.49e-05 *** #> tensionM    -0.32132    0.06027  -5.332 9.73e-08 *** #> tensionH    -0.51849    0.06396  -8.107 5.21e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for poisson family taken to be 1) #>  #>     Null deviance: 297.37  on 53  degrees of freedom #> Residual deviance: 210.39  on 50  degrees of freedom #> AIC: 493.06 #>  #> Number of Fisher Scoring iterations: 4  power.z.test(mean = -3.994, # z-value for wool B              alpha = 0.05, # type 1 error rate              alternative = \"two.sided\",              plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean = null.mean  #>   H1 (Alt. Claim) : mean != null.mean  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.021 #>   Statistical Power    = 0.979  <<"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"user-defined-design-1","dir":"","previous_headings":"Z-Test","what":"User Defined Design","title":"Statistical Power and Sample Size Calculation Tools","text":"Power calculation readily available Spearman’s ρ\\rho rank correlation formula already known. approximate standard error Fisher’s Z-transformed correlation coefficient SE=1.06n−3SE = \\sqrt{\\frac{1.06}{n - 3}} nn sample size. details please see (Fieller, Hartley, Pearson, 1957, p. 472). Example: team school counselors want examine whether relationship students’ class rank (1st, 2nd, 3rd, etc.) self-reported academic stress levels, measured 10-point scale (1 = stress, 10 = extreme stress). Since class rank ordinal variable (lower ranks mean higher academic standing) stress scale subjective potentially interval-scaled, counselor uses Spearman’s rank-order correlation (Spearman’s ρ\\rho) assess whether higher-ranking students tend report lower higher levels stress. Researchers hypothesize students higher class ranks (.e., lower rank numbers) report lower stress levels. plan recruit 100 students, interested detecting Spearman’s ρ\\rho small 0.30, use two-tailed test α\\alpha level 0.05. power criteria?  Report: power analysis conducted assess whether 100 students sufficient detect association students’ class rank self-reported academic stress levels. analysis targeted moderate Spearman’s ρ\\rho 0.30, two-tailed test α\\alpha = 0.05. configuration yielded estimated power 0.84, indicating sufficient sensitivity detect hypothesized association.","code":"# define parameters rs <- 0.30 # spearman rho rank cor under alternative null.rs <- 0 # spearman rho rank cor under null n <- 100 # sample size  # apply Fisher's Z transformation z.rs <- cor.to.z(rs)$z #>         z       rho  #> 0.3095196 0.3000000 z.null.rs <- cor.to.z(null.rs)$z #>   z rho  #>   0   0  # calculate the standard error z.std.error <- sqrt(1.06 / (n - 3))  # calculate the non-centrality parameter ncp <- (z.rs - z.null.rs) / z.std.error  # calculate power power.z.test(ncp = ncp,              alpha = 0.05,              alternative = \"two.sided\",              plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean = null.mean  #>   H1 (Alt. Claim) : mean != null.mean  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.158 #>   Statistical Power    = 0.842  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"post-hoc-2","dir":"","previous_headings":"F-Test","what":"Post-Hoc","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: trees dataset R contains measurements volume, height, girth (diameter) 31 black cherry trees. variables interest: Girth: Diameter tree (inches) Height: Height tree (feet) aim estimate extent tree height associated tree girth. post-hoc power given observed test statistic? Report: post-hoc power analysis showed sample 31 trees 0.885 chance detecting observed relationship tree height girth, relationship exists population. analysis conducted using α\\alpha level 0.05.","code":"data(trees)  # model <- aov(Girth ~ Height, data = trees) model <- lm(Girth ~ Height, data = trees) summary(model) #>  #> Call: #> lm(formula = Girth ~ Height, data = trees) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -4.2386 -1.9205 -0.0714  2.7450  4.5384  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)    #> (Intercept) -6.18839    5.96020  -1.038  0.30772    #> Height       0.25575    0.07816   3.272  0.00276 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 2.728 on 29 degrees of freedom #> Multiple R-squared:  0.2697, Adjusted R-squared:  0.2445  #> F-statistic: 10.71 on 1 and 29 DF,  p-value: 0.002758  power.f.test(ncp = 10.71, # non-centrality under alternative              df1 = 1, # numerator degrees of freedom              df2 = 29, # denominator degrees of freedom              alpha = 0.05, # type 1 error rate              plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic F-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp = null.ncp  #>   H1 (Alt. Claim) : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.115 #>   Statistical Power      = 0.885  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"post-hoc-1-1","dir":"","previous_headings":"Chi-square Test","what":"Post-Hoc 1","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: HairEyeColor dataset R contains data survey 592 students, recording joint distribution hair color, eye color, gender. stored three-dimensional contingency table, counts representing number individuals category. variables interest: Hair: Hair color (e.g., Black, Brown, Blond, Red) Eye: Eye color (e.g., Brown, Blue, Hazel, Green) aim examine association hair color eye color. post-hoc power given observed test statistic chi-squared test independence? Report: post-hoc power analysis showed sample 592 individuals 1.00 chance detecting observed relationship hair eye color, relationship exists population. analysis conducted using α\\alpha level 0.05.","code":"data(HairEyeColor)  table <- margin.table(HairEyeColor, c(1, 2)) print(table) #>        Eye #> Hair    Brown Blue Hazel Green #>   Black    68   20    15     5 #>   Brown   119   84    54    29 #>   Red      26   17    14    14 #>   Blond     7   94    10    16  chisq.test(table) #>  #>  Pearson's Chi-squared test #>  #> data:  table #> X-squared = 138.29, df = 9, p-value < 2.2e-16  power.chisq.test(ncp = 138.29, # X-squared                  df = 9, # degrees of freedom                  alpha = 0.05, # type 1 error rate                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Chi-square Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : ncp = null.ncp  #>   H1 (Alt. Claim)   : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.000 #>   Statistical Power      = 1  <<"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"post-hoc-2-1","dir":"","previous_headings":"Chi-square Test","what":"Post-Hoc 2","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: infert dataset R contains data study infertility women, examining relationship reproductive history infertility status. includes demographic clinical information 248 women. variables interest: case: Infertility status (1 = infertile, 0 = fertile) age: Age woman years parity: Number prior full-term pregnancies induced: Number induced abortions spontaneous: Number spontaneous abortions aim evaluate whether number induced abortions contributes prediction infertility status, beyond effects age, parity, spontaneous abortions, using logistic regression framework. post-hoc power given observed deviance difference full reduced models?  Report: post-hoc power analysis indicated sample 248 women provided 0.99 probability detecting unique contribution number induced abortions infertility status, controlling variables, assuming relationship exists population. analysis conducted using α\\alpha level 0.05.","code":"data(infert)  fit.reduced <- glm(case ~ age + parity + spontaneous,                    data = infert,                    family = binomial)  fit.full <- glm(case ~ age + parity + spontaneous + induced,                 data = infert,                 family = binomial)  anova(fit.reduced, fit.full) #> Analysis of Deviance Table #>  #> Model 1: case ~ age + parity + spontaneous #> Model 2: case ~ age + parity + spontaneous + induced #>   Resid. Df Resid. Dev Df Deviance  Pr(>Chi)     #> 1       244     279.41                           #> 2       243     260.94  1   18.463 1.732e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  power.chisq.test(ncp = 18.463,                  df = 1,                  alpha = 0.05,                  plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Chi-square Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : ncp = null.ncp  #>   H1 (Alt. Claim)   : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.010 #>   Statistical Power      = 0.99  <<"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"post-hoc-3","dir":"","previous_headings":"Binomial Test","what":"Post-Hoc","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: faithful dataset contains 272 observations eruptions Old Faithful geyser Yellowstone National Park. includes: eruptions: Eruption duration (minutes) waiting: Time eruptions (minutes) aim test whether eruptions lasting 3 minutes occur half time. post-hoc power given observed proportion sample size?  Report: post-hoc power analysis indicated sample 272 eruptions provided 0.999 probability detecting whether eruptions lasting 3 minutes occur 50% time, exists underlying eruption pattern. analysis based one-sided test procedure α\\alpha = 0.05.","code":"data(faithful)  long <- faithful$eruptions > 3 n.success <- sum(long) n.total <- nrow(faithful)  binom.test(n.success, n.total, p = 0.50) #>  #>  Exact binomial test #>  #> data:  n.success and n.total #> number of successes = 175, number of trials = 272, p-value = 2.609e-06 #> alternative hypothesis: true probability of success is not equal to 0.5 #> 95 percent confidence interval: #>  0.5832982 0.7003038 #> sample estimates: #> probability of success  #>              0.6433824  power.binom.test(size = n.total, # number of eruptions                  prob = n.success / n.total, # prob. of occurrence under alt.                  null.prob = 0.50, # prob. of occurrence under null                  alpha = 0.05,                  alternative = \"one.sided\",                  plot = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= null.prob  #>   H1 (Alt. Claim) : prob > null.prob  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.039 #>   Type 2 Error (beta)    = 0.001 #>   Statistical Power      = 0.999  <<"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"user-defined-designs","dir":"","previous_headings":"Binomial Test","what":"User-Defined Designs","title":"Statistical Power and Sample Size Calculation Tools","text":"Example 1: Find number coin toss test whether coin fair. Report 1: Power analysis indicated least 85,632 coin tosses required determine whether coin fair. analysis assumes fair coin 0.50 probability landing heads, equivalence margins set 0.495 0.505, using two one-sided test procedure α\\alpha = 0.05. Example 2: Find optimal number replications Monte Carlo simulation. reliably detect type 1 error rate 0.05: reliably detect power rate 0.80: Report 2: Power analysis indicated least 16,424 replications required estimate Type 1 error rate α\\alpha = 0.05. analysis used two one-sided test procedure equivalence margins set 0.045 0.055. contrast, least 55,011 replications needed estimate statistical power 0.80, assuming equivalence margins 0.795 0.805, also using two one-sided test procedure α\\alpha = 0.05.","code":"# find the approximate solution power.z.oneprop(prob = 0.50, # prob. of head under alt.                 null.prob = c(0.495, 0.505), # equivalence margins                 power = 0.80,                 alpha = 0.05, # type 1 error rate                 alternative = \"two.one.sided\",                 verbose = FALSE)$n #> [1] 85639  # iterate to find the exact solution power.binom.test(size = 85632, # number of tosses needed                  prob = 0.50, # prob. of head under alt.                  null.prob = c(0.495, 0.505), # equivalence margins                  alpha = 0.05, # type 1 error rate                  alternative = \"two.one.sided\",                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= min(null.prob) or  #>                     prob >= max(null.prob)  #>   H1 (Alt. Claim) : prob > min(null.prob) and  #>                     prob < max(null.prob)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  << # find the approximate solution power.z.oneprop(prob = 0.05, # prob. of head under alt.                 null.prob = c(0.045, 0.055), # equivalence margins                 power = 0.80,                 alpha = 0.05, # type 1 error rate                 alternative = \"two.one.sided\", verbose = FALSE)$n #> [1] 16272  # iterate to find the exact solution power.binom.test(size = 16424, # number of replications needed                  prob = 0.05, # prob. of falsely rejecting null                  null.prob = c(0.045, 0.055), # equivalence margins                  alpha = 0.05,                  alternative = \"two.one.sided\",                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= min(null.prob) or  #>                     prob >= max(null.prob)  #>   H1 (Alt. Claim) : prob > min(null.prob) and  #>                     prob < max(null.prob)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.049 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802  << # find the approximate solution power.z.oneprop(prob = 0.80, # prob. of correctly rejecting null                 null.prob = c(0.795, 0.805), # equivalence margins                 power = 0.80,                 alpha = 0.05, # type 1 error rate                 alternative = \"two.one.sided\", verbose = FALSE)$n #> [1] 54809  # iterate to find the exact solution power.binom.test(size = 55011, # number of replications needed                  prob = 0.80, # prob. of correctly rejecting null                  null.prob = c(0.795, 0.805), # equivalence margins                  alpha = 0.05,                  alternative = \"two.one.sided\",                  plot = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= min(null.prob) or  #>                     prob >= max(null.prob)  #>   H1 (Alt. Claim) : prob > min(null.prob) and  #>                     prob < max(null.prob)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  <<"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"error-plots","dir":"","previous_headings":"","what":"Error Plots","title":"Statistical Power and Sample Size Calculation Tools","text":"plot() function (S3 method) wrapper around generic functions . creates visual representation null alternative distributions, shaded areas indicating Type 1 error (false positive) Type 2 error (false negative) regions. Assign results pwrss function R object pass plot() function.  NOTE: earlier versions {pwrss} package, plot() function generated multiple panel plots ANCOVA designs mediation models. feature longer supported, updated functions now return one effect time.","code":"power.t.student(d = 0.20, power = 0.80) |>   plot()"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"independent-samples-t-test","dir":"","previous_headings":"","what":"Independent Samples T-Test","title":"Statistical Power and Sample Size Calculation Tools","text":"independent samples t-test used compare mean outcomes two groups statistically independent - meaning outcome value individual one group related outcome value individual group. groups may represent treatment control conditions, gender groups (e.g., females males), pre-existing experimentally assigned categories.","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"parametric","dir":"","previous_headings":"Independent Samples T-Test","what":"Parametric","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Suppose aim evaluate extent psychological intervention reduces post-earthquake psychosomatic symptoms. consider standardized mean difference small Cohen’s d = -0.20 treatment control groups meaningful relevant. minimum required sample size per group, accounting 0.05 dropout rate treatment group? Report: conducted power analysis determine required sample size comparing treatment control groups psychosomatic symptoms. analysis assumed small effect size (Cohen’s d = 0.20), 0.80 statistical power, 0.05 significance level (one-tailed). Results indicated 310 participants per group needed (620 total). account anticipated 0.05 attrition treatment group, additional 17 participants required, bringing total sample size 637.","code":"power.t.student(d = -0.20,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d >= 0  #>   H1 (Alt. Claim) : d - null.d < 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 310 and 310  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # account for attrition inflate.sample(n = 310, rate = 0) # control #> 310 inflate.sample(n = 310, rate = 0.05) # treatment #> 327"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"robust-parametric","dir":"","previous_headings":"Independent Samples T-Test","what":"Robust Parametric","title":"Statistical Power and Sample Size Calculation Tools","text":"Unlike experimental designs, group variances population proportions may differ pre-existing groups (e.g. male female teachers). Assume smallest effect size interest Cohen’s d = 0.20. expected variance ratio (female male) 1.5, prevalence ratio (female male) population 2. minimum required sample size per group conditions? Report: conducted power analysis determine required sample size comparing females males. analysis assumed small effect (Cohen’s d = 0.20), 0.80 power, 0.05 significance level (two-tailed). analysis additionally incorporated realistic population characteristics: unequal variances (variance ratio = 1.5, females relative males) unequal group prevalence (2:1 female--male ratio). Results indicated 517 females 259 males required (776 total).","code":"power.t.welch(d = 0.20,               power = 0.80,               n.ratio = 2,               var.ratio = 1.5,               alpha = 0.05,               alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 517 and 259  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"non-parametric","dir":"","previous_headings":"Independent Samples T-Test","what":"Non-Parametric","title":"Statistical Power and Sample Size Calculation Tools","text":"outcome variable may treated continuous, follow normal distribution - example, Likert-type scales 5 7 categories, ranked data, bounded ordinal measures. Assume smallest effect size interest treatment control groups Cohen’s d = 0.20. minimum required sample size per group, accounting 0.05 dropout rate treatment group? Report: conducted power analysis determine required sample size comparing treatment control groups Likert-type outcome measure, assuming observed categories reflect underlying continuous latent construct follows normal distribution. analysis assumed small effect size (Cohen’s d = 0.20), 0.80 statistical power, 0.05 significance level (two-tailed). Results indicated 412 participants per group needed (824 total). account anticipated 0.05 attrition treatment group, additional 22 participants required, bringing total sample size 846.","code":"power.np.wilcoxon(d = 0.20,                   power = 0.80,                   n.ratio = 1,                   alpha = 0.05,                   alternative = \"two.sided\",                   design = \"independent\",                   distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 412 and 412  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  inflate.sample(n = 412, rate = 0.05) # treatment #> 434"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"non-inferiority","dir":"","previous_headings":"Independent Samples T-Test","what":"Non-Inferiority","title":"Statistical Power and Sample Size Calculation Tools","text":"non-inferiority trial, may evaluate effectiveness new program, drug, product, tests whether mean outcome treatment group unacceptably worse conventional-treatment placebo group, based pre-specified non-inferiority margin. instance, d - null.d difference small margin = -0.05 may still support conclusion non-inferiority. minimum required sample size detect effect size d = 0.20 criterion? higher values outcome better margin usually takes NEGATIVE values; whereas lower values outcome better margin usually takes POSITIVE values.  Report: conducted power analysis determine required sample size non-inferiority trial comparing treatment placebo groups. analysis assumed small treatment effect (d = 0.20), non-inferiority margin d = -0.05, 0.80 power, 0.05 significance level using one-tailed test appropriate non-inferiority designs. Results indicated 199 participants per group (398 total) needed demonstrate treatment meaningfully inferior placebo. Accounting anticipated 0.05 attrition rate, recruit additional 21 participants, yielding target sample size 419 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = -0.05,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 199 and 199  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # consider 0.05 attrition rate inflate.sample(n = 398, rate = 0.05) #> 419  # robust parametric power.t.welch(d = 0.20,               margin = -0.05,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 238 and 119  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = -0.05,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208 and 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"superiority","dir":"","previous_headings":"Independent Samples T-Test","what":"Superiority","title":"Statistical Power and Sample Size Calculation Tools","text":"superiority trial evaluates whether new program, drug, product leads meaningfully better mean outcome treatment group compared conventional treatment placebo group, based pre-specified superiority margin. example, d - null.d difference small margin = 0.05 may considered sufficient claim superiority. minimum required sample size detect effect size d = 0.20 criterion? higher values outcome better margin usually takes POSITIVE values; whereas lower values outcome better margin usually takes NEGATIVE values.  Report: conducted power analysis determine required sample size superiority trial comparing treatment placebo groups. analysis assumed small treatment effect (d = 0.20), superiority margin d = 0.05, 0.80 power, 0.05 significance level using one-tailed test appropriate superiority designs. Results indicated 552 participants per group (1104 total) needed demonstrate treatment meaningfully superior placebo. Accounting anticipated 0.05 attrition rate groups, recruit additional 59 participants, yielding target sample size 1163 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = 0.05,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 552 and 552  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # consider 0.05 attrition rate inflate.sample(n = 1104, rate = 0.05) #> 1163  # robust parametric power.t.welch(d = 0.20,               margin = 0.05,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 662 and 331  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = 0.05,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 578 and 578  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"equivalence","dir":"","previous_headings":"Independent Samples T-Test","what":"Equivalence","title":"Statistical Power and Sample Size Calculation Tools","text":"equivalence trial evaluates whether new program, drug, product performs similarly conventional treatment placebo, within pre-specified equivalence margin. example, difference d - null.d falling within range margin = c(-0.10, 0.10) may considered sufficient claim equivalence. minimum required sample size detect effect size d = 0.20 criterion? Report: conducted power analysis determine required sample size equivalence trial comparing new treatment conventional one. analysis assumed difference (d = 0), equivalence margin ranging d = -0.10 d = 0.10, 0.80 power, 0.05 significance level using two one-sided test appropriate equivalence designs. Results indicated 1714 participants per group (3428 total) needed demonstrate new treatment similar conventional one. Accounting anticipated 0.05 attrition rate groups, recruit additional 181 participants, yielding target sample size 3609 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0,                 margin = c(-0.10, 0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1714 and 1714  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 3428, rate = 0.05) #> 3609  # robust parametric power.t.welch(d = 0,               margin = c(-0.10, 0.10),               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 2056 and 1028  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # non-parametric power.np.wilcoxon(d = 0,                   margin = c(-0.10, 0.10),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1795 and 1795  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"minimum-effect","dir":"","previous_headings":"Independent Samples T-Test","what":"Minimum Effect","title":"Statistical Power and Sample Size Calculation Tools","text":"Minimum effect testing useful goal assess whether new program, drug, product performs meaningfully better worse conventional treatment-beyond pre-defined threshold practical significance (equivalence margins). instance, difference d - null.d falling outside range margin = c(-0.05, 0.05) may sufficient conclude intervention either inferior superior, exceeding bounds minimal practical importance. minimum required sample size detect effect size Cohen’s d = 0.20 criterion? Report: conducted power analysis determine required sample size minimum effect testing comparing new treatment conventional one. analysis assumed modest difference (d = 0.20), equivalence margin ranging d = -0.05 d = 0.05, 0.80 power, 0.05 significance level using two one-sided test appropriate minimum effect testing. Results indicated 700 participants per group (1400 total) needed reliably detect whether new treatment differs conventional treatment minimally important difference. Accounting anticipated 0.05 attrition rate groups, recruit additional 74 participants, yielding target sample size 1474 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = c(-0.05, 0.05),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 700 and 700  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 1400, rate = 0.05) #> 1474  # robust parametric power.t.welch(d = 0.20,               margin = c(-0.05, 0.05),               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alpha = 0.05,               alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 841 and 421  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = c(-0.05, 0.05),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 733 and 733  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"paired-samples-t-test","dir":"","previous_headings":"","what":"Paired Samples T-Test","title":"Statistical Power and Sample Size Calculation Tools","text":"paired samples t-test used compare mean outcomes two related matched groups, observation one group paired corresponding observation . test appropriate outcome values independent, measurements taken individuals two time points (e.g., pre-test post-test), individuals matched based characteristics (e.g., siblings, matched pairs experimental designs).","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"parametric-1","dir":"","previous_headings":"Paired Samples T-Test","what":"Parametric","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: mental health clinic transitions -person online-group therapy sessions due logistical constraints. evaluate whether new format supports core therapeutic outcome - emotional regulation - researchers plan recruit new group clients participating online therapy compare outcomes historical sample clients previously completed program person. Participants matched based baseline symptom severity, age, gender, diagnosis. primary outcome emotional regulation, assessed end program using Difficulties Emotion Regulation Scale (DERS). two-sided test conducted determine whether emotional regulation improves deteriorates online format comparison -person format. Researchers aim detect small effect (d = 0.20), using two-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criterion? Report: conducted power analysis determine required sample size comparing emotional regulation scores online versus -person therapy sessions. analysis assumed modest difference groups (d = 0.20), 0.80 power, 0.05 significance level using two-sided test. Results indicated 199 participants need matched reliably determine whether online therapy better worse -person therapy. Accounting anticipated 0.05 attrition online group, additional 11 participants need matched, yielding target sample size 210 participants.","code":"power.t.student(d = 0.20,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 199  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802  # consider an attrition rate of 0.05 inflate.sample(n = 199, rate = 0.05) #> 210"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"non-parametric-1","dir":"","previous_headings":"Paired Samples T-Test","what":"Non-parametric","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example, now focus different outcome: session satisfaction ratings, measured 5-point scale (1 = , 5 = Extremely). Researchers aim determine whether satisfaction ratings differ online -person formats. test , plan use Wilcoxon signed-rank test paired data, targeting small effect size (d = 0.20) two-sided significance level α\\alpha = 0.05. minimum required sample size conditions? Report: conducted power analysis determine required sample size comparing session satisfaction ratings online versus -person therapy sessions using Wilcoxon signed-rank test. analysis assumed modest difference groups (d = 0.20), 0.80 power, 0.05 significance level using two-sided test, normal distribution. Results indicated 208 participants need matched reliably determine whether online therapy better worse -person therapy terms session satisfaction ratings. Accounting anticipated 0.05 attrition online group, additional 11 participants need matched, yielding target sample size 219 participants.","code":"power.np.wilcoxon(d = 0.20,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.sided\",                   design = \"paired\",                   distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # consider an attrition rate of 0.05 inflate.sample(n = 208, rate = 0.05) #> 219"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"non-inferiority-1","dir":"","previous_headings":"Paired Samples T-Test","what":"Non-inferiority","title":"Statistical Power and Sample Size Calculation Tools","text":"Consider earlier example, now focus different outcome: perceived group cohesion. evaluate whether new format preserves perceived group cohesion, researchers plan conduct non-inferiority test assess whether perceived group cohesion ratings online group meaningfully worse matched -person group. researcher expects change (d = 0). d - null.d difference can small margin = -0.10 online format still considered non-inferior. minimum required sample size criterion? higher values outcome better margin usually takes NEGATIVE values; whereas lower values outcome better margin usually takes POSITIVE values.  Report: conducted power analysis determine required sample size non-inferiority test comparing perceived group cohesion ratings online versus -person therapy sessions. analysis assumed true difference groups (d = 0), non-inferiority margin -0.10, 0.80 power, 0.05 significance level using one-sided test appropriate non-inferiority designs. Results indicated 619 participants need matched reliably determine whether online therapy meaningfully worse -person therapy pre-specified margin. Accounting anticipated 0.05 attrition online group, additional 33 participants required, yielding target sample size 652 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0,                 margin = -0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 619  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 619, rate = 0.05) #> 652  # non-parametric power.np.wilcoxon(d = 0,                   margin = -0.10,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 648  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"superiority-1","dir":"","previous_headings":"Paired Samples T-Test","what":"Superiority","title":"Statistical Power and Sample Size Calculation Tools","text":"Consider earlier example, now focus different outcome: psychological safety. maintaining core therapeutic outcomes important, online format may offer additional advantages. One outcome psychological safety, defined comfort expressing thoughts, emotions, personal experiences group sessions without fear judgment rejection. evaluate whether online format enhances dimension, researchers plan recruit new group clients beginning online therapy match historical sample previous clients completed program person. Matching done based baseline symptom severity, age, gender, diagnosis. superiority test conducted assess whether psychological safety ratings meaningfully higher online group compared matched -person group. researcher interested modest change (d = 0.20), d - null.d difference can small margin = 0.10 online format still considered superior. minimum required sample size criterion? higher values outcome better margin usually takes POSITIVE values; whereas lower values outcome better margin usually takes NEGATIVE values.  Report: conducted power analysis determine required sample size superiority test comparing psychological safety ratings online versus -person therapy sessions. analysis assumed modest difference groups (d = 0.20), superiority margin 0.10, 0.80 power, 0.05 significance level using one-sided test appropriate superiority designs. Results indicated 627 participants need matched reliably determine whether online therapy meaningfully better -person therapy pre-specified margin. Accounting anticipated 0.05 attrition online group, additional 33 participants required, yielding target sample size 660 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0.20,                 margin = 0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 627  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 627, rate = 0.05) #> 660  # non-parametric power.np.wilcoxon(d = 0.20,                   margin = 0.10,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 657  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"equivalence-1","dir":"","previous_headings":"Paired Samples T-Test","what":"Equivalence","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example, now focus different outcome: emotional intensity. new format expected retain key therapeutic benefits, certain outcomes must remain stable intervention considered acceptable. One outcome emotional intensity sessions, defined typical depth strength emotions experienced expressed participants group discussions. little emotional intensity may signal disengagement superficial participation, much may overwhelm participants disrupt group cohesion. Therefore, maintaining similar level emotional intensity online format essential. evaluate , researchers plan recruit new group clients beginning online therapy match historical sample previous clients completed program person. Matching done based baseline symptom severity, age, gender, diagnosis. equivalence test conducted assess whether emotional intensity scores online group meaningfully similar matched -person group. researcher interested detecting difference (d = 0). d - null.d difference within range margin = c(-0.10, 0.10) considered sufficient claim equivalence. minimum required sample size criterion? Report: conducted power analysis determine required sample size equivalence test comparing emotional intensity online versus -person group therapy sessions. analysis assumed difference groups (d = 0), equivalence margin -0.10 0.10, 0.80 power, 0.05 significance level using two one-sided test appropriate equivalence designs. Results indicated 858 participants need matched reliably determine whether emotional intensity online therapy meaningfully similar -person therapy within pre-specified equivalence margin. Accounting anticipated 0.05 attrition online group, additional 46 participants required, yielding target sample size 904 participants.","code":"# parametric (an example report is provided below) power.t.student(d = 0,                 margin = c(-0.10, 0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 858  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 858, rate = 0.05) #> 904  # non-parametric power.np.wilcoxon(d = 0,                   margin = c(-0.10, 0.10),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 898  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"minimum-effect-1","dir":"","previous_headings":"Paired Samples T-Test","what":"Minimum Effect","title":"Statistical Power and Sample Size Calculation Tools","text":"Consider earlier example, outcome: emotional regulation. Different earlier example, null hypothesis longer point zero stated terms equivalence interval. minimal effect test conducted assess whether emotional regulation scores online group meaningfully different matched -person group. researcher interested detecting modest difference (d = 0.20). d - null.d difference outside range margin = c(-0.10, 0.10) considered sufficient claim difference. minimum required sample size criterion? Report: conducted power analysis determine required sample size minimal effect test comparing emotional regulation online versus -person group therapy sessions. analysis assumed modest difference groups (d = 0.20), equivalence margin -0.10 0.10, 0.80 power, 0.05 significance level using two one-sided test appropriate minimal effect testing. Results indicated 797 participants need matched reliably determine whether emotional regulation online therapy meaningfully different -person therapy. Accounting anticipated 0.05 attrition online group, additional 42 participants required, yielding target sample size 839 participants.","code":"# parametric (an example report is provided below) power.t.student(d = -0.20,                 margin = c(-0.10, 0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 797  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8  # consider 0.05 attrition rate inflate.sample(n = 797, rate = 0.05) #> 839  # non-parametric power.np.wilcoxon(d = -0.20,                   margin = c(-0.05, 0.05),                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 370  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"one-sample-t-test","dir":"","previous_headings":"","what":"One-Sample T-Test","title":"Statistical Power and Sample Size Calculation Tools","text":"one-sample t-test used determine whether mean single group differs significantly known hypothesized population value. test appropriate comparing observed sample mean fixed reference point-national average, theoretical benchmark, target score.","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"parametric-2","dir":"","previous_headings":"One-Sample T-Test","what":"Parametric","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: school district interested determining teacher stress levels introducing new program involves extensive teaching activities evaluation students. research division plan administer Perceived Stress Scale (PSS) teachers, produces total scores ranging 0 40. primary goal determine whether average stress level among teachers meaningfully elevated. mean score 22 higher - two points commonly used clinical threshold 20 - considered indicative elevated stress warrants attention. estimated standard deviation 5, two-point difference corresponds medium effect size (Cohen’s d = 0.40). Assume one-tailed test significance level α\\alpha = 0.05 target power 0.80. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether teachers exhibit elevated stress levels due workload. Assuming two-point difference clinical threshold (Cohen’s d = 0.40), one-sided test 0.80 power, 0.05 significance level, analysis indicated minimum 52 teachers surveyed reliably detect elevated stress.","code":"power.t.student(d = 0.40,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 52  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.192 #>   Statistical Power      = 0.808"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"non-parametric-2","dir":"","previous_headings":"One-Sample T-Test","what":"Non-Parametric","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example, now focus different outcome measured using single Likert-type item: job satisfaction. Job satisfaction measured using “Overall, satisfied job.” responses range 1 (strongly disagree) 5 (strongly agree). mean score neutral point 3 indicates dissatisfaction. schools district considers modest difference average neutral point (Cohen’s d = -0.20). Assume one-tailed test significance level α\\alpha = 0.05 target power 0.80. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether teachers satisfied job. Assuming modest difference neutral point (Cohen’s d = -0.20), one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 208 teachers surveyed.","code":"power.np.wilcoxon(d = -0.20,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.sided\",                   design = \"one.sample\",                   distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"practically-greater","dir":"","previous_headings":"One-Sample T-Test","what":"Practically Greater","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example focuses stress primary outcome. Now assume researchers testing whether observed difference (d - null.d) exceeds minimum meaningful effect specifying margin = 0.10 - correspond half-point increase average stress level. Differences smaller margin considered practically significant cause concern. Researchers plan use one-sided test significance level α\\alpha = 0.05 desired power 0.80. minimum required sample size configuration? Report: conducted power analysis determine required sample size assessing whether stress level teachers clinical threshold. Assuming medium difference clinical threshold (Cohen’s d = 0.40), one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 72 teachers surveyed.","code":"# parametric power.t.student(d = 0.40,                 margin = 0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 72  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # non-parametric power.np.wilcoxon(d = 0.40,                   margin = 0.10,                   power = 0.80,                   alpha = 0.05,                   alternative = \"one.sided\",                   design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 76  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"equivalence-2","dir":"","previous_headings":"One-Sample T-Test","what":"Equivalence","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: sleep research team evaluating safety new melatonin-based supplement designed support better sleep adults without causing excessive drowsiness oversleeping. ensure supplement disrupt healthy sleep patterns, plan assess whether average nightly sleep duration among users falls within clinically acceptable range 6.5 8.5 hours, considered optimal adults. Using one-sample equivalence t-test equivalence bounds set ±\\pm 1 hour around target value 7.5 hours, researchers aim demonstrate supplement lead - oversleeping. two one-sided tests procedure conducted significance level α\\alpha = 0.05 0.80 power. Assume standard deviation 1.2 hours expected mean 7.5 hours. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether sleep duration falls within predefined acceptable range. Assuming difference (d = 0) equivalence margin d = ±\\pm 0.83, two one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 14 participants needed.","code":"d <- (7.5 - 7.5) / 1.2 margin <- c((6.5 - 7.5) / 1.2, (8.5 - 7.5) / 1.2)  # parametric power.t.student(d = d,                 margin = margin,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 14  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.174 #>   Statistical Power      = 0.826  # non-parametric power.np.wilcoxon(d = d,                   margin = margin,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 14  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"minimal-effect","dir":"","previous_headings":"One-Sample T-Test","what":"Minimal Effect","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: research team testing new medication developed treat generalized anxiety disorder monitoring whether disrupts normal sleep patterns. drug designed reduce anxiety, concern may cause excessive drowsiness oversleeping. clinically acceptable sleep range healthy adults defined 6.5 8.5 hours per night, 7.5 hours midpoint. goal determine whether mean sleep duration deviates significantly 7.5 hours. sleep duration equal greater 9 hours considered problematic. one-sample t-test used test whether average sleep duration differs range normative values. two one-sided test significance level 0.05 0.80 power, assuming standard deviation 1.2 hours. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing whether sleep duration falls outside predefined acceptable range. Assuming large difference (d = 1.25) equivalence margin d = ±\\pm 0.83, two one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 74 participants needed.","code":"d <- (9 - 7.5) / 1.2 margin <- c((6.5 - 7.5) / 1.2, (8.5 - 7.5) / 1.2)  # parametric power.t.student(d = d,                 margin = margin,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.one.sided\",                 design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (One Sample) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 74  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802  # non-parametric power.np.wilcoxon(d = d,                   margin = margin,                   power = 0.80,                   alpha = 0.05,                   alternative = \"two.one.sided\",                   design = \"one.sample\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (One Sample) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim  : d - null.d >= min(margin) and  #>                     d - null.d <= max(margin)  #>   H1 (Alt. Claim) : d - null.d < min(margin) or  #>                     d - null.d > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 78  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"one-sample","dir":"","previous_headings":"","what":"One-Sample","title":"Statistical Power and Sample Size Calculation Tools","text":"one-sample proportion test compares proportion successes sample known population proportion hypothesized value. “Success” defined based outcome interest can represent various binary events: patient recovery, disease presence, survival, website click-, customer retention, exam passage, program completion, yes / outcome relevant research question.","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"approximate","dir":"","previous_headings":"One-Sample","what":"Approximate","title":"Statistical Power and Sample Size Calculation Tools","text":"approach assumes test statistics follow standard normal distribution. Example: regional traffic safety agency plans conduct observational study estimate seat belt use among daytime drivers. state law mandates seat belt use, agency adopts 90% compliance rate public safety benchmark, consistent national targets promoted National Highway Traffic Safety Administration (NHTSA). usage rate 80% lower raise concern potentially trigger enforcement campaigns. Assuming one-sided test α=0.05\\alpha = 0.05 0.80 power, many vehicles observed? Report: conducted power analysis determine required sample size assessing whether rate seat belt use falls predetermined compliance benchmark. true usage rate 80% lower considered cause concern relative 90% target. Assuming one-sided test significance level 0.05 0.80 power, analysis indicated minimum 69 vehicles observed. Arcsine transformation: arcsine transformation stabilizes variance proportion differences. can useful proportions towards extreme. Continuity correction: Continuity correction improves normal approximation small samples accounting discrete nature outcome, resulting accurate test statistics. Calculate standard error using probability success alternative hypothesis: default procedure calculates standard error using probability success null hypothesis (PASS). approach adjusts null distribution standard deviation obtain precise critical values. can changed via std.error argument. null values close zero one, appropriate use exact test.","code":"power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 69  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.200 #>   Statistical Power     = 0.8 power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 arcsine = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : TRUE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 54  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.197 #>   Statistical Power     = 0.803 power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 correct = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : TRUE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 79  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.198 #>   Statistical Power     = 0.802 power.z.oneprop(prob = 0.80, # probability of success under alternative                 null.prob = 0.90, # probability of success under null                 power = 0.80,                 alpha = 0.05,                 alternative = \"one.sided\",                 std.error = \"alternative\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Alternative #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 99  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.200 #>   Statistical Power     = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"exact-binomial","dir":"","previous_headings":"One-Sample","what":"Exact (Binomial)","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: pharmaceutical company evaluating safety profile new medication developed generalized anxiety disorder monitoring occurrence skin rash. company finds minimum rate 2 1000 problematic. research division plan one-sided test significance level 0.05 0.80 power. minimum required sample size criterion? Report: conducted power analysis determine required sample size assessing rash prevalence. Assuming rate 2 1000, one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 804 participants needed.","code":"power.exact.oneprop(prob = 0.002, # probability of success under alternative                     null.prob = 0, # probability of success under null                     power = 0.80,                     alpha = 0.05,                     alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob <= 0 #>   H1 (Alt. Claim)        : prob - null.prob > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 804  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.200 #>   Statistical Power     = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"independent-samples","dir":"","previous_headings":"","what":"Independent Samples","title":"Statistical Power and Sample Size Calculation Tools","text":"independent samples proportion test compares proportion “successes” two distinct groups (groups related, paired, matched) determine whether statistically significant difference exists. Group may exist naturally (females - males, urban - rural, etc.) formed researcher (new - standard drug, intervention - control, etc.). Cohen’s h standard effect size metric power analyses proportions; calculated arcsine-transformed success probabilities. Although h plays role proportions Cohen’s d plays means, practical gap z-test proportions independent-samples t-test continuous data usually negligible - sample size estimates rarely vary one two units. Consequently, applying familiar t-test framework yields power calculations acceptably accurate. example compares two approaches:","code":"# z-test approach power.z.twoprops(prob1 = 0.60, prob2 = 0.50,                  power = 0.80, arcsine = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 = 0  #>   H1 (Alt. Claim) : prob1 - prob2 != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 388 and 388  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801  # find Cohen's h probs.to.h(prob1 = 0.60, prob2 = 0.50) #>         h     prob1     prob2  #> 0.2013579 0.6000000 0.5000000  # t-test approach power.t.student(d = 0.2013579, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 389 and 389  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"approximate-1","dir":"","previous_headings":"Independent Samples","what":"Approximate","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: pharmaceutical company investigating new medication intended treat generalized anxiety disorder. anti-anxiety efficacy evaluated elsewhere, early case reports suggest daytime sleepiness - recorded binary outcome (present vs. absent) - may occur frequently women men. verify potential gender-specific side effect, researchers enroll equal numbers male female patients, administer drug four weeks, document whether participant experiences clinically significant daytime sleepiness. five percent difference considered clinically meaningful warrants attention. research division plan one-sided test significance level 0.05 0.80 power. minimum required sample size criterion? key difficulty planning studies proportion differences fixed absolute gap translates different Cohen’s h values depending falls 0 - 1 scale. change 50% 55% (near midpoint) yields small h thus demands extremely large samples, whereas 5% increase 1% 6% produces much larger h requires far fewer participants. reason, essential anchor power analysis realistic baseline proportion, ideally drawn administrative historical data. planning purposes, assume roughly 10% patients taking current standard medication experience daytime sleepiness. use 10% figure reference rate estimating sample size needed detect gender-specific increase new drug. many cases, researchers lack prior information event probabilities. Using 50% reference point one group - increase decrease interest - conservative approach power analysis. actual probability may anywhere near 50% fine.  Report: conducted power analysis determine required sample size assessing whether gender differences exist daytime sleepiness. analysis assume rate 15% females 10% males, one-sided test 0.05 significance level 0.80 power. Results indicated minimum 540 participants needed per group (1080 total). Arcsine transformation: Continuity correction: Calculate standard error using unpooled standard deviations:","code":"power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 540 and 540  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\",                  arcsine = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 536 and 536  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\",                  correct = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 580 and 580  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.twoprops(prob1 = 0.15,                  prob2 = 0.10,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\",                  std.error = \"unpooled\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 538 and 538  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"exact-fisher","dir":"","previous_headings":"Independent Samples","what":"Exact (Fisher)","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: metropolitan library system piloting two new reminder strategies boost timely return overdue books - naturally binary outcome, patron either brings item back within amnesty window (yes) (). Borrowers approaching due date randomly assigned one two groups. Group receives interactive WhatsApp chatbot walks renewal return options, whereas Group B receives gamified -app badge awards points prompt returns. reminder system judged worthwhile return rate either group exceeds least 10 percentage points. decision help reminder system invest considering cost. prior data exist, planners adopt “worst-case scenario” approach maximizes required sample size: rise 50% 60%. Using one-sided test α\\alpha = 0.05 0.80 power, minimum number patrons needed group? Report: conducted power analysis estimate required sample size evaluating relative effectiveness two reminder systems. Assuming 10% difference (50% 60%), one-sided test 0.05 significance level 0.80 power, analysis indicated minimum 321 patrons needed group (642 total).","code":"power.exact.twoprops(prob1 = 0.60,                      prob2 = 0.50,                      power = 0.80,                      alpha = 0.05,                      alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Fisher's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 278 and 278  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.000 #>   Statistical Power    = 1"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"non-inferiority-2","dir":"","previous_headings":"Independent Samples","what":"Non-inferiority","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: pharmaceutical company conducting non-inferiority trial evaluate safety profile new medication developed generalized anxiety disorder, focusing specifically occurrence skin rash side effect. current standard treatment skin rash rate approximately 2 per 1,000 patients (0.2%). company wants ensure new medication lead clinically unacceptable increase side effect. expect new drug skin rash rate approximately 1 per 1,000 patients (0.1%) define non-inferiority margin 1 per 1,000 (0.1%), meaning new drug’s skin rash rate exceed 0.3% considered non-inferior. Assuming one-sided test 0.05 significance level, 0.80 power, 0.05 attrition rate groups, minimum required sample size evaluate non-inferiority criterion? Report: conducted power analysis estimate minimum required sample size evaluate non-inferiority new drug treating generalized anxiety disorder compared standard treatment. analysis focused skin rash adverse event, assumed prevalence rate 1 1,000 (0.1%) new drug 2 1,000 (0.2%) standard treatment. Using non-inferiority margin 1 1,000 (0.1%) increase, one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 457 participants needed group (914 total). Considering 5% attrition rate total 963 participants needed.","code":"power.z.twoprops(prob1 = 0.01,                  prob2 = 0.02,                  margin = 0.01,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 >= margin  #>   H1 (Alt. Claim) : prob1 - prob2 < margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 457 and 457  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # consider 5% attrition rate inflate.sample(n = 914, rate = 0.05) #> 963"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"superiority-test","dir":"","previous_headings":"Independent Samples","what":"Superiority Test","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example focuses non-inferiority new drug treating generalized anxiety disorder compared standard treatment. Now assume researchers aim evaluate whether new drug superior standard treatment reducing proportion patients resort rescue medication. 5% absolute reduction rescue medication use expected new drug group. Since prior estimates available, assume worst-case scenario 50% usage rate standard treatment group. Using 1% superiority margin, one-sided test 0.05 significance level, 0.80 power, 5% attrition rate groups, minimum required sample size test superiority conditions? Report: conducted power analysis estimate minimum required sample size evaluate superiority new drug treating generalized anxiety disorder compared standard treatment. analysis focused proportion patients requiring rescue medication, assuming prevalence rate 50% standard treatment group 45% new drug group. Using least 1% decrease superiority margin, one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 1,926 participants per group (3,852 total) required. Accounting 5% attrition rate, total sample size increases 4,055 participants.","code":"power.z.twoprops(prob1 = 0.45,                  prob2 = 0.50,                  margin = -0.01,                  power = 0.80,                  alpha = 0.05,                  alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 >= margin  #>   H1 (Alt. Claim) : prob1 - prob2 < margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1926 and 1926  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # consider 5% attrition rate inflate.sample(n = 3852, rate = 0.05) #> 4055"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"equivalence-3","dir":"","previous_headings":"Independent Samples","what":"Equivalence","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: national education ministry implements new automated scoring system evaluate high school students merit-based university scholarship program. algorithm incorporates multiple factors including GPA, standardized test scores, extracurricular activities, socio-economic indicators using complex weighting system. Despite using seemingly objective inputs, concerns algorithm’s weighting interaction effects might inadvertently favor one gender another - example, system overweights certain activities traditionally dominated one gender, interaction effects variables create unexpected biases. concerns algorithmic bias composite scoring methodology, ministry wants eligibility rates (eligible vs. eligible) scholarship must remain equivalent across male female students. disparity greater ±\\pm 1% eligibility rates flagged potential violation gender equity policy. equivalence trial conducted determine whether new automated scoring system produces statistically equivalent scholarship eligibility rates male female students. standard, human-rated system yields eligibility rates approximately 10% groups. evaluate equivalence, analysis uses two one-sided test 0.05 significance level 0.80 power. minimum required number applications process per group test equivalence conditions? Report: conducted power analysis estimate minimum required sample size evaluate whether new automated scoring system yields scholarship eligibility rates statistically equivalent male female students. analysis assumed baseline eligibility rate 10% groups standard rater-based system. Using equivalence margin ±\\pm 5%, two one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 3,854 applications processed per group (7,708 total).","code":"power.z.twoprops(prob1 = 0.10,                  prob2 = 0.10,                  margin = c(-0.02, 0.02),                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= min(margin) or  #>                     prob1 - prob2 >= max(margin)  #>   H1 (Alt. Claim) : prob1 - prob2 > min(margin) and  #>                     prob1 - prob2 < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 3854 and 3854  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"minimum-effect-2","dir":"","previous_headings":"Independent Samples","what":"Minimum Effect","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example evaluates whether new automated scoring system yields scholarship eligibility rates statistically equivalent male female students. research team establishes gender difference eligibility rates greater ±\\pm 3% constitute meaningful disparity requiring algorithmic adjustment. establish equivalence bounds ±\\pm 1% eligibility rates - threshold considered smallest practically important effect warrants monitoring potential intervention. minimal effect test conducted check whether system produces gender difference least 1% either direction. Using two one-sided test 0.05 significance level, 0.80 power, minimum required number complete applications process? Report: conducted power analysis estimate minimum required number complete scholarship applications evaluate whether new automated scoring system results gender difference 3% eligibility rates (13% females 10% males). Using equivalence bounds ±\\pm 1%, two one-sided test 0.05 significance level, 0.80 power, analysis indicated minimum 3,992 applications processed per group (7,984 total).","code":"power.z.twoprops(prob1 = 0.13,                  prob2 = 0.10,                  margin = c(-0.01, 0.01),                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 >= min(margin) and  #>                     prob1 - prob2 <= max(margin)  #>   H1 (Alt. Claim) : prob1 - prob2 < min(margin) or  #>                     prob1 - prob2 > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 3992 and 3992  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"approximate-2","dir":"","previous_headings":"Paired Samples","what":"Approximate","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Colorectal cancer screening recommended adults aged 50-74 part routine preventive care. Traditionally, eligible individuals invited primary care clinics complete fecal immuno-chemical test (FIT), non-invasive screening tool early detection colorectal cancer. However, historical administrative records show 40% invited individuals complete test -clinic invitation model. improve public health outcomes, regional health authority piloting new outreach program FIT kits mailed directly individuals’ homes, removing need schedule attend clinic visit. Researchers recruit new sample 50- 74-year-olds receive -home kits compare screening completion rate 40% baseline rate administrative data. new group (receiving mailed FIT kits) matched historical administrative cohort (invited -clinic screening) based key demographic clinical characteristics available health records, binary outcome screening completion (yes / ). aim evaluate whether -home kit significantly improves uptake, expected 10% increase (40% 50%). two-sided test, α\\alpha = 0.05, 0.80 power planned estimate minimum required sample size newly recruited group. Report: conducted power analysis estimate minimum required sample size evaluate whether new -home screening strategy improves colorectal cancer screening completion among adults aged 50-74, compared historical -clinic invitation data. Administrative records show approximately 40% eligible individuals completed screening standard model. intervention aims improve rate least 10 percentage points, reaching 50% completion. Using two-sided test 0.05 significance level, 0.80 power, analysis indicates minimum 200 participants need matched.","code":"power.z.twoprops(prob1 = 0.50,                  prob2 = 0.40,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  paired = TRUE,                  rho.paired = 0.50) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Paired Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob10 - prob01 = 0 #>   H1 (Alt. Claim) : prob10 - prob01 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Paired Sample Size   = 200  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.196 #>   Statistical Power    = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"exact-mcnemar","dir":"","previous_headings":"Paired Samples","what":"Exact (McNemar)","title":"Statistical Power and Sample Size Calculation Tools","text":"Consider earlier example evaluates new outreach program increase colorectal cancer screening rates via mailing FIT kits directly individuals’ homes instead inviting clinic. Instead relying normal approximation hypothesis testing, researchers use exact McNemar’s test. parameters remain unchanged; however, additional 13 subjects need matched maintain desired power.","code":"power.exact.twoprops(prob1 = 0.50,                      prob2 = 0.40,                      power = 0.80,                      alpha = 0.05,                      alternative = \"two.sided\",                      paired = TRUE,                      rho.paired = 0.50) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Paired Proportions #>  #>   Method          : McNemar's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob10 - prob01 = 0 #>   H1 (Alt. Claim) : prob10 - prob01 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Paired Sample Size   = 213  << #>   Type 1 Error (alpha) = 0.030 #>   Type 2 Error (beta)  = 0.195 #>   Statistical Power    = 0.805"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"one-sample-1","dir":"","previous_headings":"","what":"One-Sample","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: university counseling center interested understanding relationship students’ self-reported sleep quality levels academic stress. Prior research suggests weak associations, center believes relationship may stronger population due increased course loads reduced access support services. plan test whether Pearson correlation sleep quality scores academic stress scores significantly greater 0.10, define minimum meaningful effect size. Researchers define difference expected correlation (0.20) benchmark value (0.10) minimum meaningful effect size warrants attention. plan one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis estimate minimum required sample size evaluating whether correlation academic stress sleep disturbance among university students meaningfully greater benchmark value. Researchers identified correlation 0.20 theoretically relevant set minimum meaningful difference 0.10, using 0.10 benchmark. one-sided test significance level 0.05 0.80 power planned. analysis indicated minimum 593 students sufficient.","code":"power.z.onecor(rho = 0.20,                null.rho = 0.10,                power = 0.80,                alpha = 0.05,                alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-Sample Correlation  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho -  null.rho <= 0 #>   H1 (Alt. Claim) : rho -  null.rho > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 593  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"independent-samples-1","dir":"","previous_headings":"","what":"Independent Samples","title":"Statistical Power and Sample Size Calculation Tools","text":"Cohen’s q standard effect size metric power analyses correlations; calculated Fisher’s z-transformed correlations. Although q plays role correlations Cohen’s d plays means, practical gap z-test correlations independent-samples t-test usually negligible - sample size estimates rarely vary one two units. Consequently, applying familiar t-test framework yields sample size calculations acceptably accurate.  example compares two approach: key difficulty planning studies correlation differences fixed absolute gap translates different Cohen’s q values depending falls -1 1 scale. change 10% 20% yields small q thus demands larger samples, whereas 10% increase 50% 60% produces larger q requires fewer participants. reason, essential anchor power analysis realistic baseline correlation, ideally drawn administrative historical data. many cases, researchers lack prior information population correlations. Using 0 correlation reference point one group - increase decrease interest - conservative approach power analysis. actual correlation may anywhere near 0 fine.  Example: research team examining whether association parental support academic achievement stronger low socio-economic status (SES) schools compared high-SES schools. confirmed, intend recommend targeted interventions enhance parental involvement specifically low-SES settings. determine required sample size, researchers anticipate small meaningful difference two correlations. consider minimum meaningful difference 0.10 - representing difference correlation 0 0.10 worst-case scenario - corresponds small effect size (Cohen’s q = 0.10). Researchers plan use one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis estimate minimum required sample size evaluating whether correlation parental support academic achievement meaningfully stronger low socio-economic status (SES) schools compared high-SES schools. reflect conservative scenario, considered minimum meaningful increase correlation 0 0.10, representing small effect size (Cohen’s q = 0.10). analysis assumed one-sided test significance level 0.05 statistical power 0.80. Results indicated data collected least 1,232 students (parents) SES group, totaling 2,464 participants.","code":"# z-test approach power.z.twocors(rho1 = 0.20, rho2 = 0.10, power = .80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Correlations  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho1 - rho2 = 0 #>   H1 (Alt. Claim) : rho1 - rho2 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1501 and 1501  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # find Cohen's q cors.to.q(rho1 = 0.20, rho2 = 0.10) #>         q     delta      rho1      rho2  #> 0.1023972 0.1000000 0.2000000 0.1000000  # t-test approach power.t.student(d = 0.1023972, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1499 and 1499  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 power.z.twocors(rho1 = 0.10,                 rho2 = 0,                 power = .80,                 alpha = 0.05,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Correlations  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho1 - rho2 <= 0 #>   H1 (Alt. Claim) : rho1 - rho2 > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1232 and 1232  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # calculate Cohen's h cors.to.q(rho1 = 0.10, rho2 = 0) #>         q     delta      rho1      rho2  #> 0.1003353 0.1000000 0.1000000 0.0000000  # t-test approximation power.t.student(d = 0.1003353,                 power = .80,                 alpha = 0.05,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= 0  #>   H1 (Alt. Claim) : d - null.d > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 1229 and 1229  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"one-common-index","dir":"","previous_headings":"Paired Samples","what":"One Common Index","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: research team investigates whether school-based parental engagement program can reduce impact socio-economic status (SES) academic achievement. Using pre-test post-test scores, compare correlation SES achievement intervention. power analysis conducted detect small meaningful change (Cohen’s q = 0.10) strength correlations. post-intervention correlation weaker, suggests program effectively mitigates SES-related disparities. Several meta-analyses found moderate positive correlation SES academic achievement (rho12 = 0.30). reduction 0.30 0.20 meaningful warrants attention (rho13 = 0.30). Also based prior meta-analytic findings, common observe correlation 0.70 pre-test post-test achievement scores (rho23 = 0.30). Researchers plan use one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis determine minimum sample size required detect meaningful reduction correlation SES academic achievement following parental engagement intervention. Based prior meta-analyses, correlation SES academic achievement assumed ρ12\\rho_{12} = 0.30 pre-test, post-test correlation ρ13\\rho_{13} = 0.20 representing meaningful reduction (Cohen’s q = 0.126). correlation pre-test post-test scores assumed ρ23\\rho_{23} = -0.70. analysis uses one-sided Steiger’s Z test compare dependent correlations, significance level 0.05 statistical power 0.80. assumptions, minimum required sample size 286 students. account anticipated 5% attrition rate, additional 16 students included, bringing total target sample size 302 students.","code":"# example data for one common index # compare cor(V1, V2) to cor(V1, V3)  # subject    V1       V2      V3 # <int>    <dbl>    <dbl>    <dbl> #   1       1.2      2.3      0.8 #   2      -0.0      1.1      0.7 #   3       1.9     -0.4     -2.3 #   4       0.7      1.3      0.4 #   5       2.1     -0.1      0.8 #   ...     ...      ...      ... #   1000   -0.5      2.7     -1.7  # V1: socio-economic status (common) # V2: pre-test # V3: post-test  power.z.twocors.steiger(rho12 = 0.50,                         rho13 = 0.40,                         rho23 = 0.70,                         power = 0.80,                         alpha = 0.05,                         alternative = \"one.sided\",                         common.index = TRUE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Dependent Correlations #>  #>   Common Index    : TRUE #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho12 - rho13 <= 0 #>   H1 (Alt. Claim) : rho12 - rho13 > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 286  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # calculate the effect size cors.to.q(rho1 = 0.40, rho2 = 0.50) #>          q      delta       rho1       rho2  #> -0.1256572 -0.1000000  0.4000000  0.5000000  # adjust the sample for 5% attrition rate inflate.sample(n = 286, rate = 0.05) #> 302"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"no-common-index","dir":"","previous_headings":"Paired Samples","what":"No Common Index","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: research team investigates whether teaching students meta-cognitive strategies reading transferable math domain. expect increase correlation reading math scores pre-test post-test following intervention involving activities related meta-cognition. Based meta-analytic findings, typical correlation reading math around 0.50. team considers increase rho12 = 0.50 rho34 = 0.60 meaningful relevant, corresponding Cohen’s q = 0.144. increase average reading math scores, along stronger post-test correlation reading math, suggest meta-cognitive strategies targeted reading transferable math domain. Researchers also assume correlation pre-test post-test reading rho13 = 0.70, correlation pre-test post-test math rho24 = 0.70, correlation pre-test reading post-test math rho14 = 0.40, correlation pre-test math post-test reading rho23 = 0.40. Researchers plan use one-sided test α\\alpha = 0.05 0.80 power. minimum required sample size criteria? Report: conducted power analysis determine minimum sample size required detect meaningful increase correlation reading math performance following intervention involving meta-cognitive strategy instruction reading. Based prior meta-analyses, correlation reading math scores assumed ρ12=0.50\\rho_{12} = 0.50 pre-test, post-test correlation ρ34=0.60\\rho_{34} = 0.60 representing meaningful increase (Cohen’s q=0.144q = 0.144). analysis also incorporates following assumed correlations: ρ13=0.70\\rho_{13} = 0.70 (pre-test reading - post-test reading), ρ24=0.70\\rho_{24} = 0.70 (pre-test math - post-test math), ρ14=0.40\\rho_{14} = 0.40 (pre-test reading - post-test math), ρ23=0.40\\rho_{23} = 0.40 (pre-test math - post-test reading). analysis uses one-sided Steiger’s Z test compare dependent correlations, significance level 0.05 statistical power 0.80. assumptions, minimum required sample size 317 students. account anticipated 5% attrition rate, additional 17 students included, bringing total target sample size 334 students.","code":"# example data for no common index # compare cor(V1, V2) to cor(V3, V4)  # subject    V1       V2       V3       V4 # <int>    <dbl>    <dbl>    <dbl>    <dbl> #   1       1.2      2.3      0.8      1.2 #   2      -0.0      1.1      0.7      0.9 #   3       1.9     -0.4     -2.3     -0.1 #   4       0.7      1.3      0.4     -0.3 #   5       2.1     -0.1      0.8      2.7 #   ...     ...      ...      ...      ... #   1000   -0.5      2.7     -1.7      0.8  # V1: pre-test reading # V2: pre-test math # V3: post-test reading # V4: post-test math  power.z.twocors.steiger(rho12 = 0.50, # cor(V1, V2)                         rho13 = 0.70,                         rho23 = 0.40,                         rho14 = 0.40,                         rho24 = 0.70,                         rho34 = 0.60, # cor(V3, V4)                         power = 0.80,                         alpha = 0.05,                         alternative = \"one.sided\",                         common.index = FALSE) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Dependent Correlations #>  #>   Common Index    : FALSE #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho12 - rho34 >= 0 #>   H1 (Alt. Claim) : rho12 - rho34 < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 317  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8  # calculate the effect size cors.to.q(rho1 = 0.60, rho2 = 0.50) #>        q    delta     rho1     rho2  #> 0.143841 0.100000 0.600000 0.500000  # adjust the sample for 5% attrition rate inflate.sample(n = 317, rate = 0.05) #> 334"},{"path":[]},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"r2--0","dir":"","previous_headings":"Omnibus F-Test","what":"R2>0R^2 > 0","title":"Statistical Power and Sample Size Calculation Tools","text":"omnibus F-test multiple linear regression used evaluate whether model whole explains statistically significant portion variance outcome variable. null hypothesis states regression coefficients (except intercept) equal zero means none predictors contributes meaningfully explaining outcome variable (R2R^2 equal zero). Alternative hypothesis states least regression coefficients (except intercept) different zero (R2R^2 greater zero). Example: Assume want predict continuous variable YY using X1X_{1}, X2X_{2}, X2X_{2} variables (can combination binary continuous). Y=β0+β1X1+β2X2+β3X3+r,r∼N(0,σ2)Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + r, \\quad r \\sim N(0, \\sigma ^ 2) interested minimum R2R^2 = 0.10. minimum required sample size? Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY three predictors (X1X_{1}, X2X_{2}, X3X_{3}). interested effect small R2=0.10R^2 = 0.10 using omnibus F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. assumptions, minimum required sample size 103 participants.","code":"power.f.regression(r.squared = 0.10,                    k.total = 3, # number of total predictors                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : R-squared = 0  #>   H1 (Alt. Claim) : R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 103  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.196 #>   Statistical Power    = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"r2--margin","dir":"","previous_headings":"Omnibus F-Test","what":"R2R^2 > Margin","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example. Now, instead testing zero null hypothesis (.e., R2R^2 = 0), aim set practical null hypothesis R2R^2 0.05 (margin = 0.05), representing largest effect size considered practically null. minimum required sample size conditions? Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY three predictors (X1X_{1}, X2X_{2}, X3X_{3}). interested effect small R2R^2 = 0.10 using omnibus F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. R2R^2 < 0.05 considered negligible practical significance. assumptions, minimum required sample size 612 participants.","code":"power.f.regression(r.squared = 0.10,                    margin = 0.05,                    k.total = 3,                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= R-squared <= margin  #>   H1 (Alt. Claim) : R-squared > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 612  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"delta-r2--0","dir":"","previous_headings":"Omnibus F-Test","what":"ΔR2\\Delta R^2 > 0","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Assume want test incremental contribution two additional predictors (X4X_{4} X5X_{5}) existing regression model. , testing whether adding two predictors (k.tested = 2) results significant increase explained variance. full model includes five predictors total (k.total = 5). interested detecting meaningful increase explained variance ΔR2=0.10\\Delta R^2 = 0.10. minimum required sample size criteria? Y=β0+β1X1+β2X2+β3X3+β4X4+β5X5+r,r∼N(0,σ2) Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + \\beta_{4}X_{4} + \\beta_{5}X_{5} + r, \\quad r \\sim N(0, \\sigma ^ 2) Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY five predictors (X1X_{1} X5X_{5}). primary interest testing incremental contribution two predictors (X4X_{4} X5X_{5}), beyond initial model includes X1X_{1}, X2X_{2}, X3X_{3}. Specifically, aim detect increase explained variance ΔR2=0.10\\Delta R^2 = 0.10 using F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. total number predictors final model five (k.total = 5), number predictors tested two (k.tested = 2). assumptions, minimum required sample size 90 participants.","code":"power.f.regression(r.squared.change = 0.10,                    k.total = 5, # number of total predictors                    k.tested = 2, # number of tested predictors                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Hierarchical Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Change in R-squared = 0  #>   H1 (Alt. Claim) : Change in R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 90  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"delta-r2--margin","dir":"","previous_headings":"Omnibus F-Test","what":"ΔR2\\Delta R^2 > Margin","title":"Statistical Power and Sample Size Calculation Tools","text":"Example: Consider earlier example. Now, instead testing zero null hypothesis (.e., ΔR2\\Delta R^2 = 0), aim set practical null hypothesis ΔR2\\Delta R^2 0.05 (margin = 0.05), representing largest effect size considered practically null. minimum required sample size conditions? Report: conducted power analysis determine minimum required sample size detect small meaningful effect multiple linear regression model predicting continuous outcome variable YY five predictors (X1X_{1} X5X_{5}). specific interest lies testing incremental contribution two predictors (X4X_{4} X5X_{5}) beyond initial model containing three predictors (X1X_{1}, X2X_{2}, X3X_{3}). interested detecting increase explained variance ΔR2=0.10\\Delta R^2 = 0.10 using F-test significance level α=0.05\\alpha = 0.05 statistical power 0.80. ΔR2\\Delta R^2 less 0.05 considered negligible practical significance. assumptions, minimum required sample size 606 participants.","code":"power.f.regression(r.squared.change = 0.10,                    margin = 0.05,                    k.total = 5, # number of total predictors                    k.tested = 2, # number of tested predictors                    power = 0.80,                    alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Hierarchical Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= Change in R-squared <= margin  #>   H1 (Alt. Claim) : Change in R-squared > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 606  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"standardized-input","dir":"","previous_headings":"Single Coefficient (T-Test)","what":"Standardized Input","title":"Statistical Power and Sample Size Calculation Tools","text":"earlier example, assume want predict continuous variable YY using continuous predictor X1X_{1} control X2X_{2}, X2X_{2} variables (can combination binary continuous). mainly interested effect X1X_{1} expect standardized regression coefficient β1=0.20\\beta_{1} = 0.20. Y=β0+β1X1+β2X2+β3X3+r,r∼N(0,σ2) Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + r, \\quad r \\sim N(0, \\sigma ^ 2) , expecting three variables explain 30% variance outcome (R2=0.30R^2 = 0.30). minimum required sample size? sufficient provide standardized regression coefficient beta sd.predictor = 1 sd.outcome = 1 default.","code":"power.t.regression(beta = 0.20,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 140  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.198 #>   Statistical Power      = 0.802"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"unstandardized-input","dir":"","previous_headings":"Single Coefficient (T-Test)","what":"Unstandardized Input","title":"Statistical Power and Sample Size Calculation Tools","text":"unstandardized coefficients specify sd.outcome sd.predictor. Assume expecting unstandardized regression coefficient beta = 0.60, standard deviation sd.outcome = 12 outcome standard deviation sd.predictor = 4 main predictor. minimum required sample size? main predictor binary (e.g. treatment / control), standardized regression coefficient Cohen’s d. Standard deviation main predictor p(1−p)\\sqrt{p(1-p)} p proportion sample one groups. Assume half sample first group p=0.50p = 0.50. minimum required sample size? sufficient provide Cohen’s d beta (standardized difference two groups) specify sd.predictor = sqrt(p * (1 - p)) p proportion subjects one groups.","code":"power.t.regression(beta = 0.60,                    sd.outcome = 12,                    sd.predictor = 4,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 140  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.198 #>   Statistical Power      = 0.802 p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 552  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"non-inferiority-3","dir":"","previous_headings":"Single Coefficient (T-Test)","what":"Non-inferiority","title":"Statistical Power and Sample Size Calculation Tools","text":"intervention expected non-inferior earlier interventions. Assume effect earlier intervention beta = 0.10. beta - null.beta expected positive least -0.05 (margin = -0.05). minimum required sample size? case higher values outcome better. lower values outcome better beta - null.beta difference expected NEGATIVE margin takes POSITIVE values.","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    null.beta = 0.10,                    margin = -0.05,                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= margin  #>   H1 (Alt. Claim) : beta - null.beta >  margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 770  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"superiority-2","dir":"","previous_headings":"Single Coefficient (T-Test)","what":"Superiority","title":"Statistical Power and Sample Size Calculation Tools","text":"intervention expected superior earlier interventions. Assume effect earlier intervention beta = 0.10. beta - null.beta expected positive least 0.05 (margin = 0.05). minimum required sample size? case higher values outcome better. lower values outcome better beta - null.beta difference expected NEGATIVE margin takes NEGATIVE values.","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    null.beta = 0.10,                    margin = 0.05,                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= margin  #>   H1 (Alt. Claim) : beta - null.beta >  margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 6934  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"equivalence-4","dir":"","previous_headings":"Single Coefficient (T-Test)","what":"Equivalence","title":"Statistical Power and Sample Size Calculation Tools","text":"intervention expected equivalent earlier interventions. Assume effect earlier intervention beta = 0.20. beta - null.beta expected within -0.05 0.05 (margin = c(-0.05, 0.05)). minimum required sample size?","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    null.beta = 0.20,                    margin = c(-0.05, 0.05),                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= min(margin) or  #>                     beta - null.beta >= max(margin)  #>   H1 (Alt. Claim) : beta - null.beta > min(margin) and  #>                     beta - null.beta < max(margin) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 9593  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"minimum-effect-3","dir":"","previous_headings":"Single Coefficient (T-Test)","what":"Minimum Effect","title":"Statistical Power and Sample Size Calculation Tools","text":"intervention effect expected different smallest value matters policy practice. beta - null.beta expected less -0.05 greater 0.05 (margin = c(-0.05, 0.05)). minimum required sample size?","code":"p <- 0.50 sd.predictor <- sqrt(p * (1 - p))  power.t.regression(beta = 0.20,                    margin = c(-0.05, 0.05),                    sd.predictor = sd.predictor,                    k.total = 3,                    r.squared = 0.30,                    power = .80,                    alpha = 0.05,                    alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta >= min(margin) and  #>                     beta - null.beta <= max(margin)  #>   H1 (Alt. Claim) : beta - null.beta < min(margin) or  #>                     beta - null.beta > max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 981  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"regression-logistic-walds-z-test","dir":"","previous_headings":"","what":"Regression: Logistic (Wald’s Z-Test)","title":"Statistical Power and Sample Size Calculation Tools","text":"logistic regression binary outcome variable (0 / 1: failure / success, dead / alive, absent / present) modeled predicting probability group 1 (P1P_1) via logit transformation (natural logarithm odds). base probability P0P_0 overall probability group 1 without influence predictors model (null). alternative hypothesis, probability group 1 (P1P_1) deviate P0P_0 depending value predictor; whereas null P0P_0. model one main predictor (X1X_1) two covariates (X2X_2 X3X_3) can constructed ln(P11−P1)=β0+β1X1+β2X2+β3X3ln(\\frac{P_1}{1 - P_1}) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} β0=ln(P01−P0)\\beta_0 = ln(\\frac{P_0}{1 - P_0})β1=ln(P11−P1/P01−P0)\\beta_1 = ln(\\frac{P_1}{1 - P_1} / \\frac{P_0}{1 - P_0}) Odds ratio defined =exp(β1)=P11−P1/P01−P0OR = exp(\\beta_1) = \\frac{P_1}{1 - P_1} / \\frac{P_0}{1 - P_0} Example: Assume squared multiple correlation 0.20 X1X_1 covariates (r2..x = 0.20 code). can found form adjusted R-square via regressing X1X_1 X2X_2 X3X_3. Higher values require larger sample sizes. default 0 (zero). base probability P0=0.15P_0 = 0.15. rate predictor X1=0X_1 = 0 β1=0\\beta_1 = 0. Increasing X1X_1 0 1 reduces probability group 1 0.15 0.10 (P1=0.10P_1 = 0.10). minimum required sample size? three types specification statistical power sample size calculations; () probability specification, (ii) odds ratio specification, (iii) regression coefficient specification (standard software output).","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"probability-specification","dir":"","previous_headings":"","what":"Probability Specification","title":"Statistical Power and Sample Size Calculation Tools","text":"","code":"power.z.logistic(prob = 0.10,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 365  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"odds-ratio-specification","dir":"","previous_headings":"","what":"Odds Ratio Specification","title":"Statistical Power and Sample Size Calculation Tools","text":"=P11−P1/P01−P0=0.101−0.10/0.151−0.15=0.6296OR = \\frac{P_1}{1 - P1} / \\frac{P_0}{1 - P_0} = \\frac{0.10}{1 - 0.10} / \\frac{0.15}{1 - 0.15} = 0.6296","code":"power.z.logistic(odds.ratio = 0.6296,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 365  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"regression-coefficient","dir":"","previous_headings":"","what":"Regression Coefficient","title":"Statistical Power and Sample Size Calculation Tools","text":"β1=ln(P11−P1/P01−P0)=ln(0.6296)=−0.4626\\beta_1 = ln(\\frac{P_1}{1 - P1} / \\frac{P_0}{1 - P_0}) = ln(0.6296) = -0.4626","code":"power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 365  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"change-distribution","dir":"","previous_headings":"","what":"Change Distribution","title":"Statistical Power and Sample Size Calculation Tools","text":"Change distribution parameters predictor X: mean standard deviation normally distributed main predictor 0 1 default. can modified. following example mean 20 standard deviation 8. Change distribution family predictor X: distribution types supported function. example, main predictor can binary (e.g. treatment / control groups). Often half sample assigned treatment group half control (prob = 0.50 default). Change treatment group allocation rate binary predictor X (prob = 0.40): per-subject cost treatment group sometimes substantially higher per-subject cost control group. times, difficult recruit subjects treatment whereas plenty subjects considered control group (e.g. long wait-list). cases leeway pick unbalanced sample (much unbalanced). Assume treatment group allocation rate 40%. minimum required sample size?","code":"distribution <- list(dist = \"normal\", mean = 20, sd = 8)  power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 591  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = \"bernoulli\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1723  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 distribution <- list(dist = \"bernoulli\", prob = 0.40)  power.z.logistic(beta1 = -0.4626,                  base.prob = 0.15,                  r.squared.predictor = 0.20,                  power = 0.80,                  alpha = 0.05,                  alternative = \"two.sided\",                  distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1826  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"regression-poisson-walds-z-test","dir":"","previous_headings":"","what":"Regression: Poisson (Wald’s Z-Test)","title":"Statistical Power and Sample Size Calculation Tools","text":"Poisson regression count outcome variable (e.g. number hospital / store / website visits, number absence / dead / purchase day / week / month) modeled predicting incidence rate (λ\\lambda) via logarithmic transformation (natural logarithm rates). model one main predictor (X1X_1) two covariates (X2X_2 X3X_3) can constructed ln(λ)=β0+β1X1+β2X2+β3X3 ln(\\lambda) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} exp(β0)exp(\\beta_0) base incidence rate. β1=ln(λ(X1=1)λ(X1=0))\\beta_1 = ln(\\frac{\\lambda(X_1=1)}{\\lambda(X_1=0)}) Incidence rate ratio defined exp(β1)=λ(X1=1)λ(X1=0)exp(\\beta_1) = \\frac{\\lambda(X_1=1)}{\\lambda(X_1=0)} Assume expected base incidence rate 1.65: exp(0.50)=1.65exp(0.50) = 1.65. Increasing X1X_1 0 1 reduces mean incidence rate 1.65 0.905: exp(−0.10)=0.905exp(-0.10) = 0.905. minimum required sample size? two types specification; () rate ratio specification (exponentiated regression coefficient), (ii) raw regression coefficient specification (standard software output).","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"regression-coefficient-1","dir":"","previous_headings":"","what":"Regression Coefficient","title":"Statistical Power and Sample Size Calculation Tools","text":"","code":"power.z.poisson(beta0 = 0.50,                 beta1 = -0.10,                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 474  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"rate-ratio-specification","dir":"","previous_headings":"","what":"Rate Ratio Specification","title":"Statistical Power and Sample Size Calculation Tools","text":"","code":"power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 474  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"change-distribution-1","dir":"","previous_headings":"","what":"Change Distribution","title":"Statistical Power and Sample Size Calculation Tools","text":"Change distribution’s parameters predictor X: function accommodates types distribution. example, main predictor can binary (e.g. treatment / control groups). Change treatment group allocation rate binary predictor X (prob = 0.40):","code":"distribution <- list(dist = \"normal\", mean = 20, sd = 8)  power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 40  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = \"bernoulli\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2003  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 distribution <- list(dist = \"bernoulli\", prob = 0.40)  power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 power = 0.80,                 alpha = 0.05,                 alternative = \"two.sided\",                 distribution = distribution) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2095  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"regression-mediation-z-test","dir":"","previous_headings":"","what":"Regression: Mediation (Z-Test)","title":"Statistical Power and Sample Size Calculation Tools","text":"simple mediation model can constructed figure. Simple Mediation Model Regression models take form M=β0M+βaX+eY=β0Y+βbM+βcpX+ϵ \\begin{eqnarray} M & = & \\beta_{0M} + \\beta_{} X + e \\\\ Y & = & \\beta_{0Y} + \\beta_{b} M + \\beta_{cp} X + \\epsilon \\end{eqnarray} Y outcome, M mediator, X main predictor. indirect effect product βa\\beta_a βb\\beta_b path coefficients. βcp\\beta_{cp} path coefficient direct effect. Path coefficients can standardized unstandardized. presumed standardized default main predictor, mediator, outcome standard deviations sd.predictor = 1, sd.mediator = 1, sd.outcome = 1 function. Standard deviations specified unstandardized path coefficients (can find values descriptive tables reports / publications).","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"continuous-predictor","dir":"","previous_headings":"","what":"Continuous Predictor","title":"Statistical Power and Sample Size Calculation Tools","text":"software applications presume covariates mediator outcome models (RM2=0R^2_M = 0 RM2=0R^2_M = 0). Even covariates, X explain variance M (RM2>0R^2_M > 0) M & X explains variance Y (RY2>0R^2_Y > 0). almost never R-squared value 0 (zero). explained variance basic mediation model (base R-squared values) can non-trivial taken account function default. Thus, results may seem different software outputs. match results software packages, explicitly specify parameters 0 (zero) (r.squared.mediator = 0 r.squared.outcome = 0). warnings indicating function expects R-squared values greater base R-squared value. Note case beta.cp argument ignored.","code":"# mediation model with base R-squared values power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 244  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801 # base R-squared values are 0 (zero) # do not specify 'cp' power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   r.squared.mediator = 0,                   r.squared.outcome = 0,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 252  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"binary-predictor","dir":"","previous_headings":"","what":"Binary Predictor","title":"Statistical Power and Sample Size Calculation Tools","text":"case main predictor binary can useful practice. researcher might interested whether treatment influence outcome mediators.","code":"p <- 0.50 # proportion of subjects in one of the groups sd.predictor <- sqrt(p * (1 - p))  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 615  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"joint-and-monte-carlo","dir":"","previous_headings":"","what":"Joint and Monte Carlo","title":"Statistical Power and Sample Size Calculation Tools","text":"Joint Monte Carlo tests available power requested.","code":"# binary X p <- 0.50 # proportion of subjects in one of the groups sd.predictor <- sqrt(p * (1 - p))  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   n = 300,                   alpha = 0.05,                   method = \"joint\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Joint #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 300 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.416 #>   Statistical Power    = 0.584  <<  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   n = 300,                   alpha = 0.05,                   method = \"monte.carlo\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Monte Carlo #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 300 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.418 #>   Statistical Power    = 0.582  <<"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"covariate-adjustment","dir":"","previous_headings":"","what":"Covariate Adjustment","title":"Statistical Power and Sample Size Calculation Tools","text":"Covariates can added mediator model, outcome model, . Explanatory power covariates (R-squared values) mediator outcome models can specified via r.squared.mediator r.squared.outcome arguments. experimental design subjects randomly assigned treatment control groups. allocation usually takes place rate 50% (probability 0.50) meaning half sample assigned treatment half control. Thus, mediator model less likely confounder. common add covariates outcome model .","code":"# continuous X power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   r.squared.mediator = 0.50,                   r.squared.outcome = 0.50,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 189  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801 # binary X p <- 0.50 # proportion of subjects in one of the groups sd.predictor <- sqrt(p * (1 - p))  power.z.mediation(beta.a = 0.25,                   beta.b = 0.25,                   sd.predictor = sd.predictor,                   r.squared.outcome = 0.50,                   power = 0.80,                   alpha = 0.05,                   method = \"sobel\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 559  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"anova-f-test","dir":"","previous_headings":"","what":"ANOVA (F-Test)","title":"Statistical Power and Sample Size Calculation Tools","text":"one-way ANOVA, researcher might interested comparing means several groups (levels factor) respect continuous variable. one-way ANCOVA, may want adjust means covariates. Furthermore, may want inspect interaction two three factors (two-way three-way ANOVA), adjust interaction covariates (two-way three-way ANCOVA). following examples illustrate determine minimum required sample size designs.","code":""},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"one-way","dir":"","previous_headings":"Effect Size as Input","what":"One-way","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting difference Cohen’s d = 0.50 treatment control groups (two levels) translating η2=0.059\\eta^2 = 0.059 (eta.squared = 0.059). Means adjusted covariates. minimum required sample size?","code":"power.f.ancova(eta.squared = 0.059,                factor.levels = 2,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"two-way","dir":"","previous_headings":"Effect Size as Input","what":"Two-way","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting partial η2=0.03\\eta^2 = 0.03 (eta.squared = 0.03) interaction treatment / control (Factor : two levels) gender (Factor B: two levels). Thus, factor.levels = c(2,2). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.03,                factor.levels = c(2, 2),                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 256  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"three-way","dir":"","previous_headings":"Effect Size as Input","what":"Three-way","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting partial η2=0.02\\eta^2 = 0.02 (eta.squared = 0.02) interaction treatment / control (Factor : two levels), gender (Factor B: two levels), socio-economic status (Factor C: three levels). Thus, factor.levels = c(2, 2, 3). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.02,                factor.levels = c(2, 2, 3),                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Three-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 480  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"practical-effects","dir":"","previous_headings":"Effect Size as Input","what":"Practical Effects","title":"Statistical Power and Sample Size Calculation Tools","text":"smallest effect size interest policy practice may differ zero. example, want test whether η2=0.02\\eta^2 = 0.02 meaningfully different null value ηNull2=0.01\\eta^2_{\\text{Null}} = 0.01, can specify null.eta.squared = 0.01.","code":"power.f.ancova(eta.squared = 0.02,                null.eta.squared = 0.01,                factor.levels = c(2, 2, 3),                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Three-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= eta.squared <= null.eta.squared  #>   H1 (Alt. Claim) : eta.squared > null.eta.squared #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 3516  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"means-and-sds-as-input","dir":"","previous_headings":"","what":"Means and SDs as Input","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting difference Cohen’s d = 0.50 treatment control groups (two levels) translating η2=0.059\\eta^2 = 0.059, earlier example. Means standard deviations adjusted covariates. minimum required sample size? NOTE: Keppel procedure allows one-way ANOVA.","code":"power.f.ancova.keppel(mu.vector = c(0.50, 0), # vector of means                       sd.vector = c(1, 1), # vector of standard deviations                       p.vector = c(0.50, 0.50), # sample allocation rates                       power = 0.80,                       alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"anova-mixed-effects-f-test","dir":"","previous_headings":"","what":"ANOVA: Mixed-Effects (F-Test)","title":"Statistical Power and Sample Size Calculation Tools","text":"group () effect: researcher might interested comparing means several groups (levels factor) respect outcome variable (continuous) controlling effect time. time effect can thought improvement / grow / loss / deterioration outcome variable happens naturally due unknown causes. time (within) effect: researcher might interested comparing means several time points respect outcome variable controlling group effect. words, change across time points due group membership due improvement / grow / loss / deterioration outcome variable happens naturally due unknown causes. group x time interaction: researcher might suspect means across groups means across time points independent . amount improvement / grow / loss / deterioration outcome variable depends group membership.","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"group-effect-between","dir":"","previous_headings":"","what":"Group Effect (Between)","title":"Statistical Power and Sample Size Calculation Tools","text":"Example 1: post-test design treatment control groups. researcher expecting difference Cohen’s d = 0.50 post-test score treatment control groups, translating η2=0.059\\eta^2 = 0.059. test administered single time point; thus, number repeated measures 1. minimum required sample size?","code":"power.f.mixed.anova(eta.squared = 0.059,                     factor.levels = c(2, 1), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"time-effect-within","dir":"","previous_headings":"","what":"Time Effect (Within)","title":"Statistical Power and Sample Size Calculation Tools","text":"Example 2: Pre-test vs. post-test design treatment group . researcher expecting difference Cohen’s d = 0.30 post-test pre-test scores, translating η2=0.022\\eta^2 = 0.022. test administered treatment; thus, number repeated measures 2. treatment group control group. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size?","code":"power.f.mixed.anova(eta.squared = 0.022,                     factor.levels = c(1, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"within\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Repeated Measures Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 90  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"group-x-time-interaction","dir":"","previous_headings":"","what":"Group x Time Interaction","title":"Statistical Power and Sample Size Calculation Tools","text":"Example 3: Pre-test vs.post-test control-group design. researcher expecting difference Cohen’s d = 0.40 post-test scores treatment control groups controlling pre-test, translating partial η2=0.038\\eta^2 = 0.038. test administered treatment; thus, number repeated measures 2. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size? researcher expecting difference Cohen’s d = 0.30 post-test pre-test scores controlling group membership, translating partial η2=0.022\\eta^2 = 0.022. treatment control groups. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size? rationale inspecting interaction benefit treatment may depend pre-test score (e.g. higher scores pre-test improve deteriorate ). researcher expecting interaction effect partial η2=0.01\\eta^2 = 0.01. test administered treatment; thus, number repeated measures 2. treatment control groups. researcher also expects correlation 0.50 pre-test post-test scores. minimum required sample size?","code":"power.f.mixed.anova(eta.squared = 0.038,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 152  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803 power.f.mixed.anova(eta.squared = 0.022,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"within\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 90  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 power.f.mixed.anova(eta.squared = 0.01,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = 0.50,                     effect = \"interaction\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 198  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"adjusted-eta-squared","dir":"","previous_headings":"","what":"Adjusted Eta-squared","title":"Statistical Power and Sample Size Calculation Tools","text":"possible η2\\eta^2 already adjusted within-subject correlation. case instead using unadjusted η2=0.038\\eta^2 = 0.038 use adjusted η2=0.05\\eta^2 = 0.05 specify rho.within = NA.","code":"power.f.mixed.anova(eta.squared = 0.05,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = NA,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 152  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"practical-effects-1","dir":"","previous_headings":"","what":"Practical Effects","title":"Statistical Power and Sample Size Calculation Tools","text":"smallest effect size interest policy practice may differ zero. example, want test whether η2=0.05\\eta^2 = 0.05 meaningfully different null value ηNull2=0.01\\eta^2_{\\text{Null}} = 0.01, can specify null.eta.squared = 0.01.","code":"power.f.mixed.anova(eta.squared = 0.05,                     null.eta.squared = 0.01,                     factor.levels = c(2, 2), # c(\"between\", \"within\")                     power = 0.80,                     alpha = 0.05,                     rho.within = NA,                     effect = \"between\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= eta.squared <= null.eta.squared  #>   H1 (Alt. Claim) : eta.squared > null.eta.squared #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 380  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":[]},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"one-way-1","dir":"","previous_headings":"Effect Size as Input","what":"One-way","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting adjusted difference Cohen’s d = 0.45 treatment control groups (factor.levels = 2) controlling pre-test (k.covariates = 1) translating partial η2=0.048\\eta^2 = 0.048. minimum required sample size?","code":"power.f.ancova(eta.squared = 0.048,                factor.levels = 2,                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 158  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"two-way-1","dir":"","previous_headings":"","what":"Two-way","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting partial η2=0.02\\eta^2 = 0.02 interaction treatment / control (Factor ) gender (Factor B) adjusted pre-test (k.covariates = 1). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.02,                factor.levels = c(2, 2),                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 388  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"three-way-1","dir":"","previous_headings":"","what":"Three-way","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting partial η2=0.01\\eta^2 = 0.01 interaction treatment / control (Factor ), gender (Factor B), socio-economic status (Factor C: three levels) adjusted pre-test (k.covariates = 1). minimum required sample size?","code":"power.f.ancova(eta.squared = 0.01,                factor.levels = c(2, 2, 3),                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Three-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 960  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"practical-effects-2","dir":"","previous_headings":"","what":"Practical Effects","title":"Statistical Power and Sample Size Calculation Tools","text":"smallest effect size interest policy practice may differ zero. example, want test whether η2=0.048\\eta^2 = 0.048 meaningfully different null value ηNull2=0.01\\eta^2_{\\text{Null}} = 0.01, can specify null.eta.squared = 0.01.","code":"power.f.ancova(eta.squared = 0.048,                null.eta.squared = 0.01,                factor.levels = 2,                k.covariates = 1,                power = 0.80,                alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : 0 <= eta.squared <= null.eta.squared  #>   H1 (Alt. Claim) : eta.squared > null.eta.squared #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 410  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"keppel-procedure","dir":"","previous_headings":"","what":"Keppel Procedure","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting adjusted difference Cohen’s d = 0.318 treatment control groups controlling pre-test (k.covariates = 1) explanatory power covariates (r.squared = 0.50). translates partial η2=0.048\\eta^2 = 0.048. minimum required sample size? NOTE: Keppel procedure allows one-way ANOVA.","code":"power.f.ancova.keppel(mu.vector = c(0.318, 0), # vector of adjusted means                       sd.vector = c(1, 1), # vector of unadjusted standard deviations                       p.vector = c(0.50, 0.50), # sample allocation rates                       r.squared = 0.50,                       k.covariates = 1,                       power = 0.80,                       alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 158  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"one-way-2","dir":"","previous_headings":"Shieh Procedure","what":"One-way","title":"Statistical Power and Sample Size Calculation Tools","text":"researcher expecting adjusted difference Cohen’s d = 0.318 treatment control groups controlling pre-test (k.covariates = 1) explanatory power covariates (r.squared = 0.50). translates partial η2=0.048\\eta^2 = 0.048. minimum required sample size?","code":"power.f.ancova.shieh(mu.vector = c(0.318, 0), # vector of adjusted means                       sd.vector = c(1, 1), # vector of unadjusted standard deviations                       p.vector = c(0.50, 0.50), # sample allocation rates                       r.squared = 0.50,                       k.covariates = 1,                       power = 0.80,                       alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 160  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.195 #>   Statistical Power      = 0.805"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"two-way-2","dir":"","previous_headings":"Shieh Procedure","what":"Two-way","title":"Statistical Power and Sample Size Calculation Tools","text":"Assume cell means interaction treatment / control (Factor ) gender (Factor B) adjusted pre-test (k.covariates = 1) explanatory power covariate (r.squared = 0.50) 0.30, 0.09, 0.05, 0.245, corresponding cells A1:B1, A1:B2, A2:B1, A2:B2, respectively, unit standard deviation . translates partial η2=0.02\\eta^2 = 0.02. minimum required sample size?","code":"power.f.ancova.shieh(mu.vector = c(0.30, 0.09, 0.05, 0.245), # vector of adjusted means                      sd.vector = c(1, 1, 1, 1), # vector of unadjusted standard deviations                      p.vector = c(0.25, 0.25, 0.25, 0.25), # sample allocation rates                      factor.levels = c(2, 2),                      r.squared = 0.50,                      k.covariates = 1,                      power = 0.80,                      alpha = 0.05) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 388  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"dummy-coding","dir":"","previous_headings":"","what":"Dummy Coding","title":"Statistical Power and Sample Size Calculation Tools","text":"","code":"contr.obj <- factorial.contrasts(factor.levels = 3,                                  coding = \"treatment\") #>    A1 A2 A3 #> A1  1  0 -1 #> A2  0  1 -1  # get contrast matrix from the contrast object contrast.matrix <- contr.obj$contrast.matrix  # calculate sample size given design characteristics design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                sd.vector = c(1, 1, 1), # unadjusted standard deviations                                p.vector = c(1 / 3, 1 / 3, 1 / 3), # sample allocation rate                                contrast.matrix = contrast.matrix,                                r.squared = 0.50,                                k.covariates = 1,                                alpha = 0.05,                                power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # power of planned contrasts, adjusted for alpha level power.t.contrasts(design, adjust.alpha = \"fdr\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr comparison   psi      d    ncp n.total power #>      1  A1 <=> A3 -0.05 -0.071 -1.018    1245 0.111 #>      2  A2 <=> A3  0.10  0.141  2.036    1245 0.418"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"helmert-coding","dir":"","previous_headings":"","what":"Helmert Coding","title":"Statistical Power and Sample Size Calculation Tools","text":"","code":"contr.obj <- factorial.contrasts(factor.levels = 3,                                  coding = \"helmert\") #>        A1     A2    A3 #> A1 -0.500  0.500 0.000 #> A2 -0.167 -0.167 0.333  # get contrast matrix from the contrast object contrast.matrix <- contr.obj$contrast.matrix  # calculate sample size given design characteristics design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                sd.vector = c(1, 1, 1), # unadjusted standard deviations                                p.vector = c(1 / 3, 1 / 3, 1 / 3), # allocation, should sum to 1                                contrast.matrix = contrast.matrix,                                r.squared = 0.50, # proportion of variance explained by covariates                                k.covariates = 1, # number of covariates                                alpha = 0.05,                                power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # power of planned contrasts power.t.contrasts(design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1    A2 <=> A1  0.075  0.106  3.055    1245 0.863 #>      2 A3 <=> A1 A2 -0.008 -0.012 -0.588    1245 0.090"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"polynomial-coding","dir":"","previous_headings":"","what":"Polynomial Coding","title":"Statistical Power and Sample Size Calculation Tools","text":"","code":"contr.obj <- factorial.contrasts(factor.levels = 3,                                  coding = \"poly\") #>         A1     A2    A3 #> A.L -0.707  0.000 0.707 #> A.Q  0.408 -0.816 0.408  # get contrast matrix from the contrast object contrast.matrix <- contr.obj$contrast.matrix  # calculate sample size given design characteristics design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                sd.vector = c(1, 1, 1), # unadjusted standard deviations                                p.vector = c(1 / 3, 1 / 3, 1 / 3), # allocation, should sum to 1                                contrast.matrix = contrast.matrix,                                r.squared = 0.50, # proportion of variance explained by covariates                                k.covariates = 1, # number of covariates                                alpha = 0.05,                                power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # power of the planned contrasts power.t.contrasts(design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1    A3 <=> A1  0.035  0.050  1.018    1245 0.174 #>      2 A1 A3 <=> A2 -0.102 -0.144 -2.939    1245 0.836"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"custom-contrasts","dir":"","previous_headings":"","what":"Custom Contrasts","title":"Statistical Power and Sample Size Calculation Tools","text":"","code":"# custom contrasts contrast.matrix <- rbind(   cbind(A1 = 1, A2 = -0.50, A3 = -0.50),   cbind(A1 = 0.50, A2 = 0.50, A3 = -1) ) # labels are not required for custom contrasts, # but they make it easier to understand power.t.contrasts() output  # calculate sample size given design characteristics design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                sd.vector = c(1, 1, 1), # unadjusted standard deviations                                p.vector = c(1 / 3, 1 / 3, 1 / 3), # allocation, should sum to 1                                contrast.matrix = contrast.matrix,                                r.squared = 0.50, # proportion of variance explained by covariates                                k.covariates = 1, # number of covariates                                alpha = 0.05,                                power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801  # power of the planned contrasts power.t.contrasts(design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1 A1 <=> A2 A3 -0.100 -0.141 -2.351    1245 0.652 #>      2 A1 A2 <=> A3  0.025  0.035  0.588    1245 0.090"},{"path":[]},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"vector-of-k-cells","dir":"","previous_headings":"","what":"Vector of k Cells","title":"Statistical Power and Sample Size Calculation Tools","text":"Effect size: Cohen’s W goodness--fit test (1 x k k x 1 table). many subjects needed claim girls choose STEM related majors less males? Check original article https://www.aauw.org/issues/education/stem/ Alternative hypothesis state 28% workforce STEM field women whereas 72% men (article). null hypothesis assume 50% women 50% men.","code":"prob.matrix <- c(0.28, 0.72)  probs.to.w(prob.matrix = prob.matrix) #>    w   df  #> 0.44 1.00 # Degrees of freedom is k - 1 for Cohen's w.  power.chisq.gof(w = 0.44,                 df = 1,                 alpha = 0.05,                 power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 41  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"contingency-table-2-x-2","dir":"","previous_headings":"","what":"Contingency Table: 2 x 2","title":"Statistical Power and Sample Size Calculation Tools","text":"Effect size: Phi Coefficient (Cramer’s V Cohen’s W) independence test (2 x 2 contingency table). many subjects needed claim girls -diagnosed ADHD? Check original article https://time.com/growing---adhd/ 5.6% girls 13.2% boys diagnosed ADHD (article).","code":"prob.matrix <- rbind(c(0.056, 0.132),                   c(0.944, 0.868)) colnames(prob.matrix) <- c(\"Girl\", \"Boy\") rownames(prob.matrix) <- c(\"ADHD\", \"No ADHD\") prob.matrix #>          Girl   Boy #> ADHD    0.056 0.132 #> No ADHD 0.944 0.868  probs.to.w(prob.matrix = prob.matrix) #>         w        df  #> 0.1302134 1.0000000 # Degrees of freedom is 1 for Phi coefficient.  power.chisq.gof(w = 0.1302134,                 df = 1,                 alpha = 0.05,                 power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 463  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"contingency-table-j-x-k","dir":"","previous_headings":"","what":"Contingency Table: j x k","title":"Statistical Power and Sample Size Calculation Tools","text":"Effect size: Cramer’s V (Cohen’s W) independence test (j x k contingency tables). many subjects needed detect relationship depression severity gender? Check original article https://doi.org/10.1016/j.jad.2019.11.121  Please send bug reports, feedback questions bulusmetin [] gmail.com. Changelog","code":"prob.matrix <- cbind(c(0.6759, 0.1559, 0.1281, 0.0323, 0.0078),                   c(0.6771, 0.1519, 0.1368, 0.0241, 0.0101)) rownames(prob.matrix) <- c(\"Normal\", \"Mild\", \"Moderate\", \"Severe\", \"Extremely Severe\") colnames(prob.matrix) <- c(\"Female\", \"Male\") prob.matrix #>                  Female   Male #> Normal           0.6759 0.6771 #> Mild             0.1559 0.1519 #> Moderate         0.1281 0.1368 #> Severe           0.0323 0.0241 #> Extremely Severe 0.0078 0.0101  probs.to.w(prob.matrix = prob.matrix) #>          w         df  #> 0.03022008 4.00000000 # Degrees of freedom is (nrow - 1) * (ncol - 1) for Cramer's V.  power.chisq.gof(w = 0.03022008,                 df = 4,                 alpha = 0.05,                 power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 13069  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8"},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"authors","dir":"","previous_headings":"","what":"Authors","title":"Statistical Power and Sample Size Calculation Tools","text":"Metin BulusSebastian Jentschke","code":""},{"path":"https://metinbulus.github.io/pwrss/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Statistical Power and Sample Size Calculation Tools","text":"work licensed GPL 3.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for One-, Two-, Three-Way ANCOVA Contrasts and Multiple Comparisons (T-Tests) — pwrss.t.contrasts","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Contrasts and Multiple Comparisons (T-Tests) — pwrss.t.contrasts","text":"Calculates power sample size one-, two-, three-Way ANCOVA contrasts multiple comparisons. pwrss.t.contrast() function allows single contrast. multiple contrast testing (multiple comparisons) use pwrss.t.contrasts() function. pwrss.t.contrasts() function also allows adjustment alpha due multiple testing. arguments earlier function except accepts object returned pwrss.f.ancova.shieh() function convenience. Beware , case, arguments ignored except alpha adjust.alpha. pwrss.t.contrasts() function returns data frame many rows number contrasts eight columns names 'contrast', 'comparison', 'psi', 'd', 'ncp', 'df', 'n.total', 'power'. 'psi' contrast estimate. 'd'  standardized contrast estimate. Remaining parameters explained elsewhere. Note R partial matching feature allows specify shortened versions arguments, mu mu.vec instead mu.vector, k k.cov instead k.covariates. Formulas validated using examples tables Shieh (2017).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Contrasts and Multiple Comparisons (T-Tests) — pwrss.t.contrasts","text":"","code":"power.t.contrast(mu.vector,                  sd.vector,                  contrast.vector,                  n.vector = NULL, p.vector = NULL,                  r.squared = 0, k.covariates = 1,                  power = NULL, alpha = 0.05,                  tukey.kramer = FALSE,                  ceiling = TRUE, verbose = TRUE, pretty = FALSE)  power.t.contrasts(x = NULL,                   mu.vector = NULL,                   sd.vector = NULL,                   n.vector = NULL, p.vector = NULL,                   r.squared = 0, k.covariates = 1,                   contrast.matrix = NULL,                   power = NULL, alpha = 0.05,                   adjust.alpha = c(\"none\", \"tukey\", \"bonferroni\",                                    \"holm\", \"hochberg\", \"hommel\",                                    \"BH\", \"BY\", \"fdr\"),                   ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Contrasts and Multiple Comparisons (T-Tests) — pwrss.t.contrasts","text":"x object; object returned pwrss.f.ancova.shieh() function. mu.vector vector; adjusted means (estimated marginal means) level factor. Ignored 'x' specified. sd.vector vector; unadjusted standard deviations level factor. Ignored 'x' specified. n.vector vector; sample sizes level factor. Ignored 'x' specified. p.vector vector; proportion total sample size level factor. proportions sum one. Ignored 'x' specified. r.squared explanatory power covariates (R-squared) ANCOVA model. Ignored 'x' specified. k.covariates Number covariates ANCOVA model. Ignored 'x' specified. contrast.vector vector; single contrast form vector many elements number levels groups (cells factorial designs). Ignored 'x' specified. contrast.matrix vector matrix; contrasts confused model (design) matrix. Rows contrast matrix indicate independent vector contrasts summing zero. default contrast matrix constructed using deviation coding scheme (.k.. effect coding). Columns contrast matrix indicate number levels groups (cells factorial designs). Ignored 'x' specified. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). Ignored 'x' specified. alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). Note specified even 'x' specified. 'alpha' value within 'x' object pertains omnibus test, test contrasts. tukey.kramer logical; TRUE default. FALSE adjustment made control Type 1 error. adjust.alpha character; one methods c(\"none\", \"tukey\", \"bonferroni\", \"holm\", \"hochberg\", \"hommel\", \"BH\", \"\", \"fdr\") control Type 1 error. See ?stats::p.adjust. ceiling logical;  TRUE default. FALSE sample size cell rounded . verbose logical; TRUE default. FALSE output printed console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Contrasts and Multiple Comparisons (T-Tests) — pwrss.t.contrasts","text":"parms list parameters used calculation. test type statistical test (T-Test). psi contrast-weighted mean difference. d contrast-weighted standardized mean difference. df degrees freedom. t.alpha critical values. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. power statistical power \\((1-\\beta)\\). n.total total sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.contrasts.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Contrasts and Multiple Comparisons (T-Tests) — pwrss.t.contrasts","text":"Shieh, G. (2017). Power sample size calculations contrast analysis ANCOVA. Multivariate Behavioral Research, 52(1), 1-11. doi:10.1080/00273171.2016.1219841","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Contrasts and Multiple Comparisons (T-Tests) — pwrss.t.contrasts","text":"","code":"###################################################################   #######################  planned contrasts  #######################   ###################################################################    #########################   ## dummy coding scheme ##   #########################    contrast.object <- factorial.contrasts(factor.levels = 3, # one factor w/ 3 levels                                          coding = \"treatment\") # use dummy coding scheme #>    A1 A2 A3 #> A1  1  0 -1 #> A2  0  1 -1    # get contrast matrix from the contrast object   contrast.matrix <- contrast.object$contrast.matrix    # calculate sample size given design characteristics   ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30,  0.20), # marginal means                                         sd.vector = c(1, 1, 1), # unadjusted standard deviations                                         p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                         contrast.matrix = contrast.matrix,                                         r.squared = 0.50,                                         k.covariates = 1,                                         alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>     # power of planned contrasts, adjusted for alpha level   power.t.contrasts(ancova.design, adjust.alpha = \"fdr\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr comparison   psi      d    ncp n.total power #>      1  A1 <=> A3 -0.05 -0.071 -1.018    1245 0.111 #>      2  A2 <=> A3  0.10  0.141  2.036    1245 0.418 #>     ###########################   ## Helmert coding scheme ##   ###########################    contrast.object <- factorial.contrasts(factor.levels = 3, # one factor w/ 4 levels                                          coding = \"helmert\") # use helmert coding scheme #>        A1     A2    A3 #> A1 -0.500  0.500 0.000 #> A2 -0.167 -0.167 0.333    # get contrast matrix from the contrast object   contrast.matrix <- contrast.object$contrast.matrix    # calculate sample size given design characteristics   ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30,  0.20), # marginal means                                         sd.vector = c(1, 1, 1), # unadjusted standard deviations                                         p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                         contrast.matrix = contrast.matrix,                                         r.squared = 0.50,                                         k.covariates = 1,                                         alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>     # power of planned contrasts   power.t.contrasts(ancova.design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1    A2 <=> A1  0.075  0.106  3.055    1245 0.863 #>      2 A3 <=> A1 A2 -0.008 -0.012 -0.588    1245 0.090 #>     ##############################   ## polynomial coding scheme ##   ##############################    contrast.object <- factorial.contrasts(factor.levels = 3, # one factor w/ 4 levels                                          coding = \"poly\") # use polynomial coding scheme #>         A1     A2    A3 #> A.L -0.707  0.000 0.707 #> A.Q  0.408 -0.816 0.408    # get contrast matrix from the contrast object   contrast.matrix <- contrast.object$contrast.matrix    # calculate sample size given design characteristics   ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                         sd.vector = c(1, 1, 1), # unadjusted standard deviations                                         p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                         contrast.matrix = contrast.matrix,                                         r.squared = 0.50,                                         k.covariates = 1,                                         alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>     # power of the planned contrasts   power.t.contrasts(ancova.design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1    A3 <=> A1  0.035  0.050  1.018    1245 0.174 #>      2 A1 A3 <=> A2 -0.102 -0.144 -2.939    1245 0.836 #>     ######################   ## custom contrasts ##   ######################    # custom contrasts   contrast.matrix <- rbind(     cbind(A1 = 1, A2 = -0.50, A3 = -0.50),     cbind(A1 = 0.50, A2 = 0.50, A3 = -1)   )   # labels are not required for custom contrasts,   # but they make it easier to understand power.t.contrasts() output    # calculate sample size given design characteristics   ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                         sd.vector = c(1, 1, 1), # unadjusted standard deviations                                         p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                         contrast.matrix = contrast.matrix,                                         r.squared = 0.50,                                         k.covariates = 1,                                         alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>     # power of the planned contrasts   power.t.contrasts(ancova.design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1 A1 <=> A2 A3 -0.100 -0.141 -2.351    1245 0.652 #>      2 A1 A2 <=> A3  0.025  0.035  0.588    1245 0.090 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.factorial.contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Factorial Contrasts — factorial.contrasts","title":"Factorial Contrasts — factorial.contrasts","text":"Helper function construct default contrast coefficients various coding schemes. Note R partial matching feature allows specify shortened versions arguments, coding instead coding.scheme. Validated using lm() aov() functions.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.factorial.contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Factorial Contrasts — factorial.contrasts","text":"","code":"factorial.contrasts(factor.levels = c(3, 2),                     coding.scheme = rep(\"deviation\", length(factor.levels)),                     base = factor.levels,                     intercept = FALSE,                     verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.factorial.contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Factorial Contrasts — factorial.contrasts","text":"factor.levels Integer. Number levels groups factor. example, two factors two levels groups use e.g. c(2, 2), three factors two levels groups use e.g. c(2, 2, 2) coding.scheme Character vector. Coding scheme factor. \"sum\" deviation effect coding, \"treatment\" dummy coding, \"helmert\" Helmert type coding, \"poly\" polynomial coding. factor can coding scheme. single character value provided, copied factors base Integer vector. Specifies group considered baseline group. Ignored coding schemes \"treatment\" intercept Logical. FALSE default. TRUE contrast matrix includes intercept verbose Logical. TRUE default. FALSE output printed console","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.factorial.contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Factorial Contrasts — factorial.contrasts","text":"factor.levels Number levels (groups) factor factor.data Unique combination factor levels model.matrix Model (design) matrix based unique combination factor levels contrast.matrix Contrast matrix","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.factorial.contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Factorial Contrasts — factorial.contrasts","text":"","code":"################################################### ############### dummy coding scheme ############### ####################################################  # one factor w/ 3 levels contrast.object <- factorial.contrasts(factor.levels = 3,                                        coding = \"treatment\") #>    A1 A2 A3 #> A1  1  0 -1 #> A2  0  1 -1 # model matrix contrast.object$model.matrix #>   (Intercept) A1 A2 #> 1           1  1  0 #> 2           1  0  1 #> 3           1  0  0 #> attr(,\"assign\") #> [1] 0 1 1 #> attr(,\"contrasts\") #> attr(,\"contrasts\")$A #>   1 2 #> 1 1 0 #> 2 0 1 #> 3 0 0 #>   # contrast matrix contrast.object$contrast.matrix #>    A1 A2 A3 #> A1  1  0 -1 #> A2  0  1 -1  ####################################################### ###############  deviation coding scheme ############## #######################################################  # especially useful for factorial designs # two factors w/ 2 and 3 levels, respectively contrast.object <- factorial.contrasts(factor.levels = c(2, 3),                                        coding = \"sum\") #> Assuming the same coding scheme applies to the other factor(s) #> Elements of `mu.vector`, `sd.vector`, `n.vector` or `p.vector` should follow this specific order: #> A1:B1  A1:B2  A1:B3  A2:B1  A2:B2  A2:B3   #>        A1:B1  A1:B2  A1:B3  A2:B1  A2:B2  A2:B3 #> A1     0.167  0.167  0.167 -0.167 -0.167 -0.167 #> B1     0.333 -0.167 -0.167  0.333 -0.167 -0.167 #> B2    -0.167  0.333 -0.167 -0.167  0.333 -0.167 #> A1:B1  0.333 -0.167 -0.167 -0.333  0.167  0.167 #> A1:B2 -0.167  0.333 -0.167  0.167 -0.333  0.167  # model matrix contrast.object$model.matrix #>   (Intercept) A1 B1 B2 A1:B1 A1:B2 #> 1           1  1  1  0     1     0 #> 2           1  1  0  1     0     1 #> 3           1  1 -1 -1    -1    -1 #> 4           1 -1  1  0    -1     0 #> 5           1 -1  0  1     0    -1 #> 6           1 -1 -1 -1     1     1 #> attr(,\"assign\") #> [1] 0 1 2 2 3 3 #> attr(,\"contrasts\") #> attr(,\"contrasts\")$A #>   [,1] #> 1    1 #> 2   -1 #>  #> attr(,\"contrasts\")$B #>   [,1] [,2] #> 1    1    0 #> 2    0    1 #> 3   -1   -1 #>   # contrast matrix contrast.object$contrast.matrix #>            A1:B1      A1:B2      A1:B3      A2:B1      A2:B2      A2:B3 #> A1     0.1666667  0.1666667  0.1666667 -0.1666667 -0.1666667 -0.1666667 #> B1     0.3333333 -0.1666667 -0.1666667  0.3333333 -0.1666667 -0.1666667 #> B2    -0.1666667  0.3333333 -0.1666667 -0.1666667  0.3333333 -0.1666667 #> A1:B1  0.3333333 -0.1666667 -0.1666667 -0.3333333  0.1666667  0.1666667 #> A1:B2 -0.1666667  0.3333333 -0.1666667  0.1666667 -0.3333333  0.1666667   ###################################################### ###############  Helmert coding scheme ############### ######################################################  # one factor w/ 3 levels contrast.object <- factorial.contrasts(factor.levels = 3,                                        coding = \"helmert\") #>        A1     A2    A3 #> A1 -0.500  0.500 0.000 #> A2 -0.167 -0.167 0.333  # model matrix contrast.object$model.matrix #>   (Intercept) A1 A2 #> 1           1 -1 -1 #> 2           1  1 -1 #> 3           1  0  2 #> attr(,\"assign\") #> [1] 0 1 1 #> attr(,\"contrasts\") #> attr(,\"contrasts\")$A #>   [,1] [,2] #> 1   -1   -1 #> 2    1   -1 #> 3    0    2 #>   # contrast matrix contrast.object$contrast.matrix #>            A1         A2        A3 #> A1 -0.5000000  0.5000000 0.0000000 #> A2 -0.1666667 -0.1666667 0.3333333  ######################################################### ###############  polynomial coding scheme ############### #########################################################  # one factor w/ 3 levels contrast.object <- factorial.contrasts(factor.levels = 3,                                        coding = \"poly\") #>         A1     A2    A3 #> A.L -0.707  0.000 0.707 #> A.Q  0.408 -0.816 0.408  # model matrix contrast.object$model.matrix #>   (Intercept)           A.L        A.Q #> 1           1 -7.071068e-01  0.4082483 #> 2           1 -7.850462e-17 -0.8164966 #> 3           1  7.071068e-01  0.4082483 #> attr(,\"assign\") #> [1] 0 1 1 #> attr(,\"contrasts\") #> attr(,\"contrasts\")$A #>              .L         .Q #> 1 -7.071068e-01  0.4082483 #> 2 -7.850462e-17 -0.8164966 #> 3  7.071068e-01  0.4082483 #>   # contrast matrix contrast.object$contrast.matrix #>             A1         A2        A3 #> A.L -0.7071068  0.0000000 0.7071068 #> A.Q  0.4082483 -0.8164966 0.4082483"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for One-, Two-, Three-Way ANOVA/ANCOVA Using Effect Size (F-Test) — power.f.ancova","title":"Power Analysis for One-, Two-, Three-Way ANOVA/ANCOVA Using Effect Size (F-Test) — power.f.ancova","text":"Calculates power sample size one-way, two-way, three-way ANOVA/ANCOVA. Set k.cov = 0 ANOVA, k.cov > 0 ANCOVA. Note latter, effect size (eta.squared obtained relevant ANCOVA model, already adjusted explanatory power covariates (thus, additional R-squared argument required input). Note R partial matching feature allows specify shortened versions arguments, k k.cov instead k.covariates. Formulas validated using G*Power tables PASS documentation.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for One-, Two-, Three-Way ANOVA/ANCOVA Using Effect Size (F-Test) — power.f.ancova","text":"","code":"power.f.ancova(eta.squared,                null.eta.squared = 0,                factor.levels = 2,                k.covariates = 0,                n.total = NULL,                power = NULL,                alpha = 0.05,                ceiling = TRUE,                verbose = TRUE,                pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for One-, Two-, Three-Way ANOVA/ANCOVA Using Effect Size (F-Test) — power.f.ancova","text":"eta.squared (partial) eta-squared alternative. null.eta.squared (partial) eta-squared null. factor.levels integer; number levels groups factor. example, two factors two levels groups use e.g. c(2, 2), three factors two levels (groups) use e.g. c(2, 2, 2). k.covariates integer; number covariates ANCOVA model. n.total integer; total sample size power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). ceiling logical; FALSE sample size cell rounded . verbose logical; FALSE output printed console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for One-, Two-, Three-Way ANOVA/ANCOVA Using Effect Size (F-Test) — power.f.ancova","text":"parms list parameters used calculation. test type statistical test (F-Test). df1 numerator degrees freedom. df2 denominator degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. f.alpha critical value. power statistical power \\((1-\\beta)\\). n.total total sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for One-, Two-, Three-Way ANOVA/ANCOVA Using Effect Size (F-Test) — power.f.ancova","text":"Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913 Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for One-, Two-, Three-Way ANOVA/ANCOVA Using Effect Size (F-Test) — power.f.ancova","text":"","code":"############################################# #              one-way ANOVA                # #############################################  # Cohen's d = 0.50 between treatment and control # translating into Eta-squared = 0.059  # estimate sample size using ANOVA approach power.f.ancova(eta.squared = 0.059,                factor.levels = 2,                alpha = 0.05, power = .80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803 #>   # estimate sample size using regression approach(F-Test) power.f.regression(r.squared = 0.059,                    k.total = 1,                    alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : R-squared = 0  #>   H1 (Alt. Claim) : R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 128  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.197 #>   Statistical Power    = 0.803 #>   # estimate sample size using regression approach (T-Test) p <- 0.50 # proportion of sample in treatment (allocation rate) power.t.regression(beta = 0.50, r.squared = 0,                    k.total = 1,                    sd.predictor = sqrt(p*(1-p)),                    alpha = 0.05, power = 0.80) #> Warning: `r.squared` is possibly larger. #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.199 #>   Statistical Power      = 0.801 #>   # estimate sample size using t test approach power.t.student(d = 0.50, alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 64 and 64  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ############################################# #              two-way ANOVA                # #############################################  # a researcher is expecting a partial Eta-squared = 0.03 # for interaction of treatment (Factor A) with # gender consisting of two levels (Factor B)  power.f.ancova(eta.squared = 0.03,                factor.levels = c(2,2),                alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 256  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   # estimate sample size using regression approach (F test) # one dummy for treatment, one dummy for gender, and their interaction (k = 3) # partial Eta-squared is equivalent to the increase in R-squared by adding # only the interaction term (m = 1) power.f.regression(r.squared = 0.03,                    k.total = 3, k.test = 1,                    alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Hierarchical Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Change in R-squared = 0  #>   H1 (Alt. Claim) : Change in R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 256  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   ############################################# #              one-way ANCOVA               # #############################################  # a researcher is expecting an adjusted difference of # Cohen's d = 0.45 between treatment and control after # controllling for the pretest (k.cov = 1) # translating into Eta-squared = 0.048  power.f.ancova(eta.squared = 0.048,                factor.levels = 2,                k.covariates = 1,                alpha = 0.05, power = .80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 158  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ############################################# #              two-way ANCOVA               # #############################################  # a researcher is expecting an adjusted partial Eta-squared = 0.02 # for interaction of treatment (Factor A) with # gender consisting of two levels (Factor B)  power.f.ancova(eta.squared = 0.02,                factor.levels = c(2,2),                k.covariates = 1,                alpha = 0.05, power = .80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 388  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.keppel.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for One-Way ANOVA/ANCOVA Using Means and Standard Deviations (F test) — power.f.ancova.keppel","title":"Power Analysis for One-Way ANOVA/ANCOVA Using Means and Standard Deviations (F test) — power.f.ancova.keppel","text":"Calculates power sample size one-way ANOVA/ANCOVA. Set k.cov = 0 one-way ANOVA (without pretest covariate adjustment). Set k.cov > 0 combination  r2 > 0 one-way ANCOVA (pretest covariate adjustment). Note R partial matching feature allows specify shortened versions arguments, mu mu.vec instead mu.vector, k k.cov instead k.covariates. Formulas validated using PASS documentation.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.keppel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for One-Way ANOVA/ANCOVA Using Means and Standard Deviations (F test) — power.f.ancova.keppel","text":"","code":"power.f.ancova.keppel(mu.vector, sd.vector,                       n.vector = NULL, p.vector = NULL,                       factor.levels = length(mu.vector),                       r.squared = 0, k.covariates = 0,                       power = NULL, alpha = 0.05,                       ceiling = TRUE, verbose = TRUE,                       pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.keppel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for One-Way ANOVA/ANCOVA Using Means and Standard Deviations (F test) — power.f.ancova.keppel","text":"mu.vector vector adjusted means (estimated marginal means) level factor. sd.vector vector unadjusted standard deviations level factor. n.vector vector sample sizes level factor. p.vector vector proportion total sample size level factor. proportions sum one. factor.levels integer; number levels groups factor. example, two factors two levels groups use e.g. c(2, 2), three factors two levels groups use e.g. c(2, 2, 2) r.squared explanatory power covariates (R-squared) ANCOVA model. default r.squared = 0, means ANOVA model interest. k.covariates integer; number covariates ANCOVA model. default k.cov = 0, means ANOVA model interest. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.keppel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for One-Way ANOVA/ANCOVA Using Means and Standard Deviations (F test) — power.f.ancova.keppel","text":"parms list parameters used calculation. test type statistical test (F-Test). df1 numerator degrees freedom. df2 denominator degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. power statistical power \\((1-\\beta)\\). n.total total sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.keppel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for One-Way ANOVA/ANCOVA Using Means and Standard Deviations (F test) — power.f.ancova.keppel","text":"Keppel, G., & Wickens, T. D. (2004). Design analysis: researcher's handbook (4th ed.). Pearson.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.keppel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for One-Way ANOVA/ANCOVA Using Means and Standard Deviations (F test) — power.f.ancova.keppel","text":"","code":"# required sample size to detect a mean difference of # Cohen's d = 0.50 for a one-way two-group design power.f.ancova.keppel(mu.vector = c(0.50, 0), # marginal means                       sd.vector = c(1, 1), # unadjusted standard deviations                       n.vector = NULL, # sample size (will be calculated)                       p.vector = c(0.50, 0.50), # balanced allocation                       k.cov = 1, # number of covariates                       r.squared = 0.50, # explanatory power of covariates                       alpha = 0.05, # Type 1 error rate                       power = .80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 66  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.193 #>   Statistical Power      = 0.807 #>   # effect size approach power.f.ancova(eta.squared = 0.111, # effect size that is already adjusted for covariates                factor.levels = 2, # one-way ANCOVA with two levels (groups)                k.covariates = 1, # number of covariates                alpha = 0.05, # Type 1 error rate                power = .80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 66  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.193 #>   Statistical Power      = 0.807 #>   # regression approach p <- 0.50 power.t.regression(beta = 0.50,                    sd.predictor = sqrt(p * (1 - p)),                    sd.outcome = 1,                    k.total = 1,                    r.squared = 0.50,                    n = NULL, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 65  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.199 #>   Statistical Power      = 0.801 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.shieh.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for One-, Two-, Three-Way ANCOVA Using Means, Standard Deviations, and (Optionally) Contrasts (F test) — power.f.ancova.shieh","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Using Means, Standard Deviations, and (Optionally) Contrasts (F test) — power.f.ancova.shieh","text":"Calculates power sample size one-, two-, three-way ANCOVA. factorial designs, use argument factor.levels note unique combination levels (cells case) follow specific order test interaction. order marginal means standard deviations  printed warning message. Note R partial matching feature allows specify shortened versions arguments, mu mu.vec instead mu.vector, k k.cov instead k.covariates. Formulas validated using examples tables Shieh (2020).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.shieh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Using Means, Standard Deviations, and (Optionally) Contrasts (F test) — power.f.ancova.shieh","text":"","code":"power.f.ancova.shieh(mu.vector, sd.vector,                      n.vector = NULL, p.vector = NULL,                      factor.levels = length(mu.vector),                      r.squared = 0, k.covariates = 1,                      contrast.matrix = NULL,                      power = NULL, alpha = 0.05,                      ceiling = TRUE, verbose = TRUE,                      pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.shieh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Using Means, Standard Deviations, and (Optionally) Contrasts (F test) — power.f.ancova.shieh","text":"mu.vector vector; adjusted means (estimated marginal means) level factor. sd.vector vector; unadjusted standard deviations level factor. pooled standard deviation provided, repeat value match number group means. warning issued group standard deviations differ substantially beyond expected due sampling error. n.vector vector; sample sizes level factor. p.vector vector; proportion total sample size level factor. proportions sum one. factor.levels integer; number levels groups factor. example, two factors two levels groups use e.g. c(2, 2), three factors two levels groups use e.g. c(2, 2, 2). r.squared explanatory power covariates (R-squared) ANCOVA model. k.covariates integer; number covariates ANCOVA model. contrast.matrix vector matrix; contrasts confused model (design) matrix. Rows contrast matrix indicate independent vector contrasts summing zero. default contrast matrix constructed using deviation coding scheme (.k.. effect coding). Columns contrast matrix indicate number levels groups (cells factorial designs). power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). ceiling logical;  TRUE default. FALSE sample size cell rounded . verbose logical; TRUE default. FALSE output printed console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.shieh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Using Means, Standard Deviations, and (Optionally) Contrasts (F test) — power.f.ancova.shieh","text":"parms list parameters used calculation. test type statistical test (F-Test) eta.squared (partial) eta-squared. f Cohen's f statistic. df1 numerator degrees freedom. df2 denominator degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. power statistical power \\((1-\\beta)\\). n.total total sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.shieh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Using Means, Standard Deviations, and (Optionally) Contrasts (F test) — power.f.ancova.shieh","text":"Shieh, G. (2020). Power analysis sample size planning ANCOVA designs. Psychometrika, 85(1), 101-120. doi:10.1007/s11336-019-09692-3","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/ancova.shieh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for One-, Two-, Three-Way ANCOVA Using Means, Standard Deviations, and (Optionally) Contrasts (F test) — power.f.ancova.shieh","text":"","code":"################################################################### ##########################  main effect  ########################## ###################################################################  # power for one-way ANCOVA (two levels or groups) power.f.ancova.shieh(mu.vector = c(0.20, 0), # marginal means                      sd.vector = c(1, 1), # unadjusted standard deviations                      n.vector = c(150, 150), # sample sizes                      r.squared = 0.50, # proportion of variance explained by covariates                      k.covariates = 1, # number of covariates                      alpha = 0.05) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 300 #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.316 #>   Statistical Power      = 0.684  << #>    # sample size for one-way ANCOVA (two levels or groups) power.f.ancova.shieh(mu.vector = c(0.20, 0), # marginal means                      sd.vector = c(1, 1), # unadjusted standard deviations                      p.vector = c(0.50, 0.50), # allocation, should sum to 1                      r.squared = 0.50,                      k.covariates = 1,                      alpha = 0.05,                      power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 396  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ################################################################### #######################  interaction effect  ###################### ###################################################################  # sample size for two-way ANCOVA (2 x 2) power.f.ancova.shieh(mu.vector = c(0.20, 0.25, 0.15, 0.05), # marginal means                      sd.vector = c(1, 1, 1, 1), # unadjusted standard deviations                      p.vector = c(0.25, 0.25, 0.25, 0.25), # allocation, should sum to 1                      factor.levels = c(2, 2), # 2 by 2 factorial design                      r.squared = 0.50,                      k.covariates = 1,                      alpha = 0.05,                      power = 0.80) #> Elements of `mu.vector`, `sd.vector`, `n.vector` or `p.vector` should follow this specific order: #> A1:B1  A1:B2  A2:B1  A2:B2   #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Two-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 2796  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>  # Elements of `mu.vector`, `sd.vector`, `n.vector` or `p.vector` should follow this specific order: #  A1:B1  A1:B2  A2:B1  A2:B2  ################################################################### #######################  planned contrasts  ####################### ###################################################################  ######################### ## dummy coding scheme ## #########################  contrast.object <- factorial.contrasts(factor.levels = 3, # one factor w/ 3 levels                                        coding = \"treatment\") # use dummy coding scheme #>    A1 A2 A3 #> A1  1  0 -1 #> A2  0  1 -1  # get contrast matrix from the contrast object contrast.matrix <- contrast.object$contrast.matrix  # calculate sample size given design characteristics ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                       sd.vector = c(1, 1, 1), # unadjusted standard deviations                                       p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                       contrast.matrix = contrast.matrix,                                       r.squared = 0.50,                                       k.covariates = 1,                                       alpha = 0.05,                                       power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   # power of planned contrasts, adjusted for alpha level power.t.contrasts(ancova.design, adjust.alpha = \"fdr\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr comparison   psi      d    ncp n.total power #>      1  A1 <=> A3 -0.05 -0.071 -1.018    1245 0.111 #>      2  A2 <=> A3  0.10  0.141  2.036    1245 0.418 #>   ########################### ## Helmert coding scheme ## ###########################  contrast.object <- factorial.contrasts(factor.levels = 3, # one factor w/ 4 levels                                        coding = \"helmert\") # use helmert coding scheme #>        A1     A2    A3 #> A1 -0.500  0.500 0.000 #> A2 -0.167 -0.167 0.333  # get contrast matrix from the contrast object contrast.matrix <- contrast.object$contrast.matrix  # calculate sample size given design characteristics ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                       sd.vector = c(1, 1, 1), # unadjusted standard deviations                                       p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                       contrast.matrix = contrast.matrix,                                       r.squared = 0.50,                                       k.covariates = 1,                                       alpha = 0.05,                                       power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   # power of planned contrasts power.t.contrasts(ancova.design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1    A2 <=> A1  0.075  0.106  3.055    1245 0.863 #>      2 A3 <=> A1 A2 -0.008 -0.012 -0.588    1245 0.090 #>   ############################## ## polynomial coding scheme ## ##############################  contrast.object <- factorial.contrasts(factor.levels = 3, # one factor w/ 4 levels                                        coding = \"poly\") # use polynomial coding scheme #>         A1     A2    A3 #> A.L -0.707  0.000 0.707 #> A.Q  0.408 -0.816 0.408  # get contrast matrix from the contrast object contrast.matrix <- contrast.object$contrast.matrix  # calculate sample size given design characteristics ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                       sd.vector = c(1, 1, 1), # unadjusted standard deviations                                       p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                       contrast.matrix = contrast.matrix,                                       r.squared = 0.50,                                       k.covariates = 1,                                       alpha = 0.05,                                       power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   # power of the planned contrasts power.t.contrasts(ancova.design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1    A3 <=> A1  0.035  0.050  1.018    1245 0.174 #>      2 A1 A3 <=> A2 -0.102 -0.144 -2.939    1245 0.836 #>   ###################### ## custom contrasts ## ######################  # custom contrasts contrast.matrix <- rbind(   cbind(A1 = 1, A2 = -0.50, A3 = -0.50),   cbind(A1 = 0.50, A2 = 0.50, A3 = -1) ) # labels are not required for custom contrasts, # but they make it easier to understand power.t.contrasts() output  # calculate sample size given design characteristics ancova.design <- power.f.ancova.shieh(mu.vector = c(0.15, 0.30, 0.20), # marginal means                                       sd.vector = c(1, 1, 1), # unadjusted standard deviations                                       p.vector = c(1/3, 1/3, 1/3), # allocation, should sum to 1                                       contrast.matrix = contrast.matrix,                                       r.squared = 0.50,                                       k.covariates = 1,                                       alpha = 0.05,                                       power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-way Analysis of Covariance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 1245  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   # power of the planned contrasts power.t.contrasts(ancova.design) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Multiple Contrast Analyses (T-Tests) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : psi = 0  #>   H1 (Alt. Claim) : psi != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>  contr   comparison    psi      d    ncp n.total power #>      1 A1 <=> A2 A3 -0.100 -0.141 -2.351    1245 0.652 #>      2 A1 A2 <=> A3  0.025  0.035  0.588    1245 0.090 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/anova.mixed.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Mixed-Effects Analysis of Variance (F-Test) — power.f.mixed.anova","title":"Power Analysis for Mixed-Effects Analysis of Variance (F-Test) — power.f.mixed.anova","text":"Calculates power sample size mixed-effects ANOVA design two factors (within). one group observed time, design often referred repeated-measures ANOVA. Formulas validated using G*Power tables PASS documentation. NOTE: pwrss.f.rmanova() function deprecated longer supported, remain available wrapper power.f.mixed.anova() transition period.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/anova.mixed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Mixed-Effects Analysis of Variance (F-Test) — power.f.mixed.anova","text":"","code":"power.f.mixed.anova(eta.squared, null.eta.squared = 0,                     factor.levels = c(2, 2),                     factor.type = c(\"between\", \"within\"),                     rho.within = 0.50, epsilon = 1,                     n.total = NULL, power = NULL, alpha = 0.05,                     effect = c(\"between\", \"within\", \"interaction\"),                     ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/anova.mixed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Mixed-Effects Analysis of Variance (F-Test) — power.f.mixed.anova","text":"eta.squared (partial) eta-squared alternative. null.eta.squared (partial) eta-squared null. rho.within Correlation repeated measures. example, pretest/post-test designs, correlation pretest post-test scores regardless group membership. default 0.50. eta.squared already adjusted correlation specify 'rho.within = NA'. factor.levels vector; integer; length two representing number levels groups measures. example, randomized controlled trials two arms (treatment control) pre-test, post-test, follow-test administered, represented c(2, 3). factor.type vector; character; length two indicating order -subject within-subject factors. default, first value represents -subject factor second value represents within-subject factor. argument rarely needed, except unsure element 'factor.levels' represent -subject within-subject factors. Therefore, specify 'factor.levels' accordingly. epsilon non-sphericity correction factor, default 1 (means violation sphericity). Lower bound argument epsilon = 1 / (factor.levels[2] - 1). n.total integer; total sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). effect character; effect interest: \"\", \"within\", \"interaction\". ceiling logical;  TRUE default. FALSE sample size group rounded . verbose logical; TRUE default. FALSE output printed console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/anova.mixed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Mixed-Effects Analysis of Variance (F-Test) — power.f.mixed.anova","text":"parms list parameters used calculation. test type statistical test (F-Test). df1 numerator degrees freedom. df2 denominator degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. power statistical power \\((1-\\beta)\\). n.total total sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/anova.mixed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Mixed-Effects Analysis of Variance (F-Test) — power.f.mixed.anova","text":"Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/anova.mixed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Mixed-Effects Analysis of Variance (F-Test) — power.f.mixed.anova","text":"","code":"###################################################### # pretest-post-test design with treatment group only  # ######################################################  # a researcher is expecting a difference of Cohen's d = 0.30 # between post-test and pretest score translating into # Eta-squared = 0.022  # adjust effect size for correlation with 'rho.within' power.f.mixed.anova(eta.squared = 0.022,                     factor.levels = c(1, 2), # 1 between 2 within                     rho.within = 0.50,                     effect = \"within\",                     alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Repeated Measures Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 90  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 #>   # if effect size is already adjusted for correlation # use 'rho.within = NA' power.f.mixed.anova(eta.squared = 0.08255,                     factor.levels = c(1, 2), # 1 between 2 within                     rho.within = NA,                     effect = \"within\",                     alpha = 0.05, power = 0.80) #> Warning: Assuming that 'eta.squared' and 'null.eta.squared' are already adjusted for within-subject correlation. #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Repeated Measures Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 90  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 #>   ########################################################## # post-test only design with treatment and control groups # ##########################################################  # a researcher is expecting a difference of Cohen's d = 0.50 # on the post-test score between treatment and control groups # translating into Eta-squared = 0.059 power.f.mixed.anova(eta.squared = 0.059,                     factor.levels = c(2, 1),  # 2 between 1 within                     effect = \"between\",                     alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 128  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803 #>    ############################################################# # pretest-post-test design with treatment and control groups # #############################################################  # a researcher is expecting a difference of Cohen's d = 0.40 # on the post-test score between treatment and control groups # after controlling for the pretest translating into # partial Eta-squared = 0.038 power.f.mixed.anova(eta.squared = 0.038,                     factor.levels = c(2, 2),  # 2 between 2 within                     rho.within = 0.50,                     effect = \"between\",                     alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 152  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803 #>   # a researcher is expecting an interaction effect # (between groups and time) of Eta-squared = 0.01 power.f.mixed.anova(eta.squared = 0.01,                     factor.levels = c(2, 2),  # 2 between 2 within                     rho.within = 0.50,                     effect = \"interaction\",                     alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 198  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 #>   # a researcher is expecting an interaction effect # (between groups and time) of Eta-squared = 0.01 power.f.mixed.anova(eta.squared = 0.01,                     factor.levels = c(2, 2),  # 2 between 2 within                     rho.within = 0.50,                     effect = \"within\",                     alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Mixed-Effects Analysis of Variance (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : eta.squared = 0  #>   H1 (Alt. Claim) : eta.squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 198  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.cors.to.q.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion from Correlation Difference to Cohen's q — cors.to.q","title":"Conversion from Correlation Difference to Cohen's q — cors.to.q","text":"Helper function convert correlation difference Cohen's q (vice versa). cor..z() function applies Fisher's z transformation.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.cors.to.q.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion from Correlation Difference to Cohen's q — cors.to.q","text":"","code":"cor.to.z(rho, verbose = TRUE)    cors.to.q(rho1, rho2, verbose = TRUE)    q.to.cors(q, rho1 = NULL, rho2 = NULL, verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.cors.to.q.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion from Correlation Difference to Cohen's q — cors.to.q","text":"rho correlation. rho1 first correlation. rho2 second correlation. q Cohen's q effect size. verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.cors.to.q.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion from Correlation Difference to Cohen's q — cors.to.q","text":"rho1 first correlation. rho2 second correlation. delta correlation difference: rho1 - rho2. q Cohen's q effect size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.cors.to.q.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion from Correlation Difference to Cohen's q — cors.to.q","text":"","code":"q.to.cors(q = 0.10, rho1 = 0.50) #>           q       delta        rho1        rho2  #>  0.10000000 -0.07120268  0.50000000  0.57120268  q.to.cors(q = 0.30, rho1 = 0.50) #>          q      delta       rho1       rho2  #>  0.3000000 -0.1907068  0.5000000  0.6907068  q.to.cors(q = 0.50, rho1 = 0.50) #>          q      delta       rho1       rho2  #>  0.5000000 -0.2815365  0.5000000  0.7815365   cors.to.q(rho2 = 0.5712027, rho1 = 0.50) #>          q      delta       rho1       rho2  #> -0.1000000 -0.0712027  0.5000000  0.5712027  cors.to.q(rho2 = 0.6907068, rho1 = 0.50) #>          q      delta       rho1       rho2  #> -0.3000000 -0.1907068  0.5000000  0.6907068  cors.to.q(rho2 = 0.7815365, rho1 = 0.50) #>          q      delta       rho1       rho2  #> -0.5000001 -0.2815365  0.5000000  0.7815365"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.d.to.cles.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion from Cohen's d to Common Language Effect Size — d.to.cles","title":"Conversion from Cohen's d to Common Language Effect Size — d.to.cles","text":"Helper function convert Cohen's d common language effect size (vice versa). result probability superiority independent samples. can interpreted probability randomly selected observation Group 1 exceeds randomly selected observation Group 2. rationale paired-samples one-sample designs, interpretation differs: paired samples, can interpreted probability difference score (.e., score Condition 1 minus score Condition 2) greater zero randomly selected individual. one-sample design, can interpreted probability randomly selected observation greater reference value (e.g., 0).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.d.to.cles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion from Cohen's d to Common Language Effect Size — d.to.cles","text":"","code":"d.to.cles(d, design = c(\"independent\", \"paired\", \"one.sample\"), verbose = TRUE)    cles.to.d(cles, design = c(\"independent\", \"paired\", \"one.sample\"), verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.d.to.cles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion from Cohen's d to Common Language Effect Size — d.to.cles","text":"d Cohen's d design character; one \"independent\", \"paired\", \"one.sample\". default \"independent\". cles common language effect size. verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.d.to.cles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion from Cohen's d to Common Language Effect Size — d.to.cles","text":"d Cohen's d cles common language effect size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.d.to.cles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion from Cohen's d to Common Language Effect Size — d.to.cles","text":"","code":"d.to.cles(0.20) # small #>      cles         d  #> 0.5562315 0.2000000  d.to.cles(0.50) # medium #>      cles         d  #> 0.6381632 0.5000000  d.to.cles(0.80) # large #>      cles         d  #> 0.7141962 0.8000000   cles.to.d(0.5562315) #>         d      cles  #> 0.2000002 0.5562315  cles.to.d(0.6381632) #>         d      cles  #> 0.5000000 0.6381632  cles.to.d(0.7141962) #>         d      cles  #> 0.8000001 0.7141962"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.f.to.etasq.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion from Cohen's f to Eta-squared — f.to.etasq","title":"Conversion from Cohen's f to Eta-squared — f.to.etasq","text":"Helper function convert Cohen's f Eta-squared.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.f.to.etasq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion from Cohen's f to Eta-squared — f.to.etasq","text":"","code":"f.to.etasq(f, verbose = TRUE)  etasq.to.f(eta.squared, verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.f.to.etasq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion from Cohen's f to Eta-squared — f.to.etasq","text":"f Cohen's f. eta.squared (Partial) Eta-squared. verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.f.to.etasq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion from Cohen's f to Eta-squared — f.to.etasq","text":"f Cohen's f. eta.squared (Partial) Eta-squared.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.f.to.etasq.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conversion from Cohen's f to Eta-squared — f.to.etasq","text":"Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.f.to.etasq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion from Cohen's f to Eta-squared — f.to.etasq","text":"","code":"f.to.etasq(f = 0.10) # small #> eta.squared   f.squared           f  #>  0.00990099  0.01000000  0.10000000  f.to.etasq(f = 0.25) # medium #> eta.squared   f.squared           f  #>  0.05882353  0.06250000  0.25000000  f.to.etasq(f = 0.40) # large #> eta.squared   f.squared           f  #>    0.137931    0.160000    0.400000"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.mcnemar.probs.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion Between Joint and Marginal Probabilities for the McNemar Test — joint.probs.2x2","title":"Conversion Between Joint and Marginal Probabilities for the McNemar Test — joint.probs.2x2","text":"Helper function converts joint probabilities marginal probabilities (vice versa) McNemar test applied paired binary data.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.mcnemar.probs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion Between Joint and Marginal Probabilities for the McNemar Test — joint.probs.2x2","text":"","code":"joint.probs.2x2(prob1, prob2, rho = 0.50, verbose = TRUE)  marginal.probs.2x2(prob11, prob10, prob01, prob00, verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.mcnemar.probs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion Between Joint and Marginal Probabilities for the McNemar Test — joint.probs.2x2","text":"prob1 (marginal) probability success case group (). prob2 (marginal) probability success matched-control group (). rho correlation case matched-control, (phi coefficient). prob11 (joint) probability success groups. 'prob11' 'prob00' known concordant probs. prob10 (joint) probability success case () failure matched control (). 'prob10' 'prob01' known discordant probs. prob01 (joint) probability failure case () success matched control (). prob10' 'prob01' known discordant probs. prob00 (joint) probability failure groups. 'prob11' 'prob00' known concordant probs. verbose FALSE output printed console.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.mcnemar.probs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion Between Joint and Marginal Probabilities for the McNemar Test — joint.probs.2x2","text":"parms list parameters used calculation. prob1 (marginal) probability success case group (). prob2 (marginal) probability success matched-control group (). rho correlation case matched-control, (phi coefficient). prob11 (joint) probability success groups. 'prob11' 'prob00' known concordant probs. prob10 (joint) probability success case () failure matched control (). 'prob10' 'prob01' known discordant probs. prob01 (joint) probability failure case () success matched control (). prob10' 'prob01' known discordant probs. prob00 (joint) probability failure groups. 'prob11' 'prob00' known concordant probs.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.mcnemar.probs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conversion Between Joint and Marginal Probabilities for the McNemar Test — joint.probs.2x2","text":"Zhang, S., Cao, J., Ahn, C. (2017). Inference sample size calculation clinical trials incomplete observations paired binary outcomes. Statistics Medicine, 36(4), 581-591. doi:10.1002/sim.7168","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.mcnemar.probs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion Between Joint and Marginal Probabilities for the McNemar Test — joint.probs.2x2","text":"","code":"# example data for a matched case-control design # subject  case     control # <int>    <dbl>    <dbl> #   1        1        1 #   2        0        1 #   3        1        0 #   4        0        1 #   5        1        1 #   ...     ...      ... #   100      0        0  # example summary stats # prob1 = mean(case) which is 0.55 # prob2 = mean(control) which is 0.45 # rho = cor(case, control) which is 0.4141414   # example data for a before-after design # subject  before   after # <int>    <dbl>    <dbl> #   1        1        1 #   2        0        1 #   3        1        0 #   4        0        1 #   5        1        1 #   ...     ...      ... #   100      0        0  # example summary stats # prob1 = mean(after) which is 0.55 # prob2 = mean(before) which is 0.45 # rho = cor(after, before) which is 0.4141414  # convert to a 2 x 2 frequency table freqs <- matrix(c(30, 10, 20, 40), nrow = 2, ncol = 2) colnames(freqs) <- c(\"control_1\", \"control_0\") rownames(freqs) <- c(\"case_1\", \"case_0\") freqs #>        control_1 control_0 #> case_1        30        20 #> case_0        10        40  # convert to a 2 x 2 proportion table props <- freqs / sum(freqs) props #>        control_1 control_0 #> case_1       0.3       0.2 #> case_0       0.1       0.4  # discordant pairs (0 and 1, or 1 and 0) in 'props' matrix # are the sample estimates of prob01 and prob10   # we may not have 2 x 2 joint probs # convert marginal probs to joint probs using summary stats jp <- joint.probs.2x2(prob1 = 0.55, # mean of case (or after)                           prob2 = 0.45, # mean of matched control (or before)                           # correlation b/w matched case-control / before-after                           rho = 0.4141414) #> prob11 prob10 prob01 prob00  #>   0.35   0.20   0.10   0.35   # required sample size for exact test # assuming prob01 and prob10 are population parameters power.exact.mcnemar(prob01 = jp$prob01,                     prob10 = jp$prob10,                     power = 0.80, alpha = 0.05,                     method = \"exact\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Paired Proportions #>  #>   Method          : McNemar's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob10 - prob01 = 0 #>   H1 (Alt. Claim) : prob10 - prob01 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Paired Sample Size   = 249  << #>   Type 1 Error (alpha) = 0.037 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>   # convert joint probs to marginal probs and calc phi coefficient (rho) # these values can be used in other procedures marginal.probs.2x2(prob11 = 0.35, # mean of case (or after)                     prob10 = 0.20, # mean of matched control (or before)                     prob01 = 0.10,                     prob00 = 0.35) #>     prob1     prob2       rho  #> 0.5500000 0.4500000 0.4141414"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.means.to.d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion from Means and Standard Deviations to Cohen's d — means.to.d","title":"Conversion from Means and Standard Deviations to Cohen's d — means.to.d","text":"Helper function convert means standard deviations Cohen's d.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.means.to.d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion from Means and Standard Deviations to Cohen's d — means.to.d","text":"","code":"means.to.d(mu1, mu2 = 0,            sd1 = 1, sd2 = 1,            n2, n.ratio = 1,            paired = FALSE,            rho.paired = 0.50,            verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.means.to.d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion from Means and Standard Deviations to Cohen's d — means.to.d","text":"mu1 mean first group. mu2 mean second group. sd1 standard deviation first group. sd2 standard deviation second group. n.ratio n1/n2 ratio (applies independent samples ). paired TRUE paired samples rho.paired correlation repeated measures paired samples (e.g., pretest post-test). n2 integer; sample size second group (single group paired samples). verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.means.to.d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion from Means and Standard Deviations to Cohen's d — means.to.d","text":"d Cohen's d","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.means.to.d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion from Means and Standard Deviations to Cohen's d — means.to.d","text":"","code":"# means and standard deviations from independent samples means.to.d(mu1 = 20, mu2 = 17.5,            sd1 = 5, sd2 = 15,            n2 = 30, n.ratio = 1) #> Warning: Interpretation of Cohen's d may no longer be valid when variances differ beyond sampling error. #>         d  #> 0.2236068   # means and standard deviations from paired samples means.to.d(mu1 = 20, mu2 = 17.5,            sd1 = 5, sd2 = 15,            n2 = 30, n.ratio = 1,            paired = TRUE,            rho.paired = 0.50) #> Warning: Interpretation of Cohen's d may no longer be valid when variances differ beyond sampling error. #>         d  #> 0.1889822"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.h.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion from Probability Difference to Cohen's h — probs.to.h","title":"Conversion from Probability Difference to Cohen's h — probs.to.h","text":"Helper function convert probability difference Cohen's h (vice versa).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.h.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion from Probability Difference to Cohen's h — probs.to.h","text":"","code":"probs.to.h(prob1, prob2 = 0.50, verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.h.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion from Probability Difference to Cohen's h — probs.to.h","text":"prob1 probability success first group, alternative hypothesis one-sample case). prob2 probability success second group, null hypothesis one-sample case). h Cohen's h effect size. verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.h.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion from Probability Difference to Cohen's h — probs.to.h","text":"p1 probability success first group, alternative hypothesis one-sample case). p2 probability success second group, null hypothesis one-sample case). h Cohen's h effect size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.h.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion from Probability Difference to Cohen's h — probs.to.h","text":"","code":"probs.to.h(prob1 = 0.56, prob2 = 0.50) #>         h     prob1     prob2  #> 0.1202899 0.5600000 0.5000000"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.w.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion from Probabilities to Cohen's w — probs.to.w","title":"Conversion from Probabilities to Cohen's w — probs.to.w","text":"Helper function convert (multinomial product-multinomial) probabilities Cohen's w.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.w.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion from Probabilities to Cohen's w — probs.to.w","text":"","code":"probs.to.w(prob.matrix,            null.prob.matrix = NULL,            verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.w.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion from Probabilities to Cohen's w — probs.to.w","text":"prob.matrix vector matrix cell probabilities alternative hypothesis null.prob.matrix vector matrix cell probabilities null hypothesis. Calculated automatically prob.matrix specified. default can overwritten user via providing vector size matrix dimensions prob.matrix verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.w.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion from Probabilities to Cohen's w — probs.to.w","text":"w Cohen's w effect size. can Cohen's W, Phi coefficient, Cramer's V. Phi coefficient defined sqrt(X2/n) Cramer's V defined sqrt(X2/(n*v)) v min(nrow - 1, ncol - 1) X2 chi-square statistic. df degrees freedom.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.w.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conversion from Probabilities to Cohen's w — probs.to.w","text":"Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.probs.to.w.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion from Probabilities to Cohen's w — probs.to.w","text":"","code":"# ---------------------------------------------------------#   # Example 1: Cohen's W                                     #   # goodness-of-fit test for 1 x k or k x 1 table            #   # How many subjects are needed to claim that               #   # girls choose STEM related majors less than males?       #   # ---------------------------------------------------------#    ## from https://www.aauw.org/resources/research/the-stem-gap/   ## 28 percent of the  workforce in STEM field is women   prob.vector <- c(0.28, 0.72)   null.prob.vector <- c(0.50, 0.50)   probs.to.w(prob.vector, null.prob.vector) #>    w   df  #> 0.44 1.00     power.chisq.gof(w = 0.44, df = 1,                   alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 41  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 #>      # ---------------------------------------------------------#   # Example 2: Phi Coefficient (or Cramer's V or Cohen's W)  #   # test of independence for 2 x 2 contingency tables        #   # How many subjects are needed to claim that               #   # girls are underdiagnosed with ADHD?                      #   # ---------------------------------------------------------#    ## from https://time.com/growing-up-with-adhd/   ## 5.6 percent of girls and 13.2 percent of boys are diagnosed with ADHD   prob.matrix <- rbind(c(0.056, 0.132),                        c(0.944, 0.868))   colnames(prob.matrix) <- c(\"Girl\", \"Boy\")   rownames(prob.matrix) <- c(\"ADHD\", \"No ADHD\")   prob.matrix #>          Girl   Boy #> ADHD    0.056 0.132 #> No ADHD 0.944 0.868    probs.to.w(prob.matrix) #>         w        df  #> 0.1302134 1.0000000     power.chisq.gof(w = 0.1302134, df = 1,                   alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 463  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>      # --------------------------------------------------------#   # Example 3: Cramer's V (or Cohen's W)                    #   # test of independence for j x k contingency tables       #   # How many subjects are needed to detect the relationship #   # between depression severity and gender?                 #   # --------------------------------------------------------#    ## from https://doi.org/10.1016/j.jad.2019.11.121   prob.matrix <- cbind(c(0.6759, 0.1559, 0.1281, 0.0323, 0.0078),                        c(0.6771, 0.1519, 0.1368, 0.0241, 0.0101))   rownames(prob.matrix) <- c(\"Normal\", \"Mild\", \"Moderate\",                              \"Severe\", \"Extremely Severe\")   colnames(prob.matrix) <- c(\"Female\", \"Male\")   prob.matrix #>                  Female   Male #> Normal           0.6759 0.6771 #> Mild             0.1559 0.1519 #> Moderate         0.1281 0.1368 #> Severe           0.0323 0.0241 #> Extremely Severe 0.0078 0.0101    probs.to.w(prob.matrix) #>          w         df  #> 0.03022008 4.00000000     power.chisq.gof(w = 0.03022008, df = 4,                   alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 13069  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.rsq.to.f.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion from Cohen's f to R-squared — f.to.rsq","title":"Conversion from Cohen's f to R-squared — f.to.rsq","text":"Helper function convert Cohen's f R-squared.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.rsq.to.f.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion from Cohen's f to R-squared — f.to.rsq","text":"","code":"rsq.to.f(r.squared.full, r.squared.reduced = 0, verbose = TRUE)    f.to.rsq(f, r.squared.full = NULL, verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.rsq.to.f.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion from Cohen's f to R-squared — f.to.rsq","text":"f Cohen's f. r.squared.full R-squared full model. r.squared.reduced R-squared reduced model. verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.rsq.to.f.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion from Cohen's f to R-squared — f.to.rsq","text":"f Cohen's f. f.squared Cohen's f-squared. r.squared.full R-squared full model. r.squared.reduced R-squared reduced model.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.rsq.to.f.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conversion from Cohen's f to R-squared — f.to.rsq","text":"Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates. Selya, . S., Rose, J. S., Dierker, L. C., Hedeker, D., & Mermelstein, R. J. (2012). practical guide calculating Cohen's f2, measure local effect size, PROC MIXED. Frontiers Psychology, 3, 111. doi:10.3389/fpsyg.2012.00111","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/conversion.rsq.to.f.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion from Cohen's f to R-squared — f.to.rsq","text":"","code":"f.to.rsq(f = 0.10) # small #>         f.squared                 f    r.squared.full r.squared.reduced  #>        0.01000000        0.10000000        0.00990099        0.00000000    f.to.rsq(f = 0.25) # medium #>         f.squared                 f    r.squared.full r.squared.reduced  #>        0.06250000        0.25000000        0.05882353        0.00000000    f.to.rsq(f = 0.40) # large #>         f.squared                 f    r.squared.full r.squared.reduced  #>          0.160000          0.400000          0.137931          0.000000"},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.one.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for One-Sample Correlation — power.z.onecor","title":"Power Analysis for One-Sample Correlation — power.z.onecor","text":"Calculates power sample size (one can NULL time) test (Pearson) correlation constant using Fisher's z transformation. Formulas validated using PASS G*Power.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.one.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for One-Sample Correlation — power.z.onecor","text":"","code":"power.z.onecor(rho, null.rho = 0,                n = NULL, power = NULL, alpha = 0.05,                alternative = c(\"two.sided\", \"one.sided\"),                ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.one.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for One-Sample Correlation — power.z.onecor","text":"rho correlation. null.rho correlation null true. n sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"two.sided\" \"one.sided\". ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.one.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for One-Sample Correlation — power.z.onecor","text":"parms list parameters used calculation. test type statistical test (Z-Test) mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.one.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for One-Sample Correlation — power.z.onecor","text":"Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913 Chow, S. C., Shao, J., Wang, H., & Lokhnygina, Y. (2018). Sample size calculations clinical research (3rd ed.). Taylor & Francis/CRC. Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.one.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for One-Sample Correlation — power.z.onecor","text":"","code":"# expected correlation is 0.20 and it is different from 0 # it could be 0.20 as well as -0.20 power.z.onecor(rho = 0.20,                power = 0.80,                alpha = 0.05,                alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-Sample Correlation  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho -  null.rho = 0 #>   H1 (Alt. Claim) : rho -  null.rho != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 194  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   # expected correlation is 0.20 and it is greater than 0.10 power.z.onecor(rho = 0.20, null = 0.10,                power = 0.80,                alpha = 0.05,                alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One-Sample Correlation  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho -  null.rho <= 0 #>   H1 (Alt. Claim) : rho -  null.rho > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 593  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.steiger.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Dependent Correlations (Steiger's Z-Test) — power.z.twocors.steiger","title":"Power Analysis for Dependent Correlations (Steiger's Z-Test) — power.z.twocors.steiger","text":"Calculates power sample size (one can NULL time) test difference paired correlations (Pearson) using Fisher's Z-transformation. Validated via PASS G*Power.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.steiger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Dependent Correlations (Steiger's Z-Test) — power.z.twocors.steiger","text":"","code":"power.z.twocors.steiger(rho12, rho13, rho23,                         rho14 = NULL, rho24 = NULL, rho34 = NULL,                         n = NULL, power = NULL, alpha = 0.05,                         alternative = c(\"two.sided\", \"one.sided\"),                         pooled = TRUE, common.index = FALSE,                         ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.steiger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Dependent Correlations (Steiger's Z-Test) — power.z.twocors.steiger","text":"rho12 correlation variable V1 V2 (one common index common index). Check examples . rho13 correlation variable V1 V3 (one common index common index). Check examples . rho23 correlation variable V2 V3 (one common index common index). Check examples . rho14 correlation variable V1 V4 (common index ). Check examples . rho24 correlation variable V2 V4 (common index ). Check examples . rho34 correlation variable V3 V4 (common index ). Check examples . n integer; sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"two.sided\" \"one.sided\". pooled logical; whether standard error pooled. TRUE default. common.index logical; whether calculations pertain one common index. TRUE means calculations involve correlations common index (correlations share one variable). FALSE (default) means calculations pertain correlations common index (relevant correlations must explicitly specified). Check examples . ceiling logical; TRUE rounds sample size. verbose logical; FALSE output printed console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.steiger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Dependent Correlations (Steiger's Z-Test) — power.z.twocors.steiger","text":"parms list parameters used calculation. test type statistical test (Z-Test) mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample size first second groups, form c(n1, n2).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.steiger.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Dependent Correlations (Steiger's Z-Test) — power.z.twocors.steiger","text":"Steiger, J. H. (1980). Tests comparing elements correlation matrix. Psychological Bulletin, 87(2), 245-251. doi:10.1037/0033-2909.87.2.245","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.steiger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Dependent Correlations (Steiger's Z-Test) — power.z.twocors.steiger","text":"","code":"# example data for one common index # compare cor(V1, V2) to cor(V1, V3)  # subject    V1       V2      V3 # <int>    <dbl>    <dbl>    <dbl> #   1       1.2      2.3      0.8 #   2      -0.0      1.1      0.7 #   3       1.9     -0.4     -2.3 #   4       0.7      1.3      0.4 #   5       2.1     -0.1      0.8 #   ...     ...      ...      ... #   1000   -0.5      2.7     -1.7  # V1: socio-economic status (common) # V2: pretest # V3: post-test  power.z.twocors.steiger(rho12 = 0.35, rho13 = 0.45, rho23 = 0.05,                         n = 1000, power = NULL, alpha = 0.05,                         alternative = \"two.sided\",                         common.index = TRUE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Dependent Correlations #>  #>   Common Index    : TRUE #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho12 - rho13 = 0 #>   H1 (Alt. Claim) : rho12 - rho13 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1000 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.253 #>   Statistical Power    = 0.747  << #>    # example data for no common index # compare cor(V1, V2) to cor(V3, V4)  # subject    V1       V2       V3       V4 # <int>    <dbl>    <dbl>    <dbl>    <dbl> #   1       1.2      2.3      0.8      1.2 #   2      -0.0      1.1      0.7      0.9 #   3       1.9     -0.4     -2.3     -0.1 #   4       0.7      1.3      0.4     -0.3 #   5       2.1     -0.1      0.8      2.7 #   ...     ...      ...      ...      ... #   1000   -0.5      2.7     -1.7      0.8  # V1: pretest reading # V2: pretest math # V3: post-test reading # V4: post-test math  power.z.twocors.steiger(rho12 = 0.45, rho13 = 0.45, rho23 = 0.50,                         rho14 = 0.50, rho24 = 0.80, rho34 = 0.55,                         n = 1000, power = NULL, alpha = 0.05,                         alternative = \"two.sided\",                         common.index = FALSE) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Dependent Correlations #>  #>   Common Index    : FALSE #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho12 - rho34 = 0 #>   H1 (Alt. Claim) : rho12 - rho34 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1000 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.062 #>   Statistical Power    = 0.938  << #>"},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.two.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Independent Correlations — power.z.twocors","title":"Power Analysis for Independent Correlations — power.z.twocors","text":"Calculates power sample size (one can NULL time) test difference two independent (Pearson) correlations using Fisher's z transformation. Formulas validated using PASS G*Power.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.two.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Independent Correlations — power.z.twocors","text":"","code":"power.z.twocors(rho1, rho2,                 n2 = NULL, n.ratio = 1,                 power = NULL, alpha = 0.05,                 alternative = c(\"two.sided\", \"one.sided\"),                 ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.two.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Independent Correlations — power.z.twocors","text":"rho1 correlation first group. rho2 correlation second group. n2 sample size second group. Sample size first group can calculated n2*kappa. default, n1 = n2 kappa = 1. n.ratio n1/n2 ratio. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"two.sided\" \"one.sided\". ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.two.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Independent Correlations — power.z.twocors","text":"parms list parameters used calculation. test type statistical test (Z-Test) mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\) n sample size first second groups, form c(n1, n2).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.two.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Independent Correlations — power.z.twocors","text":"Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913 Chow, S. C., Shao, J., Wang, H., & Lokhnygina, Y. (2018). Sample size calculations clinical research (3rd ed.). Taylor & Francis/CRC. Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/correlations.two.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Independent Correlations — power.z.twocors","text":"","code":"# difference between r1 and r2 is different from zero # it could be -0.10 as well as 0.10 power.z.twocors(rho1 = .20, rho2 = 0.30,                alpha = 0.05, power = .80,                alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Correlations  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho1 - rho2 = 0 #>   H1 (Alt. Claim) : rho1 - rho2 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1380 and 1380  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   # difference between r1 and r2 is greater than zero power.z.twocors(rho1 = .30, rho2 = 0.20,                alpha = 0.05, power = .80,                alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Correlations  #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : rho1 - rho2 <= 0 #>   H1 (Alt. Claim) : rho1 - rho2 > 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1088 and 1088  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.binom.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for the Generic Binomial Test — power.binom","title":"Power Analysis for the Generic Binomial Test — power.binom","text":"Calculates power generic binomial test (optional) Type 1 Type 2 error plots.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.binom.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for the Generic Binomial Test — power.binom","text":"","code":"power.binom.test(size, prob, null.prob = 0.5, alpha = 0.05,                  alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),                  plot = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.binom.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for the Generic Binomial Test — power.binom","text":"size number trials (zero ). prob probability success trial alternative. null.prob probability success trial null. alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative direction type hypothesis test: \"two.sided\", \"one.sided\", \"two.one.sided\". non-inferiority superiority tests, add subtract margin null hypothesis value use alternative = \"one.sided\". plot logical; FALSE switches Type 1 Type 2 error plot. TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.binom.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for the Generic Binomial Test — power.binom","text":"size number trials (zero ). prob probability success trial alternative. null.prob probability success trial null. binom.alpha critical value(s). power statistical power \\((1-\\beta)\\).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.binom.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for the Generic Binomial Test — power.binom","text":"","code":"# one-sided power.binom.test(size = 200, prob = 0.6, null.prob = 0.5,                  alpha = 0.05, alternative = \"one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= null.prob  #>   H1 (Alt. Claim) : prob > null.prob  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.038 #>   Type 2 Error (beta)    = 0.140 #>   Statistical Power      = 0.86  << #>   # two-sided power.binom.test(size = 200, prob = 0.4, null.prob = 0.5,                  alpha = 0.05, alternative = \"two.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob = null.prob  #>   H1 (Alt. Claim) : prob != null.prob  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.040 #>   Type 2 Error (beta)    = 0.213 #>   Statistical Power      = 0.787  << #>   # equivalence power.binom.test(size = 200, prob = 0.5, null.prob = c(0.4, 0.6),                  alpha = 0.05, alternative = \"two.one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Binomial Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob <= min(null.prob) or  #>                     prob >= max(null.prob)  #>   H1 (Alt. Claim) : prob > min(null.prob) and  #>                     prob < max(null.prob)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.049 #>   Type 2 Error (beta)    = 0.229 #>   Statistical Power      = 0.771  << #>"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.chisq.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical Power for the Generic Chi-square Test — power.chisq","title":"Statistical Power for the Generic Chi-square Test — power.chisq","text":"Calculates power generic chi-square test (optional) Type 1 Type 2 error plots.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.chisq.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical Power for the Generic Chi-square Test — power.chisq","text":"","code":"power.chisq.test(ncp, null.ncp = 0, df, alpha = 0.05,                  plot = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.chisq.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical Power for the Generic Chi-square Test — power.chisq","text":"ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. df integer; degrees freedom. example, test independence df = (nrow - 1)*(ncol - 1). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). plot logical; FALSE switches Type 1 Type 2 error plot. TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.chisq.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical Power for the Generic Chi-square Test — power.chisq","text":"power statistical power \\((1-\\beta)\\).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.chisq.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical Power for the Generic Chi-square Test — power.chisq","text":"","code":"# power is defined as the probability of observing Chi-square-statistics # greater than the critical  value power.chisq.test(ncp = 20, df = 100, alpha = 0.05)  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Chi-square Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : ncp = null.ncp  #>   H1 (Alt. Claim)   : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.619 #>   Statistical Power      = 0.381  << #>"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.f.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical Power for the Generic F-Test — power.f","title":"Statistical Power for the Generic F-Test — power.f","text":"Calculates power generic F-Test (optional) Type 1 Type 2 error plots.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.f.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical Power for the Generic F-Test — power.f","text":"","code":"power.f.test(ncp, null.ncp = 0, df1, df2, alpha = 0.05,              plot = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.f.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical Power for the Generic F-Test — power.f","text":"ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). df1 integer; numerator degrees freedom. df2 integer; denominator degrees freedom. plot logical; FALSE switches Type 1 Type 2 error plot. TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.f.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical Power for the Generic F-Test — power.f","text":"df1 numerator degrees freedom. df2 denominator degrees freedom. ncp non-centrality parameter alternative. ncp.null non-centrality parameter null. f.alpha critical value(s). power statistical power \\((1-\\beta)\\).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.f.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical Power for the Generic F-Test — power.f","text":"","code":"# power is defined as the probability of observing F-statistics # greater than the critical value power.f.test(ncp = 1, df1 = 4, df2 = 100, alpha = 0.05)  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic F-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp = null.ncp  #>   H1 (Alt. Claim) : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.897 #>   Statistical Power      = 0.103  << #>"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.t.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical Power for the Generic T-Test — power.t","title":"Statistical Power for the Generic T-Test — power.t","text":"Calculates power generic T-Test (optional) Type 1 Type 2 error plots.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.t.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical Power for the Generic T-Test — power.t","text":"","code":"power.t.test(ncp, null.ncp = 0, df, alpha = 0.05,              alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),              plot = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.t.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical Power for the Generic T-Test — power.t","text":"ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. alternative = \"two.one.sided\", function expects two values form c(lower, upper). single value provided, interpreted absolute bound automatically expanded c(-value, +value). df degrees freedom. alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"one.sided\", \"two.sided\", \"two.one.sided\". \"two.one.sided\" used equivalence minimal effect testing. plot logical; FALSE switches Type 1 Type 2 error plot. TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.t.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical Power for the Generic T-Test — power.t","text":"df degrees freedom. ncp non-centrality parameter alternative. ncp.null non-centrality parameter null. t.alpha critical value(s). power statistical power \\((1-\\beta)\\).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.t.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical Power for the Generic T-Test — power.t","text":"","code":"# two-sided # power defined as the probability of observing a test statistic # greater than the positive critical value OR # less than the negative critical value power.t.test(ncp = 1.96, df = 100, alpha = 0.05,              alternative = \"two.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp = null.ncp  #>   H1 (Alt. Claim) : ncp != null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.507 #>   Statistical Power      = 0.493  <<  #>   # one-sided # power is defined as the probability of observing a test statistic # greater than the critical value power.t.test(ncp = 1.96, df = 100, alpha = 0.05,              alternative = \"one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp <= null.ncp  #>   H1 (Alt. Claim) : ncp > null.ncp  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.381 #>   Statistical Power      = 0.619  <<  #>   # equivalence # power is defined as the probability of observing a test statistic # greater than the upper critical value (for the lower bound) AND # less than the lower critical value (for the upper bound) power.t.test(ncp = 0, df = 100,              null.ncp = c(-2, 2), alpha = 0.05,              alternative = \"two.one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp <= min(null.ncp) or  #>                     ncp >= max(null.ncp)  #>   H1 (Alt. Claim) : ncp > min(null.ncp) and  #>                     ncp < max(null.ncp)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.723 #>   Statistical Power      = 0.277  <<  #>   # minimal effect testing # power is defined as the probability of observing a test statistic # greater than the upper critical value (for the upper bound) OR # less than the lower critical value (for the lower bound). power.t.test(ncp = 2, df = 100,              null.ncp = c(-1, 1), alpha = 0.05,              alternative = \"two.one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic T-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : ncp >= min(null.ncp) and  #>                     ncp <= max(null.ncp)  #>   H1 (Alt. Claim) : ncp < min(null.ncp) or  #>                     ncp > max(null.ncp)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.837 #>   Statistical Power      = 0.163  <<  #>"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.z.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical Power for the Generic Z-Test — power.z","title":"Statistical Power for the Generic Z-Test — power.z","text":"Calculates power generic Z-Test (optional) Type 1 Type 2 error plots.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.z.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical Power for the Generic Z-Test — power.z","text":"","code":"power.z.test(mean = NULL, sd = 1, null.mean = 0, null.sd = 1,              alpha = 0.05, alternative = c(\"two.sided\",                                            \"one.sided\", \"two.one.sided\"),              plot = TRUE, verbose = TRUE, pretty = FALSE, ...)"},{"path":"https://metinbulus.github.io/pwrss/reference/generic.z.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical Power for the Generic Z-Test — power.z","text":"mean mean alternative. sd standard deviation alternative. change value except sort variance correction applied (e.g. logistic Poisson regressions). null.mean mean null. alternative = \"two.one.sided\", function expects two values form c(lower, upper). single value provided, interpreted absolute bound automatically expanded c(-value, +value). null.sd standard deviation null. change value except sort correction applied. alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"one.sided\", \"two.sided\", \"two.one.sided\". \"two.one.sided\" used equivalence minimal effect testing. plot logical; FALSE switches Type 1 Type 2 error plot. TRUE default. verbose logical; whether output printed console. TRUE default. ... legacy inputs mapped corresponding arguments (silent). e.g. ncp pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.z.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical Power for the Generic Z-Test — power.z","text":"mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/generic.z.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical Power for the Generic Z-Test — power.z","text":"","code":"# two-sided # power defined as the probability of observing z-statistics # greater than the positive critical t value OR # less than the negative critical t value power.z.test(mean = 1.96, alpha = 0.05,              alternative = \"two.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean = null.mean  #>   H1 (Alt. Claim) : mean != null.mean  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.500 #>   Statistical Power    = 0.5  << #>   # one-sided # power is defined as the probability of observing z-statistics # greater than the critical t value power.z.test(mean = 1.96, alpha = 0.05,              alternative = \"one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean <= null.mean  #>   H1 (Alt. Claim) : mean > null.mean  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.376 #>   Statistical Power    = 0.624  << #>   # equivalence # power is defined as the probability of observing a test statistic # greater than the upper critical value (for the lower bound) AND # less than the lower critical value (for the upper bound) power.z.test(mean = 0, null.mean = c(-2, 2), alpha = 0.05,              alternative = \"two.one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean <= min(null.mean) or  #>                     mean >= max(null.mean)  #>   H1 (Alt. Claim) : mean > min(null.mean) and  #>                     mean < max(null.mean)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.722 #>   Statistical Power    = 0.278  << #>   # minimal effect testing # power is defined as the probability of observing a test statistic # greater than the upper critical value (for the upper bound) OR # less than the lower critical value (for the lower bound). power.z.test(mean = 2, null.mean = c(-1, 1), alpha = 0.05,              alternative = \"two.one.sided\")  #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Generic Z-Test #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : mean >= min(null.mean) and  #>                     mean <= max(null.mean)  #>   H1 (Alt. Claim) : mean < min(null.mean) or  #>                     mean > max(null.mean)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.831 #>   Statistical Power    = 0.169  << #>"},{"path":"https://metinbulus.github.io/pwrss/reference/means.student.welch.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Student's and Welch's T-Tests — power.t.student","title":"Power Analysis for Student's and Welch's T-Tests — power.t.student","text":"Calculates power sample size (one can NULL time) Student's Welch's T-Tests. Welch's T-Test implementation relies formulas proposed Bulus (2024). Use means..d() convert raw means standard deviations Cohen's d, d..cles() convert Cohen's d probability superiority. Note interpretation appropriate underlying distribution approximately normal two groups similar population variances. contrast previous versions, users can now specify whether claims based raw score mean difference P-values standardized mean difference confidence intervals. results typically differ units, distinctions can particularly consequential studies small sample sizes high-risk interventions. Formulas validated using Monte Carlo simulations (see Bulus, 2024), G*Power, http://powerandsamplesize.com/, tables PASS documentation. One key difference PASS pwrss lies handle non-inferiority superiority tests-, one-sided tests defined negligible effect margin (implemented version). PASS shifts test statistic null hypothesis assumes zero effect, treating negligible margin part alternative hypothesis. result, test statistic evaluated central distribution. contrast, pwrss treats negligible effect true null value, test statistic evaluated non-central distribution. leads slight differences third decimal place. get results, reflect margin null.d specify margin = 0. Equivalence tests implemented line Bulus Polat (2023), Chow et al. (2018) Lakens (2017). NOTE: functions pwrss.z.mean() pwrss.z.2means() longer supported. pwrss.t.mean() pwrss.t.2means() functions deprecated, remain available wrappers power.t.student() power.t.welch() transition period.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.student.welch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Student's and Welch's T-Tests — power.t.student","text":"","code":"power.t.student(d, null.d = 0, margin = 0,                 n2 = NULL, n.ratio = 1, power = NULL, alpha = 0.05,                 alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),                 design = c(\"independent\", \"paired\", \"one.sample\"),                 claim.basis = c(\"md.pval\", \"smd.ci\"),                 ceiling = TRUE, verbose = TRUE, pretty = FALSE)  power.t.welch(d, null.d = 0, margin = 0,               var.ratio = 1, n.ratio = 1, n2 = NULL,               power = NULL, alpha = 0.05,               alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),               claim.basis = c(\"md.pval\", \"smd.ci\"),               ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/means.student.welch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Student's and Welch's T-Tests — power.t.student","text":"d Cohen's d Hedges' g. null.d Cohen's d Hedges' g null, typically 0(zero). margin margin - ignorable d - null.d difference. var.ratio variance ratio form sd1^2 / sd2^2. n2 integer; sample size second group (single group paired samples one-sample). n.ratio n1/n2 ratio (applies independent samples ) power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"one.sided\", \"two.sided\", \"two.one.sided\". non-inferiority superiority tests, add subtract margin null hypothesis value use alternative = \"one.sided\". design character; \"independent\", \"paired\" \"one.sample\". claim.basis character; \"md.pval\" claims based raw mean differences p-values, \"smd.ci\" claims based standardized mean differences confidence intervals. ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.student.welch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Student's and Welch's T-Tests — power.t.student","text":"parms list parameters used calculation. test type statistical test (T-Test). df degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. t.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample size (`n` `c(n1, n2)` depending design.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.student.welch.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Student's and Welch's T-Tests — power.t.student","text":"Bulus, M. (2024). Robust standard errors confidence intervals standardized mean difference [Preprint].doi:10.31219/osf.io/k6mbs Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913 Chow, S. C., Shao, J., Wang, H., & Lokhnygina, Y. (2018). Sample size calculations clinical research (3rd ed.). Taylor & Francis/CRC. Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates. Lakens, D. (2017). Equivalence tests: practical primer t tests, correlations, meta-analyses. Social psychological personality science, 8(4), 355-362. doi:10.1177/1948550617697177","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.student.welch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Student's and Welch's T-Tests — power.t.student","text":"","code":"####################### # Independent Samples # #######################  ## difference between group 1 and group 2 is not equal to zero ## targeting minimal difference of Cohen'd = 0.20 ## non-parametric power.np.wilcoxon(d = 0.20,                   power = 0.80,                   alternative = \"two.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 412 and 412  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## parametric power.t.student(d = 0.20,                 power = 0.80,                 alternative = \"two.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 394 and 394  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## when sample size ratio and group variances differ power.t.welch(d = 0.20,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alternative = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 473 and 237  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>    ## difference between group 1 and group 2 is greater than zero ## targeting minimal difference of Cohen'd = 0.20 ## non-parametric power.np.wilcoxon(d = 0.20,                   power = 0.80,                   alternative = \"one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= 0  #>   H1 (Alt. Claim) : d - null.d > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 325 and 325  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## parametric power.t.student(d = 0.20,                 power = 0.80,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= 0  #>   H1 (Alt. Claim) : d - null.d > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 310 and 310  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## when sample size ratio and group variances differ power.t.welch(d = 0.20,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= 0  #>   H1 (Alt. Claim) : d - null.d > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 372 and 186  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>    ## mean of group 1 is practically not smaller than mean of group 2 ## targeting minimal difference of Cohen'd = 0.20 and can be as small as -0.05 ## non-parametric power.np.wilcoxon(d = 0.20,                   margin = -0.05,                   power = 0.80,                   alternative = \"one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208 and 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## parametric power.t.student(d = 0.20,                 margin = -0.05,                 power = 0.80,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 199 and 199  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## when sample size ratio and group variances differ power.t.welch(d = 0.20,               margin = -0.05,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 238 and 119  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>    ## mean of group 1 is practically greater than mean of group 2 ## targeting minimal difference of Cohen'd = 0.20 and can be as small as 0.05 ## non-parametric power.np.wilcoxon(d = 0.20,                   margin = 0.05,                   power = 0.80,                   alternative = \"one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 578 and 578  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## parametric power.t.student(d = 0.20,                 margin = 0.05,                 power = 0.80,                 alternative = \"one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 552 and 552  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## when sample size ratio and group variances differ power.t.welch(d = 0.20,               margin = 0.05,               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 662 and 331  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>    ## mean of group 1 is practically same as mean of group 2 ## targeting minimal difference of Cohen'd = 0 ## and can be as small as -0.05 or as high as 0.05 ## non-parametric power.np.wilcoxon(d = 0,                   margin = c(-0.05, 0.05),                   power = 0.80,                   alternative = \"two.one.sided\",                   design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 7175 and 7175  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## parametric power.t.student(d = 0,                 margin = c(-0.05, 0.05),                 power = 0.80,                 alternative = \"two.one.sided\",                 design = \"independent\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 6852 and 6852  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## when sample size ratio and group variances differ power.t.welch(d = 0,               margin = c(-0.05, 0.05),               n.ratio = 2,               var.ratio = 2,               power = 0.80,               alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Welch's T-Test (Independent Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 8222 and 4111  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>    ################## # Paired Samples # ##################  ## difference between time 1 and time 2 is not equal to zero ## targeting minimal difference of Cohen'd = -0.20 ## non-parametric power.np.wilcoxon(d = -0.20,                   power = 0.80,                   alternative = \"two.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## parametric power.t.student(d = -0.20,                 power = 0.80,                 alternative = \"two.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 199  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802 #>   ## difference between time 1 and time 2 is less than zero ## targeting minimal difference of Cohen'd = -0.20 ## non-parametric power.np.wilcoxon(d = -0.20,                   power = 0.80,                   alternative = \"one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d >= 0  #>   H1 (Alt. Claim) : d - null.d < 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 164  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802 #>   ## parametric power.t.student(d = -0.20,                 power = 0.80,                 alternative = \"one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d >= 0  #>   H1 (Alt. Claim) : d - null.d < 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 156  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## mean of time 1 is practically not greater than mean of time 2 ## targeting minimal difference of Cohen'd = -0.20 and can be as small as 0.05 ## non-parametric ## non-parametric power.np.wilcoxon(d = 0.20,                   margin = 0.05,                   power = 0.80,                   alternative = \"one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 291  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## parametric power.t.student(d = 0.20,                 margin = 0.05,                 power = 0.80,                 alternative = \"one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 278  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## mean of time 1 is practically greater than mean of time 2 ## targeting minimal difference of Cohen'd = -0.20 and can be as small as -0.05 ## non-parametric power.np.wilcoxon(d = 0.20,                   margin = -0.05,                   power = 0.80,                   alternative = \"one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 105  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.198 #>   Statistical Power      = 0.802 #>   ## parametric power.t.student(d = 0.20,                 margin = -0.05,                 power = 0.80,                 alternative = \"one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 100  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>    ## mean of time 1 is practically same as mean of time 2 ## targeting minimal difference of Cohen'd = 0 ## and can be as small as -0.05 or as high as 0.05 ## non-parametric ## non-parametric power.np.wilcoxon(d = 0,                   margin = c(-0.05, 0.05),                   power = 0.80,                   alternative = \"two.one.sided\",                   design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 3589  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## parametric power.t.student(d = 0,                 margin = c(-0.05, 0.05),                 power = 0.80,                 alternative = \"two.one.sided\",                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Student's T-Test (Paired Samples) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 3427  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/means.wilcoxon.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Non-parametric Rank-Based Tests (One-Sample, Independent, and Paired Designs) — power.np.wilcoxon","title":"Power Analysis for Non-parametric Rank-Based Tests (One-Sample, Independent, and Paired Designs) — power.np.wilcoxon","text":"Calculates power sample size (one can NULL time) non-parametric rank-based tests. following tests designs available: Wilcoxon Signed-Rank Test (One Sample) Wilcoxon Rank-Sum Mann-Whitney U Test (Independent Samples) Wilcoxon Matched-Pairs Signed-Rank Test (Paired Samples) Use means..d() convert raw means standard deviations Cohen's d, d..cles() convert Cohen's d probability superiority. Note interpretation appropriate underlying distribution approximately normal two groups similar population variances. Formulas validated using G*Power tables PASS documentation. However, adopt rounding convention used G*Power. Note R partial matching feature allows specify shortened versions arguments, alt instead alternative, dist instead distribution. NOTE: pwrss.np.2means() function longer supported. pwrss.np.2groups() remain available time.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.wilcoxon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Non-parametric Rank-Based Tests (One-Sample, Independent, and Paired Designs) — power.np.wilcoxon","text":"","code":"power.np.wilcoxon(d, null.d = 0, margin = 0,                   n2 = NULL, n.ratio = 1, power = NULL, alpha = 0.05,                   alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),                   design = c(\"independent\", \"paired\", \"one.sample\"),                   distribution = c(\"normal\", \"uniform\", \"double.exponential\",                                    \"laplace\", \"logistic\"),                   method = c(\"guenther\", \"noether\"),                   ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/means.wilcoxon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Non-parametric Rank-Based Tests (One-Sample, Independent, and Paired Designs) — power.np.wilcoxon","text":"d Cohen's d Hedges' g. null.d Cohen's d Hedges' g null, typically 0 (zero). margin margin - ignorable d - null.d difference. n2 integer; sample size second group (single group paired samples one-sample) n.ratio n1/n2 ratio (applies independent samples ) power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). design character; \"independent\" (default), \"one.sample\", \"paired\". alternative character; direction type hypothesis test: \"two.sided\", \"one.sided\", \"two.one.sided\". distribution character; parent distribution: \"normal\", \"uniform\", \"double.exponential\", \"laplace\", \"logistic\". method character; non-parametric approach: \"guenther\" (default) \"noether\" ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.wilcoxon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Non-parametric Rank-Based Tests (One-Sample, Independent, and Paired Designs) — power.np.wilcoxon","text":"parms list parameters used calculation. test type statistical test (Z- T-Test). df degrees freedom (applies method = 'guenther'). ncp non-centrality parameter alternative (applies method = 'guenther'). null.ncp non-centrality parameter null (applies method = 'guenther'). t.alpha critical value(s) (applies method = 'guenther'). mean mean alternative (applies method = 'noether'). null.mean mean null (applies method = 'noether'). sd standard deviation alternative (applies method = 'noether'). null.sd standard deviation null (applies method = 'noether'). z.alpha critical value(s) (applies method = 'noether'). power statistical power \\((1-\\beta)\\). n sample size (`n` `c(n1, n2)` depending design.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.wilcoxon.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Non-parametric Rank-Based Tests (One-Sample, Independent, and Paired Designs) — power.np.wilcoxon","text":"Al-Sunduqchi, M. S. (1990). Determining appropriate sample size inferences based Wilcoxon statistics [Unpublished doctoral dissertation]. University Wyoming - Laramie Chow, S. C., Shao, J., Wang, H., Lokhnygina, Y. (2018). Sample size calculations clinical research (3rd ed.). Taylor & Francis/CRC. Lehmann, E. (1975). Nonparameterics: Statistical methods based ranks. McGraw-Hill. Noether, G. E. (1987). Sample size determination common nonparametric tests. Journal American Statistical Association, 82(1), 645-647. Ruscio, J. (2008). probability-based measure effect size: Robustness base rates factors. Psychological Methods, 13(1), 19-30. Ruscio, J., & Mullen, T. (2012). Confidence intervals probability superiority effect size measure area receiver operating characteristic curve. Multivariate Behavioral Research, 47(2), 201-223. Zhao, Y.D., Rahardja, D., & Qu, Y. (2008). Sample size calculation Wilcoxon-Mann-Whitney test adjusting ties. Statistics Medicine, 27(3), 462-468.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/means.wilcoxon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Non-parametric Rank-Based Tests (One-Sample, Independent, and Paired Designs) — power.np.wilcoxon","text":"","code":"# Mann-Whitney U or Wilcoxon rank-sum test # (a.k.a Wilcoxon-Mann-Whitney test) for independent samples  ## difference between group 1 and group 2 is not equal to zero ## estimated difference is Cohen'd = 0.25 power.np.wilcoxon(d = 0.25,                 power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 265 and 265  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## difference between group 1 and group 2 is greater than zero ## estimated difference is Cohen'd = 0.25 power.np.wilcoxon(d = 0.25,                 power = 0.80,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= 0  #>   H1 (Alt. Claim) : d - null.d > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 208 and 208  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## mean of group 1 is practically not smaller than mean of group 2 ## estimated difference is Cohen'd = 0.10 and can be as small as -0.05 power.np.wilcoxon(d = 0.10,                 margin = -0.05,                 power = 0.80,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 576 and 576  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## mean of group 1 is practically greater than mean of group 2 ## estimated difference is Cohen'd = 0.10 and can be as small as 0.05 power.np.wilcoxon(d = 0.10,                 margin = 0.05,                 power = 0.80,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= margin  #>   H1 (Alt. Claim) : d - null.d > margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 5184 and 5184  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## mean of group 1 is practically same as mean of group 2 ## estimated difference is Cohen'd = 0 ## and can be as small as -0.05 and as high as 0.05 power.np.wilcoxon(d = 0,                 margin = c(-0.05, 0.05),                 power = 0.80,                 alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Rank-Sum Test (Independent Samples)  #> (Wilcoxon-Mann-Whitney or Mann-Whitney U Test) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 7175 and 7175  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>    # Wilcoxon signed-rank test for matched pairs (dependent samples)  ## difference between time 1 and time 2 is not equal to zero ## estimated difference between time 1 and time 2 is Cohen'd = -0.25 power.np.wilcoxon(d = -0.25,                 power = 0.80,                 design = \"paired\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d = 0  #>   H1 (Alt. Claim) : d - null.d != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 134  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## difference between time 1 and time 2 is greater than zero ## estimated difference between time 1 and time 2 is Cohen'd = -0.25 power.np.wilcoxon(d = -0.25,                 power = 0.80,                 design = \"paired\",                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d >= 0  #>   H1 (Alt. Claim) : d - null.d < 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 106  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.197 #>   Statistical Power      = 0.803 #>   ## mean of time 1 is practically not smaller than mean of time 2 ## estimated difference is Cohen'd = -0.10 and can be as small as 0.05 power.np.wilcoxon(d = -0.10,                 margin = 0.05,                 power = 0.80,                 design = \"paired\",                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d >= margin  #>   H1 (Alt. Claim) : d - null.d < margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 289  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.199 #>   Statistical Power      = 0.801 #>   ## mean of time 1 is practically greater than mean of time 2 ## estimated difference is Cohen'd = -0.10 and can be as small as -0.05 power.np.wilcoxon(d = -0.10,                 margin = -0.05,                 power = 0.80,                 design = \"paired\",                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d >= margin  #>   H1 (Alt. Claim) : d - null.d < margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 2599  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>   ## mean of time 1 is practically same as mean of time 2 ## estimated difference is Cohen'd = 0 ## and can be as small as -0.05 and as high as 0.05 power.np.wilcoxon(d = 0,                 margin = c(-0.05, 0.05),                 power = 0.80,                 design = \"paired\",                 alternative = \"two.one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Wilcoxon Signed-Rank Test (Paired Samples) #>  #>   Method       : Guenther #>   Distribution : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : d - null.d <= min(margin) or  #>                     d - null.d >= max(margin)  #>   H1 (Alt. Claim) : d - null.d > min(margin) and  #>                     d - null.d < max(margin)  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 3589  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.fisher.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Fisher's Exact Test (Independent Proportions) — power.exact.fisher","title":"Power Analysis for Fisher's Exact Test (Independent Proportions) — power.exact.fisher","text":"Calculates power sample size Fisher's exact test independent binary outcomes. Approximate exact methods available. Validated via PASS G*Power.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.fisher.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Fisher's Exact Test (Independent Proportions) — power.exact.fisher","text":"","code":"power.exact.fisher(prob1, prob2, n2 = NULL, n.ratio = 1,                    alpha = 0.05, power = NULL,                    alternative = c(\"two.sided\", \"one.sided\"),                    method = c(\"exact\", \"approximate\"),                    ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.fisher.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Fisher's Exact Test (Independent Proportions) — power.exact.fisher","text":"prob1 probability success first group. prob2 probability success second group. n2 integer; sample size second group. n.ratio n1 / n2 ratio. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"two.sided\" \"one.sided\". method character; method used power calculation. \"exact\" specifies Fisher's exact test, \"approximate\" refers Z-Test based normal approximation. ceiling logical; TRUE rounds sample size group. verbose logical; FALSE output printed console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.fisher.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Fisher's Exact Test (Independent Proportions) — power.exact.fisher","text":"parms list parameters used calculation. test type test, \"exact\" \"z\". odds.ratio odds ratio. mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample sizes first second groups, specified c(n1, n2). n.total total sample size, sum cell frequencies 2 x 2 table (f11 + f10 + f01 + f00), number rows data frame group variable stacked.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.fisher.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Fisher's Exact Test (Independent Proportions) — power.exact.fisher","text":"Bennett, B. M., & Hsu, P. (1960). power function exact test 2 x 2 contingency table. Biometrika, 47(3/4), 393-398. doi:10.2307/2333309 Fisher, R. . (1935). logic inductive inference. Journal Royal Statistical Society, 98(1), 39-82. doi:10.2307/2342435","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.fisher.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Fisher's Exact Test (Independent Proportions) — power.exact.fisher","text":"","code":"# example data for a randomized controlled trial # subject  group    success # <int>    <dbl>      <dbl> #   1        1          1 #   2        0          1 #   3        1          0 #   4        0          1 #   5        1          1 #   ...     ...        ... #   100      0          0  # prob1 = mean(success | group = 1) # prob2 = mean(success | group = 0)  # post-hoc exact power power.exact.fisher(prob1 = 0.60, prob2 = 0.40, n2 = 50) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Fisher's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 = 0  #>   H1 (Alt. Claim) : prob1 - prob2 != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 50 and 50 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.538 #>   Statistical Power    = 0.462  << #>   # we may have 2 x 2 joint probs such as # ------------------------------------- #             | group (1) | group (0) | # ------------------------------------- # success (1) |  0.24    |   0.36     | # ------------------------------------- # success (0) |  0.16    |   0.24     | # -------------------------------------  # convert joint probs to marginal probs marginal.probs.2x2(prob11 = 0.24, prob10 = 0.36,                    prob01 = 0.16, prob00 = 0.24) #> prob1 prob2   rho  #>   0.6   0.4   0.0"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.gof.html","id":null,"dir":"Reference","previous_headings":"","what":"Power and Sample Size for Chi-square Goodness-of-Fit or Independence Tests — power.chisq.gof","title":"Power and Sample Size for Chi-square Goodness-of-Fit or Independence Tests — power.chisq.gof","text":"Calculates power sample size (one can NULL time) Chi-square goodness--fit independence tests. NOTE: pwrss.chisq.gofit() function deprecated. However, remain available wrapper power.chisq.gof() function.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.gof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power and Sample Size for Chi-square Goodness-of-Fit or Independence Tests — power.chisq.gof","text":"","code":"power.chisq.gof(w, null.w = 0, df,                 n = NULL, power = NULL, alpha = 0.05,                 ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.gof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power and Sample Size for Chi-square Goodness-of-Fit or Independence Tests — power.chisq.gof","text":"w Cohen's w effect size alternative. can Cohen's W, Phi coefficient, Cramer's V degrees freedom specified accordingly. Phi coefficient defined sqrt(X2/n) Cramer's V defined sqrt(X2/(n*v)) v min(nrow - 1, ncol - 1) X2 chi-square statistic. null.w Cohen's w effect size null. df integer; degrees freedom.  Defined (n.cells - 1) p1 vector, (n.rows - 1) * (n.cols - 1) p1 matrix. n integer; total sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.gof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power and Sample Size for Chi-square Goodness-of-Fit or Independence Tests — power.chisq.gof","text":"parms list parameters used calculation. test type statistical test (Chi-square Test). df degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. chisq.alpha critical value. power statistical power \\((1-\\beta)\\). n total sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.gof.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power and Sample Size for Chi-square Goodness-of-Fit or Independence Tests — power.chisq.gof","text":"Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.gof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power and Sample Size for Chi-square Goodness-of-Fit or Independence Tests — power.chisq.gof","text":"","code":"# ---------------------------------------------------------# # Example 1: Cohen's W                                     # # goodness-of-fit test for 1 x k or k x 1 table            # # How many subjects are needed to claim that               # # girls choose STEM related majors less than males?       # # ---------------------------------------------------------#  ## Option 1: Use cell probabilities ## from https://www.aauw.org/resources/research/the-stem-gap/ ## 28 percent of the  workforce in STEM field is women prob.vector <- c(0.28, 0.72) null.prob.vector <- c(0.50, 0.50) probs.to.w(prob.vector, null.prob.vector) #>    w   df  #> 0.44 1.00   power.chisq.gof(w = 0.44, df = 1,                 alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 41  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.196 #>   Statistical Power      = 0.804 #>    # ---------------------------------------------------------# # Example 2: Phi Coefficient (or Cramer's V or Cohen's W)  # # test of independence for 2 x 2 contingency tables        # # How many subjects are needed to claim that               # # girls are underdiagnosed with ADHD?                      # # ---------------------------------------------------------#  ## from https://time.com/growing-up-with-adhd/ ## 5.6 percent of girls and 13.2 percent of boys are diagnosed with ADHD prob.matrix <- rbind(c(0.056, 0.132),                      c(0.944, 0.868)) colnames(prob.matrix) <- c(\"Girl\", \"Boy\") rownames(prob.matrix) <- c(\"ADHD\", \"No ADHD\") prob.matrix #>          Girl   Boy #> ADHD    0.056 0.132 #> No ADHD 0.944 0.868  probs.to.w(prob.matrix) #>         w        df  #> 0.1302134 1.0000000   power.chisq.gof(w = 0.1302134, df = 1,                 alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 463  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>    # --------------------------------------------------------# # Example 3: Cramer's V (or Cohen's W)                    # # test of independence for j x k contingency tables       # # How many subjects are needed to detect the relationship # # between depression severity and gender?                 # # --------------------------------------------------------#  ## from https://doi.org/10.1016/j.jad.2019.11.121 prob.matrix <- cbind(c(0.6759, 0.1559, 0.1281, 0.0323, 0.0078),                      c(0.6771, 0.1519, 0.1368, 0.0241, 0.0101)) rownames(prob.matrix) <- c(\"Normal\", \"Mild\", \"Moderate\",                            \"Severe\", \"Extremely Severe\") colnames(prob.matrix) <- c(\"Female\", \"Male\") prob.matrix #>                  Female   Male #> Normal           0.6759 0.6771 #> Mild             0.1559 0.1519 #> Moderate         0.1281 0.1368 #> Severe           0.0323 0.0241 #> Extremely Severe 0.0078 0.0101  probs.to.w(prob.matrix) #>          w         df  #> 0.03022008 4.00000000   power.chisq.gof(w = 0.03022008, df = 4,                 alpha = 0.05, power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Chi-Square Test for Goodness-of-Fit or Independence #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : P[i,j] = P0[i,j] for all (i,j)  #>   H1 (Alt. Claim)   : P[i,j] != P0[i,j] for some (i,j) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Total Sample Size      = 13069  <<  #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error (beta)    = 0.200 #>   Statistical Power      = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.mcnemar.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for McNemar's Exact Test (Paired Proportions) — power.exact.mcnemar","title":"Power Analysis for McNemar's Exact Test (Paired Proportions) — power.exact.mcnemar","text":"Calculates power sample size McNemar's test paired binary outcomes. Approximate exact methods available (check references details). Validated via PASS G*Power.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.mcnemar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for McNemar's Exact Test (Paired Proportions) — power.exact.mcnemar","text":"","code":"power.exact.mcnemar(prob10, prob01, n.paired = NULL,                     power = NULL,  alpha = 0.05,                     alternative = c(\"two.sided\", \"one.sided\"),                     method = c(\"exact\", \"approximate\"),                     ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.mcnemar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for McNemar's Exact Test (Paired Proportions) — power.exact.mcnemar","text":"prob10 (joint) probability success case () failure matched control (). 'prob10' 'prob01' known discordant probs. prob01 (joint) probability failure case () success matched control (). prob10' 'prob01' known discordant probs. n.paired number pairs, sum cell frequencies 2 x 2 table (f11 + f10 + f01 + f00), number rows data frame matched variables 'case' 'control' '' ''. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). method character; method used power calculation. \"exact\" specifies Fisher's exact test, \"approximate\" refers z-test based normal approximation. alternative character; direction type hypothesis test: \"equal\", \"greater\", \"less\". Optionally, users can specify 'two.sided' alternative 'equal' consistency R statistical functions. ceiling logical; TRUE rounds sample size cell. procedure assumes symmetry concordant probs, 'p11' 'p00'). Thus results may differ software units. match results set 'ceiling = FALSE'. verbose logical; FALSE output printed console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.mcnemar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for McNemar's Exact Test (Paired Proportions) — power.exact.mcnemar","text":"parms list parameters used calculation. test type test, \"exact\" \"z\". odds.ratio odds ratio. mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\). n.paired paired sample size, sum cell frequencies 2 x 2 table (f11 + f10 + f01 + f00), number rows data frame variables 'case' 'control' '' ''.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.mcnemar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for McNemar's Exact Test (Paired Proportions) — power.exact.mcnemar","text":"Bennett, B. M., & Underwood, R. E. (1970). 283. Note: McNemar's Test 2 * 2 Table Power Function. Biometrics, 26(2), 339-343. doi:10.2307/2529083 Connor, R. J. (1987). Sample size testing differences proportions paired-sample design. Biometrics, 43(1), 207-211. doi:10.2307/2531961 Duffy, S. W. (1984). Asymptotic exact power McNemar test analogue R controls per case. Biometrics, 40(4) 1005-1015. doi:10.2307/2531151 McNemar, Q. (1947). Note sampling error difference correlated proportions percentages. Psychometrika, 12(2), 153-157. doi:10.1007/BF02295996 Miettinen, O. S. (1968). matched pairs design case --none responses. Biometrics, 24(2), 339-352. doi:10.2307/2528039","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.mcnemar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for McNemar's Exact Test (Paired Proportions) — power.exact.mcnemar","text":"","code":"# example data for a matched case-control design # subject  case     control # <int>    <dbl>    <dbl> #   1        1        1 #   2        0        1 #   3        1        0 #   4        0        1 #   5        1        1 #   ...     ...      ... #   100      0        0  # example data for a before-after design # subject  before   after # <int>    <dbl>    <dbl> #   1        1        1 #   2        0        1 #   3        1        0 #   4        0        1 #   5        1        1 #   ...     ...      ... #   100      0        0  # convert to a 2 x 2 frequency table freqs <- matrix(c(30, 10, 20, 40), nrow = 2, ncol = 2) colnames(freqs) <- c(\"control_1\", \"control_0\") rownames(freqs) <- c(\"case_1\", \"case_0\") freqs #>        control_1 control_0 #> case_1        30        20 #> case_0        10        40  # convert to a 2 x 2 proportion table props <- freqs / sum(freqs) props #>        control_1 control_0 #> case_1       0.3       0.2 #> case_0       0.1       0.4  # discordant pairs (0 and 1, or 1 and 0) in 'props' matrix # are the sample estimates of prob01 and prob10  # post-hoc exact power power.exact.mcnemar(prob10 = 0.20, prob01 = 0.10,                     n.paired = 100, alpha = 0.05,                     method = \"exact\", alt = \"two.sided\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Paired Proportions #>  #>   Method          : McNemar's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob10 - prob01 = 0 #>   H1 (Alt. Claim) : prob10 - prob01 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Paired Sample Size   = 100 #>   Type 1 Error (alpha) = 0.043 #>   Type 2 Error (beta)  = 0.627 #>   Statistical Power    = 0.373  << #>   # required sample size for exact test # assuming prob01 and prob10 are population parameters power.exact.mcnemar(prob10 = 0.20, prob01 = 0.10,                     power = 0.80, alpha = 0.05,                     method = \"exact\", alt = \"two.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Paired Proportions #>  #>   Method          : McNemar's Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob10 - prob01 = 0 #>   H1 (Alt. Claim) : prob10 - prob01 != 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Paired Sample Size   = 249  << #>   Type 1 Error (alpha) = 0.037 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>   # we may not have 2 x 2 joint probs # convert marginal probs to joint probs joint.probs.2x2(prob1 = 0.55, # mean of case group (or after)                     prob2 = 0.45, # mean of matched control group (or before)                     # correlation between matched case-control or before-after                     rho = 0.4141414 ) #> prob11 prob10 prob01 prob00  #>   0.35   0.20   0.10   0.35"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.oneprop.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for the Test of One Proportion (Normal Approximation and Exact Methods) — power.z.oneprop","title":"Power Analysis for the Test of One Proportion (Normal Approximation and Exact Methods) — power.z.oneprop","text":"Calculates power sample size (one can NULL time) test proportion constant using normal approximation exact method. Formulas validated using PASS documentation. NOTE: pwrss.z.prop() function deprecated, remain available wrapper power.z.oneprop() function transition period.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.oneprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for the Test of One Proportion (Normal Approximation and Exact Methods) — power.z.oneprop","text":"","code":"power.z.oneprop(prob, null.prob = 0.50,                 n = NULL, power = NULL, alpha = 0.05,                 alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),                 std.error = c(\"null\", \"alternative\"),                 arcsine = FALSE, correct = FALSE,                 ceiling = TRUE, verbose = TRUE, pretty = FALSE)  power.exact.oneprop(prob, null.prob = 0.50,                     n = NULL, power = NULL, alpha = 0.05,                     alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),                     verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.oneprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for the Test of One Proportion (Normal Approximation and Exact Methods) — power.z.oneprop","text":"prob probability success alternative. null.prob probability success null. n integer; sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). std.error character; whether calculate standard error using \"null\" \"alternative\" value. \"null\" default. arcsine logical; whether arcsine transformation applied. FALSE default. Note arcsine = TRUE, specification correct std.error ignored. correct logical; whether Yate's continuity correction applied. alternative character; direction type hypothesis test: \"two.sided\", \"one.sided\", \"two.one.sided\". non-inferiority superiority tests, add margin null hypothesis value use alternative = \"one.sided\". ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.oneprop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for the Test of One Proportion (Normal Approximation and Exact Methods) — power.z.oneprop","text":"parms list parameters used calculation. test type statistical test (\"exact\"). mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.oneprop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for the Test of One Proportion (Normal Approximation and Exact Methods) — power.z.oneprop","text":"Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.oneprop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for the Test of One Proportion (Normal Approximation and Exact Methods) — power.z.oneprop","text":"","code":"# power power.z.oneprop(prob = 0.45, null.prob = 0.50,                 alpha = 0.05, n = 500,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 500 #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.276 #>   Statistical Power     = 0.724  << #>   power.exact.oneprop(prob = 0.45, null.prob = 0.50,                     alpha = 0.05, n = 500,                     alternative = \"one.sided\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 500 #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.279 #>   Statistical Power     = 0.721  << #>     # sample size power.z.oneprop(prob = 0.45, null.prob = 0.50,                 alpha = 0.05, power = 0.80,                 alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Normal Approximation #>   Continuity Correction  : FALSE #>   Arcsine Transformation : FALSE #>   Standard Error         : Calculated From Null #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 617  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.200 #>   Statistical Power     = 0.8 #>   power.exact.oneprop(prob = 0.45, null.prob = 0.50,                     alpha = 0.05, power = 0.80,                     alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> One Proportion #>  #>   Method                 : Exact #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)        : prob - null.prob >= 0 #>   H1 (Alt. Claim)        : prob - null.prob < 0 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size           = 633  << #>   Type 1 Error (alpha)  = 0.050 #>   Type 2 Error (beta)   = 0.197 #>   Statistical Power     = 0.803 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.twoprops.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Testing Difference Between Two Proportions (Normal Approximation and Exact Methods) — power.z.twoprops","title":"Power Analysis for Testing Difference Between Two Proportions (Normal Approximation and Exact Methods) — power.z.twoprops","text":"Calculates power sample size (one can NULL time) two proportions using normal approximation method. Validated via G*Power PASS documentation. NOTE: pwrss.z.2props() function deprecated, remain available wrapper power.z.twoprops() function transition period.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.twoprops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Testing Difference Between Two Proportions (Normal Approximation and Exact Methods) — power.z.twoprops","text":"","code":"power.z.twoprops(prob1, prob2, margin = 0,                  n2 = NULL, n.ratio = 1,                  power = NULL, alpha = 0.05,                  alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),                  arcsine = FALSE, correct = FALSE,                  paired = FALSE, rho.paired = 0.50,                  std.error = c(\"pooled\", \"unpooled\"),                  ceiling = TRUE, verbose = TRUE, pretty = FALSE)  power.exact.twoprops(prob1, prob2, n2 = NULL, n.ratio = 1,                      power = NULL, alpha = 0.05,                      alternative = c(\"two.sided\", \"one.sided\"),                      paired = FALSE, rho.paired = 0.50,                      method = c(\"exact\", \"approximate\"),                      ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.twoprops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Testing Difference Between Two Proportions (Normal Approximation and Exact Methods) — power.z.twoprops","text":"prob1 probability success first group. prob2 probability success second group. margin ignorable prob1 - prob2 difference. two one-sided tests provide lower upper margins form c(lower, upper). n2 integer; sample size second group. n.ratio sample size ratio (n1 / n2). power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). paired logical; TRUE samples paired. FALSE default. rho.paired correlation paired observations. method character; whether use \"approximate\" \"exact\" method. Default \"exact\" (power.exact.twoprops() function). arcsine logical; whether arcsine transformation applied. Note applies independent proportions without continuity correction. correct logical; whether Yates' continuity correction applied test statistic. Ignored paired test. std.error character; whether calculate standard error using \"pooled\" \"unpooled\" standard deviation. Ignored paired test. alternative character; direction type hypothesis test: \"two.sided\", \"one.sided\", \"two.one.sided\". ceiling logical; TRUE rounds sample size group. verbose logical; TRUE prints output console. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.twoprops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Testing Difference Between Two Proportions (Normal Approximation and Exact Methods) — power.z.twoprops","text":"parms list parameters used calculation. test type test, \"z\" \"exact\". power statistical power \\((1-\\beta)\\). mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). n sample size form c(n1, n2) (applies independent proportions). n.total total sample size (applies independent proportions). n.paired paired sample size (applies paired proportions).","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.twoprops.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Testing Difference Between Two Proportions (Normal Approximation and Exact Methods) — power.z.twoprops","text":"Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/proportions.twoprops.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Testing Difference Between Two Proportions (Normal Approximation and Exact Methods) — power.z.twoprops","text":"","code":"# power   power.z.twoprops(prob1 = 0.65, prob2 = 0.60,                    alpha = 0.05, n2 = 500,                    alternative = \"one.sided\") #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 500 and 500 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.505 #>   Statistical Power    = 0.495  << #>     # sample size   power.z.twoprops(prob1 = 0.65, prob2 = 0.60,                    alpha = 0.05, power = 0.80,                    alternative = \"one.sided\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Independent Proportions #>  #>   Method          : Normal Approximation #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : prob1 - prob2 <= 0  #>   H1 (Alt. Claim) : prob1 - prob2 > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1159 and 1159  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.f.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Linear Regression: R-squared or R-squared Change (F-Test) — power.f.regression","title":"Power Analysis for Linear Regression: R-squared or R-squared Change (F-Test) — power.f.regression","text":"Calculates power sample size (one can NULL time) test R-squared deviation 0 (zero) linear regression test R-squared change two linear regression models. test R-squared change often used evaluate incremental contribution set predictors hierarchical linear regression. Formulas validated using Monte Carlo simulation, G*Power, tables PASS documentation. NOTE: pwrss.f.reg() function alias pwrss.f.regression deprecated, remain available wrapper power.f.regression() transition period.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.f.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Linear Regression: R-squared or R-squared Change (F-Test) — power.f.regression","text":"","code":"power.f.regression(r.squared.change = NULL, margin = 0,                    k.total, k.tested = k.total,                    n = NULL, power = NULL, alpha = 0.05,                    ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.f.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Linear Regression: R-squared or R-squared Change (F-Test) — power.f.regression","text":"r.squared.change R-squared (R-squared change). margin margin - ignorable R-squared (R-squared change). k.total integer; total number predictors. k.tested integer; number predictors subset interest. default m.tested = k.total, implies one interested contribution predictors, tests whether R-squared value different 0 (zero). n integer; sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.f.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Linear Regression: R-squared or R-squared Change (F-Test) — power.f.regression","text":"parms list parameters used calculation. test type statistical test (F-Test). df1 numerator degrees freedom. df2 denominator degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. f.alpha critical value. power statistical power \\((1-\\beta)\\). n sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.f.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Linear Regression: R-squared or R-squared Change (F-Test) — power.f.regression","text":"Bulus, M., & Polat, C. (2023). pwrss R paketi ile istatistiksel guc analizi [Statistical power analysis pwrss R package]. Ahi Evran Universitesi Kirsehir Egitim Fakultesi Dergisi, 24(3), 2207-2328. doi:10.29299/kefad.1209913 Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.f.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Linear Regression: R-squared or R-squared Change (F-Test) — power.f.regression","text":"","code":"# in the outcome (R-squared = 0.15). power.f.regression(r.squared = 0.15,                    k.total = 3, # total number of predictors                    power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : R-squared = 0  #>   H1 (Alt. Claim) : R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 66  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>   # adding two more variables will increase R-squared # from 0.15 (with 3 predictors) to 0.25 (with 3 + 2 predictors) power.f.regression(r.squared.change = 0.10, # R-squared change                    k.total = 5, # total number of predictors                    k.tested = 2, # predictors to be tested                    power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Hierarchical Linear Regression (F-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Change in R-squared = 0  #>   H1 (Alt. Claim) : Change in R-squared > 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 90  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.t.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Linear Regression: Single Coefficient (T-Test) — power.t.regression","title":"Power Analysis for Linear Regression: Single Coefficient (T-Test) — power.t.regression","text":"Calculates power sample size (one can NULL time) test single coefficient multiple linear regression. predictor assumed continuous default. However, one can calculate power sample size binary predictor (treatment control groups experimental design) specifying sd.predictor = sqrt(p*(1-p)) p proportion subjects one groups. sample size group n*p n*(1-p). power.t.regression()pwrss.t.regression() functions, well power.t.reg() pwrss.t.reg(). Minimal effect equivalence tests implemented line Hodges Lehmann (1954), Kim Robinson (2019), Phillips (1990), Dupont Plummer (1998). Formulas validated using Monte Carlo simulation, G*Power, tables PASS documentation, tables Bulus (2021). NOTE: pwrss.t.regression() function alias pwrss.z.reg() deprecated, remain available wrapper power.t.regression() transition period.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Linear Regression: Single Coefficient (T-Test) — power.t.regression","text":"","code":"power.t.regression(beta, null.beta = 0, margin = 0,                    sd.predictor = 1, sd.outcome = 1,                    r.squared = (beta * sd.predictor / sd.outcome)^2,                    k.total = 1, n = NULL, power = NULL, alpha = 0.05,                    alternative = c(\"two.sided\", \"one.sided\", \"two.one.sided\"),                    ceiling = TRUE, verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Linear Regression: Single Coefficient (T-Test) — power.t.regression","text":"beta regression coefficient. One can use standardized regression coefficient, keep sd.predictor = 1 sd.outcome = 1 leave default specifications. null.beta regression coefficient null hypothesis (typically zero). One can use standardized regression coefficient, keep sd.predictor = 1 sd.outcome = 1 leave default specifications. margin margin - ignorable beta - null.beta difference. sd.predictor standard deviation predictor. binary predictor, sd.predictor = sqrt(p * (1 - p)) p proportion subjects one groups. sd.outcome standard deviation outcome. k.total integer; total number predictors, including predictor interest. r.squared model R-squared. default r.squared = (beta * sd.predictor / sd.outcome)^2 assuming linear regression one predictor. Thus, r.squared value throw warning. consider covariates model provide value greater default r.squared along argument k.total > 1. n integer; sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"two.sided\", \"one.sided\", \"two.one.sided\". ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Linear Regression: Single Coefficient (T-Test) — power.t.regression","text":"parms list parameters used calculation. test type statistical test (T-Test). df degrees freedom. ncp non-centrality parameter alternative. null.ncp non-centrality parameter null. t.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.t.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Linear Regression: Single Coefficient (T-Test) — power.t.regression","text":"Bulus, M. (2021). Sample size determination optimal design randomized/non-equivalent pretest-post-test control-group designs. Adiyaman University Journal Educational Sciences, 11(1), 48-69. doi:10.17984/adyuebd.941434 Hodges Jr, J. L., & Lehmann, E. L. (1954). Testing approximate validity statistical hypotheses. Journal Royal Statistical Society Series B: Statistical Methodology, 16(2), 261-268. doi:10.1111/j.2517-6161.1954.tb00169.x Kim, J. H., & Robinson, . P. (2019). Interval-based hypothesis testing applications economics finance. Econometrics, 7(2), 21. doi:10.3390/econometrics7020021 Phillips, K. F. (1990). Power two one-sided tests procedure bioequivalence. Journal Pharmacokinetics Biopharmaceutics, 18(2), 137-144. doi:10.1007/bf01063556 Dupont, W. D., Plummer, W. D. (1998). Power sample size calculations studies involving linear regression. Controlled Clinical Trials, 19(6), 589-601. doi:10.1016/s0197-2456(98)00037-3","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.linear.t.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Linear Regression: Single Coefficient (T-Test) — power.t.regression","text":"","code":"# continuous predictor x (and 4 covariates) power.t.regression(beta = 0.20,             k.total = 5,             r.squared = 0.30,             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 140  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.198 #>   Statistical Power      = 0.802 #>   # binary predictor x (and 4 covariates) p <- 0.50 # proportion of subjects in one group power.t.regression(beta = 0.20,             sd.predictor = sqrt(p*(1-p)),             k.total = 5,             r.squared = 0.30,             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta = 0  #>   H1 (Alt. Claim) : beta - null.beta != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 552  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8 #>   # non-inferiority test with binary predictor x (and 4 covariates) p <- 0.50 # proportion of subjects in one group power.t.regression(beta = 0.20, # Cohen's d             margin = -0.05, # non-inferiority margin in Cohen's d unit             alternative = \"one.sided\",             sd.predictor = sqrt(p*(1-p)),             k.total = 5,             r.squared = 0.30,             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= margin  #>   H1 (Alt. Claim) : beta - null.beta >  margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 278  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8 #>   # superiority test with binary predictor x (and 4 covariates) p <- 0.50 # proportion of subjects in one group power.t.regression(beta = 0.20, # Cohen's d             margin = 0.05, # superiority margin in Cohen's d unit             alternative = \"one.sided\",             sd.predictor = sqrt(p*(1-p)),             k.total = 5,             r.squared = 0.30,             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= margin  #>   H1 (Alt. Claim) : beta - null.beta >  margin  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 773  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8 #>   # equivalence test with binary predictor x (and 4 covariates) p <- 0.50 # proportion of subjects in one group power.t.regression(beta = 0, # Cohen's d             margin = c(-0.05, 0.05), # equivalence bounds in Cohen's d unit             alternative = \"two.one.sided\",             sd.predictor = sqrt(p*(1 - p)),             k.total = 5,             r.squared = 0.30,             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Linear Regression Coefficient (T-Test) #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : beta - null.beta <= min(margin) or  #>                     beta - null.beta >= max(margin)  #>   H1 (Alt. Claim) : beta - null.beta > min(margin) and  #>                     beta - null.beta < max(margin) #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size            = 9593  << #>   Type 1 Error (alpha)   = 0.050 #>   Type 2 Error           = 0.200 #>   Statistical Power      = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Logistic Regression Coefficient (Wald's Z-Test) — power.z.logistic","title":"Power Analysis for Logistic Regression Coefficient (Wald's Z-Test) — power.z.logistic","text":"Calculates power sample size (one can NULL time) test single coefficient logistic regression. power.z.logistic() power.z.logreg() functions, well pwrss.z.logistic() pwrss.z.logreg(). distribution predictor variable can one following: c(\"normal\", \"poisson\", \"uniform\", \"exponential\", \"binomial\", \"bernouilli\", \"lognormal\") Demidenko (2007) procedure c(\"normal\", \"binomial\", \"bernouilli\") Hsieh et al. (1998) procedure. default parameters distributions distribution = list(dist = \"normal\", mean = 0, sd = 1) distribution = list(dist = \"poisson\", lambda = 1) distribution = list(dist = \"uniform\", min = 0, max = 1) distribution = list(dist = \"exponential\", rate = 1) distribution = list(dist = \"binomial\", size = 1, prob = 0.50) distribution = list(dist = \"bernoulli\", prob = 0.50) distribution = list(dist = \"lognormal\", meanlog = 0, sdlog = 1) Parameters defined list() form can modified, element names kept . sufficient use distribution's name default parameters (e.g. dist = \"normal\"). NOTE: pwrss.z.logistic() alias pwrss.z.logreg() deprecated. However, remain available wrappers power.z.logistic() function. Formulas validated using G*Power tables PASS documentation.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Logistic Regression Coefficient (Wald's Z-Test) — power.z.logistic","text":"","code":"power.z.logistic(prob = NULL, base.prob = NULL,                  odds.ratio  = (prob/(1-prob))/(base.prob/(1-base.prob)),                  beta0 = log(base.prob/(1-base.prob)), beta1 = log(odds.ratio),                  n = NULL, power = NULL, r.squared.predictor = 0,                  alpha = 0.05, alternative = c(\"two.sided\", \"one.sided\"),                  method = c(\"demidenko(vc)\", \"demidenko\", \"hsieh\"),                  distribution = \"normal\", ceiling = TRUE,                  verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.logistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Logistic Regression Coefficient (Wald's Z-Test) — power.z.logistic","text":"base.prob base probability null hypothesis (probability event occurs without influence predictor - value predictor zero). prob probability alternative hypothesis (probability event occurs value predictor increased 0 1). Warning: base probability + incremental increase. beta0 regression coefficient defined beta0 = log(base.prob/(1-base.prob)) beta1 regression coefficient predictor X defined beta1 = log((prob/(1-prob))/(base.prob/(1-base.prob))) odds.ratio odds ratio defined odds.ratio = exp(beta1) = (prob/(1-prob))/(base.prob/(1-base.prob)) n integer; sample size power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). r.squared.predictor proportion variance predictor accounted covariates. pseudo R-squared. compute , regress predictor covariates extract adjusted R-squared model. alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"equal\", \"greater\", \"less\" method character; analytic method. \"demidenko(vc)\" stands Demidenko (2007) procedure variance correction; \"demidenko\" stands Demidenko (2007) procedure without variance correction; \"hsieh\" stands Hsieh et al. (1998) procedure. \"demidenko\" \"hsieh\" methods produce similar results \"demidenko(vc)\" precise distribution character; distribution family. Can one c(\"noramal\", \"poisson\", \"uniform\", \"exponential\", \"binomial\", \"bernouilli\", \"lognormal\") Demidenko (2007) procedure c(\"normal\", \"binomial\", \"bernouilli\") Hsieh et al. (1998) procedure. ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.logistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Logistic Regression Coefficient (Wald's Z-Test) — power.z.logistic","text":"parms list parameters used calculation. test type statistical test (Z-Test). mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.logistic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Logistic Regression Coefficient (Wald's Z-Test) — power.z.logistic","text":"Demidenko, E. (2007). Sample size determination logistic regression revisited. Statistics Medicine, 26(18), 3385-3397. doi:10.1002/sim.2771 Hsieh, F. Y., Bloch, D. ., & Larsen, M. D. (1998). simple method sample size calculation linear logistic regression. Statistics Medicine, 17(4), 1623-1634.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.logistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Logistic Regression Coefficient (Wald's Z-Test) — power.z.logistic","text":"","code":"########################################### # predictor X follows normal distribution # ###########################################  ## probability specification power.z.logistic(base.prob = 0.15, prob = 0.20,                  alpha = 0.05, power = 0.80,                  dist = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 511  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>   ## odds ratio specification power.z.logistic(base.prob = 0.15, odds.ratio = 1.416667,                  alpha = 0.05, power = 0.80,                  dist = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 511  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>   ## regression coefficient specification power.z.logistic(beta0 = -1.734601, beta1 = 0.3483067,                  alpha = 0.05, power = 0.80,                  dist = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 511  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>   ## change parameters associated with predictor X pred.dist <- list(dist = \"normal\", mean = 10, sd = 2) power.z.logistic(base.prob = 0.15, beta1 = 0.3483067,                  alpha = 0.05, power = 0.80,                  dist = pred.dist) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 134  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>    ############################################## # predictor X follows Bernoulli distribution # # (such as treatment/control groups)         # ##############################################  ## odds ratio specification power.z.logistic(base.prob = 0.15, odds.ratio = 1.416667,                  alpha = 0.05, power = 0.80,                  dist = \"bernoulli\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 1816  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   ## change parameters associated with predictor X pred.dist <- list(dist = \"bernoulli\", prob = 0.30) power.z.logistic(base.prob = 0.15, odds.ratio = 1.416667,                  alpha = 0.05, power = 0.80,                  dist = pred.dist) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2114  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   #################################### # predictor X is an ordinal factor # ####################################  ## generating an ordinal predictor x.ord <- sample(   x = c(1, 2, 3, 4), # levels   size = 1e5, # sample size large enough to get stable estimates   prob = c(0.25, 0.25, 0.25, 0.25), # category probabilities   replace = TRUE )  ## dummy coding the ordinal predictor x.ord <- factor(x.ord, ordered = TRUE) contrasts(x.ord) <- contr.treatment(4, base = 4) x.dummy <- model.matrix( ~ x.ord)[,-1] x.data <- as.data.frame(x.dummy)  ## fit linear regression to get multiple r-squared x.fit <- lm(x.ord1 ~ x.ord2 + x.ord3, data = x.data)  ## extract parameters bern.prob <- mean(x.data$x.ord1) r.squared.pred <- summary(x.fit)$adj.r.squared  ## change parameters associated with predictor X pred.dist <- list(dist = \"bernoulli\", prob = bern.prob) power.z.logistic(base.prob = 0.15, odds.ratio = 1.416667,                alpha = 0.05, power = 0.80,                r.squared.pred = r.squared.pred,                dist = pred.dist) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Logistic Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Odds Ratio = 1 #>   H1 (Alt. Claim) : Odds Ratio != 1 #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 3549  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.mediation.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Indirect Effects in a Mediation Model (Z, Joint, and Monte Carlo Tests) — power.z.mediation","title":"Power Analysis for Indirect Effects in a Mediation Model (Z, Joint, and Monte Carlo Tests) — power.z.mediation","text":"Calculates power sample size (one can NULL time) test indirect effects mediation model (Z-Test, Joint Test, Monte Carlo Interval Test). One can consider explanatory power covariates mediator outcome model via specifying R-squared values accordingly. power.z.mediation() power.z.med() functions. NOTE: function pwrss.z.mediation() (alias pwrss.z.med()) longer supported. However, remain available wrappers power.z.mediation function. Formulas validated using Monte Carlo simulation.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.mediation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Indirect Effects in a Mediation Model (Z, Joint, and Monte Carlo Tests) — power.z.mediation","text":"","code":"power.z.mediation(beta.a, beta.b, beta.cp = 0,                   sd.predictor = 1, sd.mediator = 1, sd.outcome = 1,                   r.squared.mediator = beta.a^2 * sd.predictor^2 / sd.mediator^2,                   r.squared.outcome = (beta.b^2 * sd.mediator^2 +                                          beta.cp^2 * sd.predictor^2) / sd.outcome^2,                   n = NULL, power = NULL, alpha = 0.05,                   alternative = c(\"two.sided\", \"one.sided\"),                   method = c(\"sobel\", \"aroian\", \"goodman\",                              \"joint\", \"monte.carlo\"),                   n.simulation = 1000,                   n.draws = 1000,                   ceiling = TRUE,                   verbose = TRUE,                   pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.mediation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Indirect Effects in a Mediation Model (Z, Joint, and Monte Carlo Tests) — power.z.mediation","text":"beta.regression coefficient X -> M path. One can use standardized regression coefficient, keep sd.predictor = 1 sd.mediator = 1 leave default specifications. beta.b regression coefficient M -> Y path. One can use standardized regression coefficient, keep sd.mediator = 1 sd.outcome = 1 leave default specifications. beta.cp regression coefficient X -> Y path (direct path). One can use standardized regression coefficient, keep sd.predictor = 1 sd.outcome = 1 leave default specifications. sd.predictor standard deviation predictor (X). binary predictor, sd.predictor = sqrt(p*(1-p)) wherep proportion subjects one groups. sd.mediator standard deviation mediator (M). sd.outcome standard deviation outcome (Y). r.squared.mediator R-squared value mediator model (M ~ X). default r.squared.mediator = beta.^2 * sd.predictor^2 / sd.mediator^2 assuming X predictor. Thus, r.squared.mediator value throw warning. consider covariates mediator model provide value greater default. r.squared.outcome R-squared value outcome model (Y ~ M + X). default r.squared.outcome = (beta.b^2 * sd.mediator^2 + beta.cp^2 * sd.predictor^2) / sd.outcome^2 assuming M X predictors. Thus, r.squared.outcome value throw warning. consider covariates outcome model provide value greater default. n integer; sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"two.sided\" \"one.sided\". method character; \"sobel\", \"aroian\", \"goodman\", \"joint\" \"monte.carlo\". \"joint\" \"monte.carlo\" methods used sample size calculation. n.simulation integer; number replications (applies method = \"monte.carlo\"). n.draws integer; number draws distribution path coefficients replication (applies method = \"monte.carlo\"). ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.mediation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Indirect Effects in a Mediation Model (Z, Joint, and Monte Carlo Tests) — power.z.mediation","text":"parms list parameters used calculation. test type statistical test (\"Z-Test\", \"Joint Test\", \"Monte Carlo Interval Test\"). mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\). n sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.mediation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Indirect Effects in a Mediation Model (Z, Joint, and Monte Carlo Tests) — power.z.mediation","text":"Aroian, L. . (1947). probability function product two normally distributed variables. Annals Mathematical Statistics, 18(2), 265-271. Goodman, L. . (1960). exact variance products. Journal American Statistical Association, 55(292), 708-713. MacKinnon, D. P., & Dwyer, J. H. (1993). Estimating mediated effects prevention studies. Evaluation Review, 17(2), 144-158. MacKinnon, D. P., Warsi, G., & Dwyer, J. H. (1995). simulation study mediated effect measures. Multivariate Behavioral Research, 30(1), 41-62. Preacher, K. J., & Hayes, . F. (2004). SPSS SAS procedures estimating indirect effects simple mediation models. Behavior Research Methods, Instruments, & Computers, 36, 717-731. Preacher, K. J., & Hayes, . F. (2008). Asymptotic resampling strategies assessing comparing indirect effects multiple mediator models. Behavior Research Methods, 40, 879-891. Sobel, M. E. (1982). Asymptotic intervals indirect effects structural equations models. S. Leinhart (Ed.), Sociological methodology 1982 (pp. 290-312). Jossey-Bass.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.mediation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Indirect Effects in a Mediation Model (Z, Joint, and Monte Carlo Tests) — power.z.mediation","text":"","code":"# with standardized coefficients  ## statistical power power.z.mediation(beta.a = 0.25,             beta.b = 0.25,             beta.cp = 0.10,             n = 200) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 200 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.279 #>   Statistical Power    = 0.721  << #>   ## minimum required sample size power.z.mediation(beta.a = 0.25,             beta.b = 0.25,             beta.cp = 0.10,             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 242  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.200 #>   Statistical Power    = 0.8 #>   ## adjust for covariates in the outcome model power.z.mediation(beta.a = 0.25,             beta.b = 0.25,             beta.cp = 0.10,             r.squared.outcome = 0.50,             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 185  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.199 #>   Statistical Power    = 0.801 #>   # with binary predictor X such as treatment/control variable # in this case standardized coefficients for path a and cp would be Cohen's d values  ## statistical power p <- 0.50 # proportion of subjects in one group power.z.mediation(beta.a = 0.40,             beta.b = 0.25,             beta.cp = 0.10,             sd.predictor = sqrt(p*(1-p)),             n = 200) #> +--------------------------------------------------+ #> |                POWER CALCULATION                 | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 200 #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.387 #>   Statistical Power    = 0.613  << #>   ## minimum required sample size power.z.mediation(beta.a = 0.40,             beta.b = 0.25,             beta.cp = 0.10,             sd.predictor = sqrt(p*(1-p)),             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 311  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.200 #>   Statistical Power    = 0.8 #>   ## adjust for covariates in the outcome model power.z.mediation(beta.a = 0.40,             beta.b = 0.25, beta.cp = 0.10,             r.squared.outcome = 0.50,             sd.predictor = sqrt(p*(1-p)),             power = 0.80) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Indirect Effect in a Mediation Model #>  #>   Method            : Sobel #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim)   : beta[a*b] = 0  #>   H1 (Alt. Claim)   : beta[a*b] != 0  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 254  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error         = 0.200 #>   Statistical Power    = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for Poisson Regression Coefficient (Wald's z Test) — power.z.poisson","title":"Power Analysis for Poisson Regression Coefficient (Wald's z Test) — power.z.poisson","text":"Calculates power sample size (one can NULL time) test single coefficient poisson regression. power.z.poisson() power.z.poisreg() functions, well pwrss.z.poisson() pwrss.z.poisreg(). distribution predictor variable can one following: c(\"normal\", \"poisson\", \"uniform\", \"exponential\", \"binomial\", \"bernouilli\", \"lognormal\"). default parameters distributions distribution = list(dist = \"normal\", mean = 0, sd = 1) distribution = list(dist = \"poisson\", lambda = 1) distribution = list(dist = \"uniform\", min = 0, max = 1) distribution = list(dist = \"exponential\", rate = 1) distribution = list(dist = \"binomial\", size = 1, prob = 0.50) distribution = list(dist = \"bernoulli\", prob = 0.50) distribution = list(dist = \"lognormal\", meanlog = 0, sdlog = 1) Parameters defined list() form can modified, names kept . sufficient use distribution's name default parameters (e.g. dist = \"normal\"). Formulas validated using Monte Carlo simulation, G*Power, tables PASS documentation. NOTE: pwrss.z.poisson() alias pwrss.z.poisreg() deprecated. However, remain available wrappers power.z.logistic() function.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for Poisson Regression Coefficient (Wald's z Test) — power.z.poisson","text":"","code":"power.z.poisson(base.rate = NULL, rate.ratio = NULL,                 beta0 = log(base.rate), beta1 = log(rate.ratio),                 n = NULL, power = NULL,                 r.squared.predictor = 0, mean.exposure = 1,                 alpha = 0.05, alternative = c(\"two.sided\", \"one.sided\"),                 method = c(\"demidenko(vc)\", \"demidenko\", \"signorini\"),                 distribution = \"normal\", ceiling = TRUE,                 verbose = TRUE, pretty = FALSE)"},{"path":"https://metinbulus.github.io/pwrss/reference/regression.poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for Poisson Regression Coefficient (Wald's z Test) — power.z.poisson","text":"base.rate base mean event rate. rate.ratio event rate ratio. relative increase mean event rate one unit increase predictor (similar odds ratio logistic regression). beta0 log(base.rate) natural logarithm base mean event rate. beta1 log(rate.ratio) natural logarithm relative increase mean event rate one unit increase predictor. mean.exposure mean exposure time (> 0). Usually 1 n integer; sample size. power statistical power, defined probability correctly rejecting false null hypothesis, denoted \\(1 - \\beta\\). r.squared.predictor proportion variance predictor accounted covariates. pseudo R-squared. compute , regress predictor covariates extract adjusted R-squared model. alpha type 1 error rate, defined probability incorrectly rejecting true null hypothesis, denoted \\(\\alpha\\). alternative character; direction type hypothesis test: \"equal\", \"greater\", \"less\". method character; calculation method. \"demidenko(vc)\" stands Demidenko (2007) procedure variance correction; \"demidenko\" stands Demidenko (2007) procedure without variance correction; \"signorini\" stands Signorini (1991) procedure. \"demidenko\" \"signorini\" methods produce similar results \"demidenko(vc)\" precise. distribution character; distribution family. Can one c(\"normal\", \"poisson\", \"uniform\", \"exponential\", \"binomial\", \"bernouilli\", \"lognormal\"). ceiling logical; whether sample size rounded . TRUE default. verbose logical; whether output printed console. TRUE default. pretty logical; whether output show Unicode characters (encoding allows ). FALSE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.poisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for Poisson Regression Coefficient (Wald's z Test) — power.z.poisson","text":"parms list parameters used calculation. test type statistical test (Z-Test). mean mean alternative distribution. sd standard deviation alternative distribution. null.mean mean null distribution. null.sd standard deviation null distribution. z.alpha critical value(s). power statistical power \\((1-\\beta)\\) n sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.poisson.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Analysis for Poisson Regression Coefficient (Wald's z Test) — power.z.poisson","text":"Demidenko, E. (2007). Sample size determination logistic regression revisited. Statistics Medicine, 26(18), 3385-3397. doi:10.1002/sim.2771 Signorini, D. F. (1991). Sample size poisson regression. Biometrika, 78(2), 446-450.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/regression.poisson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Analysis for Poisson Regression Coefficient (Wald's z Test) — power.z.poisson","text":"","code":"# predictor X follows normal distribution  ## regression coefficient specification power.z.poisson(beta0 = 0.50, beta1 = -0.10,                 alpha = 0.05, power = 0.80,                 dist = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 474  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   ## rate ratio specification power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 alpha = 0.05, power = 0.80,                 dist = \"normal\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 474  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   ## change parameters associated with predictor X dist.x <- list(dist = \"normal\", mean = 10, sd = 2) power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 alpha = 0.05, power = 0.80,                 dist = dist.x) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Normal #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 318  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.199 #>   Statistical Power    = 0.801 #>    # predictor X follows Bernoulli distribution (such as treatment/control groups)  ## regression coefficient specification power.z.poisson(beta0 = 0.50, beta1 = -0.10,                 alpha = 0.05, power = 0.80,                 dist = \"bernoulli\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2003  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   ## rate ratio specification power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 alpha = 0.05, power = 0.80,                 dist = \"bernoulli\") #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2003  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>   ## change parameters associatied with predictor X dist.x <- list(dist = \"bernoulli\", prob = 0.30) power.z.poisson(base.rate = exp(0.50),                 rate.ratio = exp(-0.10),                 alpha = 0.05, power = 0.80,                 dist = dist.x) #> +--------------------------------------------------+ #> |             SAMPLE SIZE CALCULATION              | #> +--------------------------------------------------+ #>  #> Poisson Regression Coefficient (Wald's Z-Test) #>  #>   Method          : Demidenko (Variance Corrected) #>   Predictor Dist. : Bernoulli #>  #> --------------------------------------------------- #> Hypotheses #> --------------------------------------------------- #>   H0 (Null Claim) : Rate Ratio = 1  #>   H1 (Alt. Claim) : Rate Ratio != 1  #>  #> --------------------------------------------------- #> Results #> --------------------------------------------------- #>   Sample Size          = 2404  << #>   Type 1 Error (alpha) = 0.050 #>   Type 2 Error (beta)  = 0.200 #>   Statistical Power    = 0.8 #>"},{"path":"https://metinbulus.github.io/pwrss/reference/utils.attrition.html","id":null,"dir":"Reference","previous_headings":"","what":"Inflate Sample Size for Attrition — inflate.sample","title":"Inflate Sample Size for Attrition — inflate.sample","text":"Helper function inflate sample size attrition.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/utils.attrition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inflate Sample Size for Attrition — inflate.sample","text":"","code":"inflate.sample(n, rate = 0.05,                ceiling = TRUE,                verbose = TRUE)"},{"path":"https://metinbulus.github.io/pwrss/reference/utils.attrition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inflate Sample Size for Attrition — inflate.sample","text":"n sample size. rate attrition rate. ceiling rounds-inflated sample size. verbose logical; whether output printed console. TRUE default.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/utils.attrition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inflate Sample Size for Attrition — inflate.sample","text":"inflated sample size.","code":""},{"path":"https://metinbulus.github.io/pwrss/reference/utils.attrition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inflate Sample Size for Attrition — inflate.sample","text":"","code":"inflate.sample(n = 100, rate = 0.05) #> 106"},{"path":"https://metinbulus.github.io/pwrss/news/index.html","id":"changes-in-pwrss-v100","dir":"Changelog","previous_headings":"","what":"Changes in pwrss v1.0.0","title":"Changes in pwrss v1.0.0","text":"CRAN release: 2025-09-16 Addition 1: ANCOVA procedures means contrasts (Shieh) Addition 2: Exact tests proportions (Fisher & McNemar) Addition 3: Generic binomial test (plotting feature) Addition 4: Dependent correlations (Steiger) Addition 5: Effect size conversion functions Extension 1: Generic tests handles non-zero null (useful equivalence minimum effect testing). specific tests also allow non-zero null. Extension 2: ANCOVA procedures allow R-squared adjustment (.e., Keppel Shieh) Consistent function names, population-consistent argument names (Greek notation) base R consistency Rigorous error checks warnings Comprehensive print utility three-tier verbosity control Minor bug fixes plot() function","code":""},{"path":"https://metinbulus.github.io/pwrss/news/index.html","id":"changes-in-pwrss-v032-not-released-to-cran","dir":"Changelog","previous_headings":"","what":"Changes in pwrss v0.3.2 (not released to CRAN)","title":"Changes in pwrss v0.3.2 (not released to CRAN)","text":"alternative = “less” now produce correct power rates pwrss.z.prop() function. Thanks Leszek Gawarecki reporting issue. default p0 argument pwrss.chisq.gofit() can now overwritten. Thanks Kate Crespi reporting issue. Type 1 type 2 error plots show print correct power estimates two-tailed tests effect size near zero. Thanks dpnichols811 (GitHub profile handle) Adrian Olszewski reporting issue. pwrss.z.corr() print correct errors alternative = “greater” fact less (vice versa). Thanks Jarrod Hadfield reporting issue.","code":""},{"path":"https://metinbulus.github.io/pwrss/news/index.html","id":"changes-in-pwrss-v031","dir":"Changelog","previous_headings":"","what":"Changes in pwrss v0.3.1","title":"Changes in pwrss v0.3.1","text":"CRAN release: 2023-04-11 detailed vignette (typo fixes) Added web application links (shiny dashboards) Minor bug fixes plot() function","code":""},{"path":"https://metinbulus.github.io/pwrss/news/index.html","id":"changes-in-pwrss-v030","dir":"Changelog","previous_headings":"","what":"Changes in pwrss v0.3.0","title":"Changes in pwrss v0.3.0","text":"CRAN release: 2023-03-12 Added pwrss.np.2means(), pwrss.z.logreg(), pwrss.z.poisreg(), pwrss.chisq.gofit(), generic power.chisq.test() functions Improvements plot() function Improvements documentation Improvements pwrss.z.med() pwrss.f.ancova() console print detailed comprehensive examples vignette Bug fixes (Welch’s t test)","code":""},{"path":"https://metinbulus.github.io/pwrss/news/index.html","id":"changes-in-pwrss-v020","dir":"Changelog","previous_headings":"","what":"Changes in pwrss v0.2.0","title":"Changes in pwrss v0.2.0","text":"CRAN release: 2022-12-14 Added pwrss.t.reg() pwrss.z.med() functions","code":""},{"path":"https://metinbulus.github.io/pwrss/news/index.html","id":"pwrss-v010","dir":"Changelog","previous_headings":"","what":"pwrss v0.1.0","title":"pwrss v0.1.0","text":"CRAN release: 2022-11-09 Initial release","code":""}]
